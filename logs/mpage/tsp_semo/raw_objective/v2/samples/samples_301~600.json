[
     {
          "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm combines a dynamic objective-space partitioning approach with a novel hierarchical tour decomposition strategy that adaptively identifies and preserves high-quality sub-tours from promising solutions, while intelligently breaking and reconnecting them through a constrained node sequence transformation mechanism that prioritizes segments based on their contribution to both objectives, using a hybrid multi-criteria evaluation to guide the reassembly process while maintaining solution feasibility by ensuring proper node connectivity and tour closure through a guided segment rotation and merging mechanism that adaptively adjusts the segment size and merge position based on the current trade-off between objectives, incorporating a novel edge inversion technique that considers both local topology and global objective trade-offs.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Dynamic objective-space partitioning and selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-6)\n    partition_centers = np.array([[0.1, 0.9], [0.5, 0.5], [0.9, 0.1]])\n    distances = np.linalg.norm(normalized_obj[:, None] - partition_centers, axis=2)\n    partition_assignments = np.argmin(distances, axis=1)\n\n    # Select from the most promising partition (middle partition)\n    partition_indices = np.where(partition_assignments == 1)[0]\n    if len(partition_indices) > 0:\n        selected_idx = np.random.choice(partition_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Hierarchical tour decomposition with dynamic segment size\n    for _ in range(5):\n        segment_size = np.random.randint(3, min(6, n // 3))\n        start = np.random.randint(0, n - segment_size)\n        end = start + segment_size\n        segment = base_solution[start:end]\n\n        # Evaluate segment contribution using hybrid criteria\n        segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n        total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n        # Hybrid importance weighting\n        weight1 = segment_cost1 / (total_cost1 + 1e-6)\n        weight2 = segment_cost2 / (total_cost2 + 1e-6)\n        hybrid_weight = 0.6 * weight1 + 0.4 * weight2 if weight1 > weight2 else 0.4 * weight1 + 0.6 * weight2\n\n        # Remove segment and find best merge position\n        temp_solution = np.concatenate([base_solution[:start], base_solution[end:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for i in range(len(temp_solution)):\n            # Try inserting segment at position i and its rotation variants\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(temp_solution, i, rotated_segment)\n\n                candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                score = hybrid_weight * candidate_cost1 + (1 - hybrid_weight) * candidate_cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n                    best_candidate = candidate\n\n        if best_pos != -1:\n            new_solution = best_candidate\n\n    # Guided edge inversion with adaptive trade-off consideration\n    for _ in range(4):\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n\n        # Consider edge inversion variants\n        variants = [\n            segment[::-1],  # standard inversion\n            np.roll(segment, 1),  # left rotation\n            np.roll(segment, -1),  # right rotation\n            np.concatenate([segment[:1], segment[1:][::-1]])  # partial inversion\n        ]\n\n        best_variant = segment\n        best_variant_score = float('inf')\n\n        for variant in variants:\n            candidate = np.concatenate([new_solution[:i], variant, new_solution[j+1:]])\n\n            if len(np.unique(candidate)) != n:\n                continue\n\n            candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            # Adaptive trade-off consideration\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (candidate_cost1 < current_cost1 and candidate_cost2 <= current_cost2 * 1.1) or \\\n               (candidate_cost2 < current_cost2 and candidate_cost1 <= current_cost1 * 1.1):\n                score = 0.7 * candidate_cost1 + 0.3 * candidate_cost2 if candidate_cost1 > candidate_cost2 else 0.3 * candidate_cost1 + 0.7 * candidate_cost2\n                if score < best_variant_score:\n                    best_variant_score = score\n                    best_variant = variant\n\n        if best_variant_score < float('inf'):\n            new_solution = np.concatenate([new_solution[:i], best_variant, new_solution[j+1:]])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating each solution's potential for improvement using a combination of objective values and diversity measures. It then applies a novel hybrid local search operator that combines a modified version of the Lin-Kernighan heuristic with a variable-length segment relocation strategy. The operator randomly selects a segment of nodes in the tour and relocates it to a new position while considering both objective spaces, ensuring feasibility by maintaining the TSP constraints. The selection of the segment length and insertion point is guided by a probabilistic approach that balances exploration and exploitation, favoring segments that show high potential for reducing both objectives. The function returns the new neighbor solution after validating its feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    selected_idx = np.argmin([(cost1 + cost2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2)) for _, (cost1, cost2) in archive])\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search operator\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Randomly select a segment length (1 to n//2)\n    segment_length = random.randint(1, n // 2)\n\n    # Randomly select a starting position for the segment\n    start_pos = random.randint(0, n - segment_length)\n\n    # Extract the segment\n    segment = new_solution[start_pos:start_pos + segment_length]\n\n    # Remove the segment from the solution\n    new_solution = np.concatenate([new_solution[:start_pos], new_solution[start_pos + segment_length:]])\n\n    # Find the best insertion position considering both objectives\n    best_insert_pos = 0\n    best_cost = float('inf')\n\n    for insert_pos in range(len(new_solution)):\n        # Insert the segment at the current position\n        candidate = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n        # Calculate the total cost in both objectives\n        cost1 = sum(distance_matrix_1[candidate[i-1], candidate[i]] for i in range(n))\n        cost2 = sum(distance_matrix_2[candidate[i-1], candidate[i]] for i in range(n))\n\n        # Combine the costs with a weighted sum\n        total_cost = cost1 + cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_insert_pos = insert_pos\n\n    # Insert the segment at the best position\n    new_solution = np.concatenate([new_solution[:best_insert_pos], segment, new_solution[best_insert_pos:]])\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 301,
          "algorithm": "{The new algorithm employs a novel multi-objective tour reconstruction framework that integrates a dynamic Pareto frontier-aware segment extraction process with a probabilistic node reallocation mechanism, which adaptively repurposes high-contribution segments from elite solutions while maintaining feasibility through a constrained node substitution protocol that respects both objective trade-offs and topological constraints. This approach intelligently balances exploration and exploitation by using a hybrid diversity-preserving criterion to guide segment selection, followed by a multi-phase insertion strategy that considers both local and global objective improvements, with feasibility maintained through a novel node connectivity validation system that ensures proper tour closure and node uniqueness.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with best combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmin(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Dynamic segment extraction based on objective contribution\n    segment_length = np.random.randint(2, min(5, n//2))\n    start_pos = np.random.randint(0, n - segment_length)\n    segment = base_solution[start_pos:start_pos + segment_length]\n\n    # Calculate segment contribution to both objectives\n    seg_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n    seg_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n    total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n    total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n    # Probabilistic segment reallocation\n    if (seg_cost1 / total_cost1) > 0.2 or (seg_cost2 / total_cost2) > 0.2:\n        # Remove segment and find best insertion point\n        remaining = np.concatenate([base_solution[:start_pos], base_solution[start_pos+segment_length:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for pos in range(len(remaining)):\n            # Try inserting segment at different positions and rotations\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(remaining, pos, rotated_segment)\n\n                # Calculate costs\n                cost1 = sum(distance_matrix_1[candidate[i], candidate[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[candidate[i], candidate[(i+1)%n]] for i in range(n))\n\n                # Score based on improvement in both objectives\n                score = (cost1 - total_cost1) + (cost2 - total_cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = pos\n                    best_segment = rotated_segment\n\n        if best_pos != -1:\n            new_solution = np.insert(remaining, best_pos, best_segment)\n    else:\n        # Node substitution for segments with low contribution\n        for i in range(start_pos, start_pos + segment_length):\n            # Find node with best substitution\n            best_node = -1\n            best_improvement = 0\n\n            for node in range(n):\n                if node in base_solution:\n                    continue\n\n                # Try substituting the node\n                candidate = base_solution.copy()\n                candidate[i] = node\n\n                # Calculate costs\n                cost1 = sum(distance_matrix_1[candidate[j], candidate[(j+1)%n]] for j in range(n))\n                cost2 = sum(distance_matrix_2[candidate[j], candidate[(j+1)%n]] for j in range(n))\n\n                improvement = (total_cost1 - cost1) + (total_cost2 - cost2)\n\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_node = node\n\n            if best_node != -1:\n                new_solution[i] = best_node\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if invalid\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               6.341302717185038,
               5.813748503280884
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with best combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmin(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Dynamic segment extraction based on objective contribution\n    segment_length = np.random.randint(2, min(5, n//2))\n    start_pos = np.random.randint(0, n - segment_length)\n    segment = base_solution[start_pos:start_pos + segment_length]\n\n    # Calculate segment contribution to both objectives\n    seg_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n    seg_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n    total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n    total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n    # Probabilistic segment reallocation\n    if (seg_cost1 / total_cost1) > 0.2 or (seg_cost2 / total_cost2) > 0.2:\n        # Remove segment and find best insertion point\n        remaining = np.concatenate([base_solution[:start_pos], base_solution[start_pos+segment_length:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for pos in range(len(remaining)):\n            # Try inserting segment at different positions and rotations\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(remaining, pos, rotated_segment)\n\n                # Calculate costs\n                cost1 = sum(distance_matrix_1[candidate[i], candidate[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[candidate[i], candidate[(i+1)%n]] for i in range(n))\n\n                # Score based on improvement in both objectives\n                score = (cost1 - total_cost1) + (cost2 - total_cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = pos\n                    best_segment = rotated_segment\n\n        if best_pos != -1:\n            new_solution = np.insert(remaining, best_pos, best_segment)\n    else:\n        # Node substitution for segments with low contribution\n        for i in range(start_pos, start_pos + segment_length):\n            # Find node with best substitution\n            best_node = -1\n            best_improvement = 0\n\n            for node in range(n):\n                if node in base_solution:\n                    continue\n\n                # Try substituting the node\n                candidate = base_solution.copy()\n                candidate[i] = node\n\n                # Calculate costs\n                cost1 = sum(distance_matrix_1[candidate[j], candidate[(j+1)%n]] for j in range(n))\n                cost2 = sum(distance_matrix_2[candidate[j], candidate[(j+1)%n]] for j in range(n))\n\n                improvement = (total_cost1 - cost1) + (total_cost2 - cost2)\n\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_node = node\n\n            if best_node != -1:\n                new_solution[i] = best_node\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if invalid\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm employs a novel multi-objective tour reconstruction strategy that first identifies critical path segments based on their contribution to both objectives, then intelligently reorders these segments using a hybrid similarity metric that combines both objective improvements and spatial proximity, followed by a constrained segment merging process that preserves high-quality sub-tours while introducing controlled randomness through a probabilistic segment inversion mechanism that adaptively adjusts its application probability based on the current trade-off between objectives, ensuring feasibility through a guided node reinsertion strategy that maintains proper tour connectivity and closure, and finally applies a dynamic edge swap operator that selectively exchanges edges between segments to further optimize the tour while respecting the trade-off between objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    import random\n    import numpy as np\n    from collections import defaultdict\n\n    # Select solution with best combined objective\n    objectives = np.array([obj for _, obj in archive])\n    combined_obj = objectives[:, 0] * 0.5 + objectives[:, 1] * 0.5\n    selected_idx = np.argmin(combined_obj)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Identify critical path segments\n    segment_sizes = []\n    current_segment = [base_solution[0]]\n    for i in range(1, n):\n        current_node = base_solution[i]\n        prev_node = base_solution[i-1]\n\n        cost1 = distance_matrix_1[prev_node, current_node]\n        cost2 = distance_matrix_2[prev_node, current_node]\n\n        # Check if adding to current segment improves both objectives\n        if cost1 < distance_matrix_1[base_solution[i-1], base_solution[i]] and \\\n           cost2 < distance_matrix_2[base_solution[i-1], base_solution[i]]:\n            current_segment.append(current_node)\n        else:\n            segment_sizes.append(len(current_segment))\n            current_segment = [current_node]\n    segment_sizes.append(len(current_segment))\n\n    # Create segments based on calculated sizes\n    segments = []\n    start = 0\n    for size in segment_sizes:\n        segments.append(base_solution[start:start+size])\n        start += size\n\n    # Calculate segment similarity\n    segment_coords = []\n    for seg in segments:\n        seg_coords = instance[seg, :2].mean(axis=0)\n        segment_coords.append(seg_coords)\n    segment_coords = np.array(segment_coords)\n\n    similarity_matrix = np.zeros((len(segments), len(segments)))\n    for i in range(len(segments)):\n        for j in range(len(segments)):\n            if i == j:\n                similarity_matrix[i,j] = 0\n            else:\n                # Objective similarity\n                seg1_cost1 = sum(distance_matrix_1[segments[i][k], segments[i][(k+1)%len(segments[i])]] for k in range(len(segments[i])))\n                seg1_cost2 = sum(distance_matrix_2[segments[i][k], segments[i][(k+1)%len(segments[i])]] for k in range(len(segments[i])))\n                seg2_cost1 = sum(distance_matrix_1[segments[j][k], segments[j][(k+1)%len(segments[j])]] for k in range(len(segments[j])))\n                seg2_cost2 = sum(distance_matrix_2[segments[j][k], segments[j][(k+1)%len(segments[j])]] for k in range(len(segments[j])))\n\n                obj_similarity = 1 / (1 + abs(seg1_cost1 - seg2_cost1) + abs(seg1_cost2 - seg2_cost2))\n\n                # Spatial similarity\n                spatial_similarity = 1 / (1 + np.linalg.norm(segment_coords[i] - segment_coords[j]))\n\n                similarity_matrix[i,j] = 0.6 * obj_similarity + 0.4 * spatial_similarity\n\n    # Greedy segment reordering\n    ordered_segments = []\n    remaining_indices = list(range(len(segments)))\n    current_index = random.choice(remaining_indices)\n    ordered_segments.append(segments[current_index])\n    remaining_indices.remove(current_index)\n\n    while remaining_indices:\n        best_index = max(remaining_indices, key=lambda x: similarity_matrix[current_index, x])\n        ordered_segments.append(segments[best_index])\n        current_index = best_index\n        remaining_indices.remove(best_index)\n\n    # Reconstruct solution\n    new_solution = np.concatenate(ordered_segments)\n\n    # Probabilistic segment inversion\n    for i in range(len(segments)):\n        if random.random() < 0.4:  # 40% chance to invert\n            new_solution[sum(segment_sizes[:i]):sum(segment_sizes[:i+1])] = \\\n                new_solution[sum(segment_sizes[:i]):sum(segment_sizes[:i+1])][::-1]\n\n    # Dynamic edge swap operator\n    for _ in range(5):\n        # Select two random segments\n        seg1_idx, seg2_idx = random.sample(range(len(segments)), 2)\n        seg1 = new_solution[sum(segment_sizes[:seg1_idx]):sum(segment_sizes[:seg1_idx+1])]\n        seg2 = new_solution[sum(segment_sizes[:seg2_idx]):sum(segment_sizes[:seg2_idx+1])]\n\n        # Select edges from each segment\n        if len(seg1) > 1 and len(seg2) > 1:\n            edge1_pos = random.randint(0, len(seg1)-2)\n            edge2_pos = random.randint(0, len(seg2)-2)\n\n            # Create temporary solution\n            temp_solution = new_solution.copy()\n            temp_solution[sum(segment_sizes[:seg1_idx])+edge1_pos] = seg2[edge2_pos]\n            temp_solution[sum(segment_sizes[:seg1_idx])+edge1_pos+1] = seg2[edge2_pos+1]\n            temp_solution[sum(segment_sizes[:seg2_idx])+edge2_pos] = seg1[edge1_pos]\n            temp_solution[sum(segment_sizes[:seg2_idx])+edge2_pos+1] = seg1[edge1_pos+1]\n\n            # Check feasibility\n            if len(np.unique(temp_solution)) == n:\n                # Calculate cost\n                cost1 = sum(distance_matrix_1[temp_solution[k], temp_solution[(k+1)%n]] for k in range(n))\n                cost2 = sum(distance_matrix_2[temp_solution[k], temp_solution[(k+1)%n]] for k in range(n))\n\n                # Calculate original cost\n                orig_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n                orig_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n                # Accept if both objectives improve\n                if cost1 < orig_cost1 and cost2 < orig_cost2:\n                    new_solution = temp_solution\n\n    # Guided node reinsertion for feasibility\n    for _ in range(3):\n        node_pos = random.randint(0, n-1)\n        node = new_solution[node_pos]\n        new_solution = np.delete(new_solution, node_pos)\n\n        best_pos = None\n        best_score = float('inf')\n        for pos in range(n-1):\n            candidate = np.insert(new_solution, pos, node)\n            cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            score = 0.5 * cost1 + 0.5 * cost2\n\n            if score < best_score:\n                best_score = score\n                best_pos = pos\n\n        if best_pos is not None:\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating each solution's potential for improvement using a combination of objective values and diversity measures. It then applies a novel hybrid local search operator that combines a modified version of the Lin-Kernighan heuristic with a variable-length segment relocation strategy. The operator randomly selects a segment of nodes in the tour and relocates it to a new position while considering both objective spaces, ensuring feasibility by maintaining the TSP constraints. The selection of the segment length and insertion point is guided by a probabilistic approach that balances exploration and exploitation, favoring segments that show high potential for reducing both objectives. The function returns the new neighbor solution after validating its feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    selected_idx = np.argmin([(cost1 + cost2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2)) for _, (cost1, cost2) in archive])\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search operator\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Randomly select a segment length (1 to n//2)\n    segment_length = random.randint(1, n // 2)\n\n    # Randomly select a starting position for the segment\n    start_pos = random.randint(0, n - segment_length)\n\n    # Extract the segment\n    segment = new_solution[start_pos:start_pos + segment_length]\n\n    # Remove the segment from the solution\n    new_solution = np.concatenate([new_solution[:start_pos], new_solution[start_pos + segment_length:]])\n\n    # Find the best insertion position considering both objectives\n    best_insert_pos = 0\n    best_cost = float('inf')\n\n    for insert_pos in range(len(new_solution)):\n        # Insert the segment at the current position\n        candidate = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n        # Calculate the total cost in both objectives\n        cost1 = sum(distance_matrix_1[candidate[i-1], candidate[i]] for i in range(n))\n        cost2 = sum(distance_matrix_2[candidate[i-1], candidate[i]] for i in range(n))\n\n        # Combine the costs with a weighted sum\n        total_cost = cost1 + cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_insert_pos = insert_pos\n\n    # Insert the segment at the best position\n    new_solution = np.concatenate([new_solution[:best_insert_pos], segment, new_solution[best_insert_pos:]])\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 302,
          "algorithm": "{The novel algorithm employs a multi-objective tour transformation strategy that first identifies dominant nodes based on their centrality in both objective spaces, then constructs a new tour by iteratively selecting nodes that show the highest combined improvement in both objectives when inserted at the current tour's weakest points, using a dynamic edge evaluation metric that considers both spatial proximity and objective trade-offs, while maintaining feasibility through a constrained node insertion mechanism that preserves tour connectivity and closure, and finally applies a probabilistic edge flipping operator that selectively reverses node sequences to further optimize the tour while respecting the trade-off between objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    import random\n    import numpy as np\n\n    # Select solution with best combined objective\n    objectives = np.array([obj for _, obj in archive])\n    combined_obj = objectives[:, 0] * 0.5 + objectives[:, 1] * 0.5\n    selected_idx = np.argmin(combined_obj)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Calculate node importance scores\n    node_scores = np.zeros(n)\n    for i in range(n):\n        # Calculate average distance to neighbors in both objectives\n        neighbors = [base_solution[(i-1)%n], base_solution[(i+1)%n]]\n        avg_dist1 = np.mean([distance_matrix_1[i, j] for j in neighbors])\n        avg_dist2 = np.mean([distance_matrix_2[i, j] for j in neighbors])\n        node_scores[i] = 0.5 * avg_dist1 + 0.5 * avg_dist2\n\n    # Identify dominant nodes (top 30%)\n    dominant_nodes = np.argsort(node_scores)[-int(0.3*n):]\n\n    # Initialize new solution with dominant nodes\n    new_solution = np.random.choice(dominant_nodes, size=len(dominant_nodes), replace=False)\n\n    # Add remaining nodes\n    remaining_nodes = [node for node in base_solution if node not in new_solution]\n    np.random.shuffle(remaining_nodes)\n\n    # Insert remaining nodes at weakest points\n    for node in remaining_nodes:\n        best_pos = 0\n        best_score = float('inf')\n\n        for pos in range(len(new_solution)):\n            # Calculate insertion cost for both objectives\n            cost1 = (distance_matrix_1[new_solution[pos-1], node] + distance_matrix_1[node, new_solution[pos]]) - distance_matrix_1[new_solution[pos-1], new_solution[pos]]\n            cost2 = (distance_matrix_2[new_solution[pos-1], node] + distance_matrix_2[node, new_solution[pos]]) - distance_matrix_2[new_solution[pos-1], new_solution[pos]]\n\n            # Calculate combined score\n            score = 0.5 * cost1 + 0.5 * cost2\n\n            if score < best_score:\n                best_score = score\n                best_pos = pos\n\n        new_solution = np.insert(new_solution, best_pos, node)\n\n    # Probabilistic edge flipping\n    for _ in range(3):\n        if random.random() < 0.3:  # 30% chance to flip\n            flip_start = random.randint(0, n-2)\n            flip_end = random.randint(flip_start+1, min(flip_start+5, n-1))\n            new_solution[flip_start:flip_end+1] = new_solution[flip_start:flip_end+1][::-1]\n\n    # Ensure solution is valid\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if invalid\n        new_solution = base_solution.copy()\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               5.998535439897436,
               5.911161254983817
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    import random\n    import numpy as np\n\n    # Select solution with best combined objective\n    objectives = np.array([obj for _, obj in archive])\n    combined_obj = objectives[:, 0] * 0.5 + objectives[:, 1] * 0.5\n    selected_idx = np.argmin(combined_obj)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Calculate node importance scores\n    node_scores = np.zeros(n)\n    for i in range(n):\n        # Calculate average distance to neighbors in both objectives\n        neighbors = [base_solution[(i-1)%n], base_solution[(i+1)%n]]\n        avg_dist1 = np.mean([distance_matrix_1[i, j] for j in neighbors])\n        avg_dist2 = np.mean([distance_matrix_2[i, j] for j in neighbors])\n        node_scores[i] = 0.5 * avg_dist1 + 0.5 * avg_dist2\n\n    # Identify dominant nodes (top 30%)\n    dominant_nodes = np.argsort(node_scores)[-int(0.3*n):]\n\n    # Initialize new solution with dominant nodes\n    new_solution = np.random.choice(dominant_nodes, size=len(dominant_nodes), replace=False)\n\n    # Add remaining nodes\n    remaining_nodes = [node for node in base_solution if node not in new_solution]\n    np.random.shuffle(remaining_nodes)\n\n    # Insert remaining nodes at weakest points\n    for node in remaining_nodes:\n        best_pos = 0\n        best_score = float('inf')\n\n        for pos in range(len(new_solution)):\n            # Calculate insertion cost for both objectives\n            cost1 = (distance_matrix_1[new_solution[pos-1], node] + distance_matrix_1[node, new_solution[pos]]) - distance_matrix_1[new_solution[pos-1], new_solution[pos]]\n            cost2 = (distance_matrix_2[new_solution[pos-1], node] + distance_matrix_2[node, new_solution[pos]]) - distance_matrix_2[new_solution[pos-1], new_solution[pos]]\n\n            # Calculate combined score\n            score = 0.5 * cost1 + 0.5 * cost2\n\n            if score < best_score:\n                best_score = score\n                best_pos = pos\n\n        new_solution = np.insert(new_solution, best_pos, node)\n\n    # Probabilistic edge flipping\n    for _ in range(3):\n        if random.random() < 0.3:  # 30% chance to flip\n            flip_start = random.randint(0, n-2)\n            flip_end = random.randint(flip_start+1, min(flip_start+5, n-1))\n            new_solution[flip_start:flip_end+1] = new_solution[flip_start:flip_end+1][::-1]\n\n    # Ensure solution is valid\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if invalid\n        new_solution = base_solution.copy()\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (high ratio of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    ratios = objectives[:, 0] / (objectives[:, 1] + 1e-6)  # Avoid division by zero\n    selected_idx = np.argmax(ratios)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: Edge exchange followed by segment reversal\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Edge exchange: Swap two edges if it improves both objectives\n    for _ in range(10):  # Limit attempts to avoid excessive computation\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n\n        # Create candidate by swapping edges\n        candidate = new_solution.copy()\n        candidate[i:j+1] = candidate[i:j+1][::-1]  # Reverse segment\n\n        # Calculate new objectives\n        old_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        new_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n        old_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        new_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n        # Accept if both objectives improve or one improves significantly\n        if (new_cost1 < old_cost1 and new_cost2 < old_cost2) or \\\n           (new_cost1 < old_cost1 * 0.95 and new_cost2 < old_cost2 * 1.05) or \\\n           (new_cost1 < old_cost1 * 1.05 and new_cost2 < old_cost2 * 0.95):\n            new_solution = candidate\n            break\n\n    # Segment reversal: Reverse a random segment if it improves the solution\n    i, j = np.random.choice(n, 2, replace=False)\n    if i > j:\n        i, j = j, i\n    candidate = new_solution.copy()\n    candidate[i:j+1] = candidate[i:j+1][::-1]\n\n    # Calculate new objectives\n    old_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    new_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n    old_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    new_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n    # Accept if both objectives improve or one improves significantly\n    if (new_cost1 < old_cost1 and new_cost2 < old_cost2) or \\\n       (new_cost1 < old_cost1 * 0.95 and new_cost2 < old_cost2 * 1.05) or \\\n       (new_cost1 < old_cost1 * 1.05 and new_cost2 < old_cost2 * 0.95):\n        new_solution = candidate\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm combines Pareto-based solution selection with a novel multi-objective tour fragmentation and reassembly strategy that intelligently splits the tour into contiguous segments, evaluates their objective contributions, and reassembles them in a way that maximizes improvements in both objectives while maintaining solution feasibility through a constrained segment merging mechanism. The reassembly process dynamically adjusts segment boundaries based on local topology and objective trade-offs, ensuring feasibility by maintaining a valid tour structure, and incorporates a guided segment rotation mechanism to further refine the solution while respecting the bi-objective nature of the problem.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with best Pareto trade-off\n    pareto_front = []\n    for sol, obj in archive:\n        dominated = False\n        to_remove = []\n        for i, (_, p_obj) in enumerate(pareto_front):\n            if obj[0] >= p_obj[0] and obj[1] >= p_obj[1]:\n                dominated = True\n                break\n            if obj[0] <= p_obj[0] and obj[1] <= p_obj[1]:\n                to_remove.append(i)\n        if not dominated:\n            pareto_front = [pf for i, pf in enumerate(pareto_front) if i not in to_remove]\n            pareto_front.append((sol, obj))\n\n    if not pareto_front:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n    else:\n        # Select solution with best trade-off (minimize sum of normalized objectives)\n        normalized_front = []\n        min_obj1 = min(obj[0] for _, obj in pareto_front)\n        max_obj1 = max(obj[0] for _, obj in pareto_front)\n        min_obj2 = min(obj[1] for _, obj in pareto_front)\n        max_obj2 = max(obj[1] for _, obj in pareto_front)\n\n        for sol, obj in pareto_front:\n            norm_obj1 = (obj[0] - min_obj1) / (max_obj1 - min_obj1) if max_obj1 != min_obj1 else 0.5\n            norm_obj2 = (obj[1] - min_obj2) / (max_obj2 - min_obj2) if max_obj2 != min_obj2 else 0.5\n            normalized_front.append((sol, (norm_obj1, norm_obj2)))\n\n        best_idx = np.argmin([obj[0] + obj[1] for _, obj in normalized_front])\n        base_solution = normalized_front[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Multi-objective tour fragmentation and reassembly\n    for _ in range(5):\n        # Randomly select two cut points to split the tour into three segments\n        cut1, cut2 = sorted(random.sample(range(1, n), 2))\n        segment1 = base_solution[:cut1]\n        segment2 = base_solution[cut1:cut2]\n        segment3 = base_solution[cut2:]\n\n        # Try different reassembly orders\n        candidates = [\n            np.concatenate([segment1, segment3, segment2]),\n            np.concatenate([segment2, segment1, segment3]),\n            np.concatenate([segment3, segment2, segment1]),\n            np.concatenate([segment1, segment2[::-1], segment3]),\n            np.concatenate([segment2[::-1], segment1, segment3])\n        ]\n\n        best_candidate = new_solution.copy()\n        best_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        best_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n        for candidate in candidates:\n            cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            if (cost1 < best_cost1 and cost2 <= best_cost2 * 1.05) or (cost2 < best_cost2 and cost1 <= best_cost1 * 1.05):\n                best_candidate = candidate\n                best_cost1 = cost1\n                best_cost2 = cost2\n\n        new_solution = best_candidate\n\n    # Guided segment rotation\n    for _ in range(5):\n        # Select a segment to rotate\n        segment_length = np.random.randint(2, min(5, n // 2))\n        start = np.random.randint(0, n - segment_length)\n        end = start + segment_length\n\n        # Try different rotation amounts\n        for rotation in range(1, segment_length):\n            candidate = new_solution.copy()\n            segment = candidate[start:end]\n            rotated_segment = np.roll(segment, rotation)\n            candidate[start:end] = rotated_segment\n\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            new_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            new_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            if (new_cost1 < current_cost1 and new_cost2 <= current_cost2 * 1.05) or (new_cost2 < current_cost2 and new_cost1 <= current_cost1 * 1.05):\n                new_solution = candidate\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 303,
          "algorithm": "{The new algorithm combines Pareto-based solution selection with a novel multi-objective tour segmentation and reassembly strategy that intelligently splits the tour into non-contiguous segments, evaluates their objective contributions, and reassembles them in a way that maximizes improvements in both objectives while maintaining solution feasibility through a constrained segment merging mechanism. The reassembly process dynamically adjusts segment boundaries based on local topology and objective trade-offs, ensuring feasibility by maintaining a valid tour structure, and incorporates a guided segment permutation mechanism to further refine the solution while respecting the bi-objective nature of the problem.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with best Pareto trade-off\n    pareto_front = []\n    for sol, obj in archive:\n        dominated = False\n        to_remove = []\n        for i, (_, p_obj) in enumerate(pareto_front):\n            if obj[0] >= p_obj[0] and obj[1] >= p_obj[1]:\n                dominated = True\n                break\n            if obj[0] <= p_obj[0] and obj[1] <= p_obj[1]:\n                to_remove.append(i)\n        if not dominated:\n            pareto_front = [pf for i, pf in enumerate(pareto_front) if i not in to_remove]\n            pareto_front.append((sol, obj))\n\n    if not pareto_front:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n    else:\n        # Select solution with best trade-off (minimize sum of normalized objectives)\n        normalized_front = []\n        min_obj1 = min(obj[0] for _, obj in pareto_front)\n        max_obj1 = max(obj[0] for _, obj in pareto_front)\n        min_obj2 = min(obj[1] for _, obj in pareto_front)\n        max_obj2 = max(obj[1] for _, obj in pareto_front)\n\n        for sol, obj in pareto_front:\n            norm_obj1 = (obj[0] - min_obj1) / (max_obj1 - min_obj1) if max_obj1 != min_obj1 else 0.5\n            norm_obj2 = (obj[1] - min_obj2) / (max_obj2 - min_obj2) if max_obj2 != min_obj2 else 0.5\n            normalized_front.append((sol, (norm_obj1, norm_obj2)))\n\n        best_idx = np.argmin([obj[0] + obj[1] for _, obj in normalized_front])\n        base_solution = normalized_front[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Multi-objective tour segmentation and reassembly\n    for _ in range(5):\n        # Randomly select multiple segments to split the tour\n        num_segments = np.random.randint(2, min(5, n // 2))\n        cut_points = sorted(random.sample(range(1, n), num_segments - 1))\n        segments = []\n        prev = 0\n        for cut in cut_points:\n            segments.append(base_solution[prev:cut])\n            prev = cut\n        segments.append(base_solution[prev:])\n\n        # Try different permutations of segments\n        for _ in range(3):\n            random.shuffle(segments)\n            candidate = np.concatenate(segments)\n\n            cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (cost1 < current_cost1 and cost2 <= current_cost2 * 1.05) or (cost2 < current_cost2 and cost1 <= current_cost1 * 1.05):\n                new_solution = candidate\n\n    # Guided segment permutation with reversal\n    for _ in range(5):\n        # Select a segment to permute and optionally reverse\n        segment_length = np.random.randint(2, min(5, n // 2))\n        start = np.random.randint(0, n - segment_length)\n        end = start + segment_length\n\n        segment = new_solution[start:end]\n        if random.random() > 0.5:\n            segment = segment[::-1]\n\n        # Try different positions for the segment\n        for _ in range(3):\n            new_pos = np.random.randint(0, n - segment_length)\n            if new_pos == start:\n                continue\n\n            candidate = new_solution.copy()\n            candidate = np.concatenate([candidate[:new_pos], segment, candidate[new_pos:]])\n            candidate = np.concatenate([candidate[:start], candidate[start+segment_length:]])\n\n            cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (cost1 < current_cost1 and cost2 <= current_cost2 * 1.05) or (cost2 < current_cost2 and cost1 <= current_cost1 * 1.05):\n                new_solution = candidate\n\n    return new_solution\n\n",
          "score": [
               6.135657742629906,
               5.797873442094607
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with best Pareto trade-off\n    pareto_front = []\n    for sol, obj in archive:\n        dominated = False\n        to_remove = []\n        for i, (_, p_obj) in enumerate(pareto_front):\n            if obj[0] >= p_obj[0] and obj[1] >= p_obj[1]:\n                dominated = True\n                break\n            if obj[0] <= p_obj[0] and obj[1] <= p_obj[1]:\n                to_remove.append(i)\n        if not dominated:\n            pareto_front = [pf for i, pf in enumerate(pareto_front) if i not in to_remove]\n            pareto_front.append((sol, obj))\n\n    if not pareto_front:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n    else:\n        # Select solution with best trade-off (minimize sum of normalized objectives)\n        normalized_front = []\n        min_obj1 = min(obj[0] for _, obj in pareto_front)\n        max_obj1 = max(obj[0] for _, obj in pareto_front)\n        min_obj2 = min(obj[1] for _, obj in pareto_front)\n        max_obj2 = max(obj[1] for _, obj in pareto_front)\n\n        for sol, obj in pareto_front:\n            norm_obj1 = (obj[0] - min_obj1) / (max_obj1 - min_obj1) if max_obj1 != min_obj1 else 0.5\n            norm_obj2 = (obj[1] - min_obj2) / (max_obj2 - min_obj2) if max_obj2 != min_obj2 else 0.5\n            normalized_front.append((sol, (norm_obj1, norm_obj2)))\n\n        best_idx = np.argmin([obj[0] + obj[1] for _, obj in normalized_front])\n        base_solution = normalized_front[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Multi-objective tour segmentation and reassembly\n    for _ in range(5):\n        # Randomly select multiple segments to split the tour\n        num_segments = np.random.randint(2, min(5, n // 2))\n        cut_points = sorted(random.sample(range(1, n), num_segments - 1))\n        segments = []\n        prev = 0\n        for cut in cut_points:\n            segments.append(base_solution[prev:cut])\n            prev = cut\n        segments.append(base_solution[prev:])\n\n        # Try different permutations of segments\n        for _ in range(3):\n            random.shuffle(segments)\n            candidate = np.concatenate(segments)\n\n            cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (cost1 < current_cost1 and cost2 <= current_cost2 * 1.05) or (cost2 < current_cost2 and cost1 <= current_cost1 * 1.05):\n                new_solution = candidate\n\n    # Guided segment permutation with reversal\n    for _ in range(5):\n        # Select a segment to permute and optionally reverse\n        segment_length = np.random.randint(2, min(5, n // 2))\n        start = np.random.randint(0, n - segment_length)\n        end = start + segment_length\n\n        segment = new_solution[start:end]\n        if random.random() > 0.5:\n            segment = segment[::-1]\n\n        # Try different positions for the segment\n        for _ in range(3):\n            new_pos = np.random.randint(0, n - segment_length)\n            if new_pos == start:\n                continue\n\n            candidate = new_solution.copy()\n            candidate = np.concatenate([candidate[:new_pos], segment, candidate[new_pos:]])\n            candidate = np.concatenate([candidate[:start], candidate[start+segment_length:]])\n\n            cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (cost1 < current_cost1 and cost2 <= current_cost2 * 1.05) or (cost2 < current_cost2 and cost1 <= current_cost1 * 1.05):\n                new_solution = candidate\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm combines Pareto front analysis with a novel multi-objective segment relocation strategy that dynamically selects and repositions segments of the tour based on their contribution to both objectives, using a hybrid acceptance criterion that balances improvement in both objectives while maintaining solution feasibility through a constrained segment relocation mechanism. The segment relocation dynamically adjusts the segment length and position based on local topology and objective trade-offs, ensuring feasibility by maintaining a valid tour structure, and incorporates a guided edge reversal mechanism to further refine the solution while respecting the bi-objective nature of the problem.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with best trade-off using Pareto front analysis\n    pareto_front = []\n    for sol, obj in archive:\n        dominated = False\n        to_remove = []\n        for i, (_, p_obj) in enumerate(pareto_front):\n            if obj[0] >= p_obj[0] and obj[1] >= p_obj[1]:\n                dominated = True\n                break\n            if obj[0] <= p_obj[0] and obj[1] <= p_obj[1]:\n                to_remove.append(i)\n        if not dominated:\n            pareto_front = [pf for i, pf in enumerate(pareto_front) if i not in to_remove]\n            pareto_front.append((sol, obj))\n\n    if not pareto_front:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n    else:\n        # Select solution with best trade-off (minimize sum of normalized objectives)\n        normalized_front = []\n        min_obj1 = min(obj[0] for _, obj in pareto_front)\n        max_obj1 = max(obj[0] for _, obj in pareto_front)\n        min_obj2 = min(obj[1] for _, obj in pareto_front)\n        max_obj2 = max(obj[1] for _, obj in pareto_front)\n\n        for sol, obj in pareto_front:\n            norm_obj1 = (obj[0] - min_obj1) / (max_obj1 - min_obj1) if max_obj1 != min_obj1 else 0.5\n            norm_obj2 = (obj[1] - min_obj2) / (max_obj2 - min_obj2) if max_obj2 != min_obj2 else 0.5\n            normalized_front.append((sol, (norm_obj1, norm_obj2)))\n\n        best_idx = np.argmin([obj[0] + obj[1] for _, obj in normalized_front])\n        base_solution = normalized_front[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Multi-objective segment relocation\n    for _ in range(5):\n        segment_length = np.random.randint(2, min(5, n // 2))\n        start = np.random.randint(n - segment_length)\n        end = start + segment_length\n\n        # Extract the segment\n        segment = base_solution[start:end]\n\n        # Remove the segment\n        temp_solution = np.concatenate([base_solution[:start], base_solution[end:]])\n\n        # Find best insertion position considering both objectives\n        best_pos = 0\n        best_cost1 = float('inf')\n        best_cost2 = float('inf')\n\n        for i in range(len(temp_solution)):\n            # Insert segment at position i\n            candidate = np.insert(temp_solution, i, segment)\n\n            # Calculate costs\n            cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            # Multi-objective comparison\n            if (cost1 < best_cost1 and cost2 <= best_cost2 * 1.05) or (cost2 < best_cost2 and cost1 <= best_cost1 * 1.05):\n                best_pos = i\n                best_cost1 = cost1\n                best_cost2 = cost2\n\n        # Insert segment at best position\n        new_solution = np.insert(temp_solution, best_pos, segment)\n\n    # Guided edge reversal\n    for _ in range(5):\n        i, j = sorted(random.sample(range(n), 2))\n        segment = new_solution[i:j+1]\n\n        # Reverse the segment\n        reversed_segment = segment[::-1]\n\n        # Create candidate solution\n        candidate = np.concatenate([new_solution[:i], reversed_segment, new_solution[j+1:]])\n\n        # Calculate costs\n        current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        new_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n        new_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n        # Accept if at least one objective improves or both improve with controlled trade-off\n        if (new_cost1 < current_cost1 and new_cost2 <= current_cost2 * 1.05) or \\\n           (new_cost2 < current_cost2 and new_cost1 <= current_cost1 * 1.05):\n            new_solution = candidate\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating each solution's potential for improvement using a combination of objective values and diversity measures. It then applies a novel hybrid local search operator that combines a modified version of the Lin-Kernighan heuristic with a variable-length segment relocation strategy. The operator randomly selects a segment of nodes in the tour and relocates it to a new position while considering both objective spaces, ensuring feasibility by maintaining the TSP constraints. The selection of the segment length and insertion point is guided by a probabilistic approach that balances exploration and exploitation, favoring segments that show high potential for reducing both objectives. The function returns the new neighbor solution after validating its feasibility.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    selected_idx = np.argmin([(cost1 + cost2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2)) for _, (cost1, cost2) in archive])\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search operator\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Randomly select a segment length (1 to n//2)\n    segment_length = random.randint(1, n // 2)\n\n    # Randomly select a starting position for the segment\n    start_pos = random.randint(0, n - segment_length)\n\n    # Extract the segment\n    segment = new_solution[start_pos:start_pos + segment_length]\n\n    # Remove the segment from the solution\n    new_solution = np.concatenate([new_solution[:start_pos], new_solution[start_pos + segment_length:]])\n\n    # Find the best insertion position considering both objectives\n    best_insert_pos = 0\n    best_cost = float('inf')\n\n    for insert_pos in range(len(new_solution)):\n        # Insert the segment at the current position\n        candidate = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n        # Calculate the total cost in both objectives\n        cost1 = sum(distance_matrix_1[candidate[i-1], candidate[i]] for i in range(n))\n        cost2 = sum(distance_matrix_2[candidate[i-1], candidate[i]] for i in range(n))\n\n        # Combine the costs with a weighted sum\n        total_cost = cost1 + cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_insert_pos = insert_pos\n\n    # Insert the segment at the best position\n    new_solution = np.concatenate([new_solution[:best_insert_pos], segment, new_solution[best_insert_pos:]])\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 304,
          "algorithm": "{The new algorithm introduces a topological clustering and multi-objective k-means-based tour construction approach that first partitions the nodes into clusters based on their positions in both objective spaces using a novel bi-objective k-means algorithm, then constructs an initial tour by sequentially visiting nodes within each cluster while optimizing for both objectives, and finally applies a cluster-based edge exchange mechanism that intelligently swaps segments between clusters to improve both objectives simultaneously, with the entire process guided by a dynamic objective weighting scheme that adapts to the current solution quality and problem characteristics.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with best trade-off using Pareto front analysis\n    pareto_front = []\n    for sol, obj in archive:\n        dominated = False\n        to_remove = []\n        for i, (_, p_obj) in enumerate(pareto_front):\n            if obj[0] >= p_obj[0] and obj[1] >= p_obj[1]:\n                dominated = True\n                break\n            if obj[0] <= p_obj[0] and obj[1] <= p_obj[1]:\n                to_remove.append(i)\n        if not dominated:\n            pareto_front = [pf for i, pf in enumerate(pareto_front) if i not in to_remove]\n            pareto_front.append((sol, obj))\n\n    if not pareto_front:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n    else:\n        # Select solution with best trade-off (minimize sum of normalized objectives)\n        normalized_front = []\n        min_obj1 = min(obj[0] for _, obj in pareto_front)\n        max_obj1 = max(obj[0] for _, obj in pareto_front)\n        min_obj2 = min(obj[1] for _, obj in pareto_front)\n        max_obj2 = max(obj[1] for _, obj in pareto_front)\n\n        for sol, obj in pareto_front:\n            norm_obj1 = (obj[0] - min_obj1) / (max_obj1 - min_obj1) if max_obj1 != min_obj1 else 0.5\n            norm_obj2 = (obj[1] - min_obj2) / (max_obj2 - min_obj2) if max_obj2 != min_obj2 else 0.5\n            normalized_front.append((sol, (norm_obj1, norm_obj2)))\n\n        best_idx = np.argmin([obj[0] + obj[1] for _, obj in normalized_front])\n        base_solution = normalized_front[best_idx][0].copy()\n\n    # Bi-objective k-means clustering\n    n_clusters = min(5, len(base_solution) // 3)\n    n_nodes = len(base_solution)\n\n    # Initialize centroids\n    centroids = []\n    for _ in range(n_clusters):\n        idx = np.random.randint(0, n_nodes)\n        centroids.append(instance[base_solution[idx]])\n\n    # K-means clustering\n    for _ in range(10):\n        clusters = [[] for _ in range(n_clusters)]\n        for i in range(n_nodes):\n            node = base_solution[i]\n            coords = instance[node]\n            # Calculate distances to centroids considering both objectives\n            distances = []\n            for c in centroids:\n                dist1 = np.sqrt((coords[0] - c[0])**2 + (coords[1] - c[1])**2)\n                dist2 = np.sqrt((coords[2] - c[2])**2 + (coords[3] - c[3])**2)\n                distances.append(dist1 + dist2)\n            cluster_idx = np.argmin(distances)\n            clusters[cluster_idx].append(node)\n\n        # Update centroids\n        new_centroids = []\n        for cluster in clusters:\n            if not cluster:\n                new_centroids.append(centroids[np.random.randint(0, len(centroids))])\n                continue\n            cluster_coords = instance[cluster]\n            new_centroid = np.mean(cluster_coords, axis=0)\n            new_centroids.append(new_centroid)\n        centroids = new_centroids\n\n    # Construct new tour based on clusters\n    new_solution = []\n    for cluster in clusters:\n        if not cluster:\n            continue\n        # Sort nodes in cluster by their position in both objective spaces\n        cluster_coords = instance[cluster]\n        # Calculate average position in both spaces\n        avg_pos = np.mean(cluster_coords, axis=0)\n        # Sort by distance to average position considering both objectives\n        distances = []\n        for i in range(len(cluster)):\n            coords = cluster_coords[i]\n            dist1 = np.sqrt((coords[0] - avg_pos[0])**2 + (coords[1] - avg_pos[1])**2)\n            dist2 = np.sqrt((coords[2] - avg_pos[2])**2 + (coords[3] - avg_pos[3])**2)\n            distances.append(dist1 + dist2)\n        sorted_indices = np.argsort(distances)\n        new_solution.extend([cluster[i] for i in sorted_indices])\n\n    # Apply cluster-based edge exchange\n    for _ in range(5):\n        # Randomly select two clusters\n        if len(clusters) < 2:\n            break\n        cluster1, cluster2 = random.sample(clusters, 2)\n\n        if not cluster1 or not cluster2:\n            continue\n\n        # Randomly select a segment from each cluster\n        seg1_len = min(3, len(cluster1))\n        seg2_len = min(3, len(cluster2))\n        seg1_start = np.random.randint(0, len(cluster1) - seg1_len + 1)\n        seg2_start = np.random.randint(0, len(cluster2) - seg2_len + 1)\n\n        seg1 = cluster1[seg1_start:seg1_start + seg1_len]\n        seg2 = cluster2[seg2_start:seg2_start + seg2_len]\n\n        # Calculate current costs\n        current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(len(new_solution)))\n        current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(len(new_solution)))\n\n        # Create candidate solution with segments swapped\n        candidate = new_solution.copy()\n        # Find positions of segments in candidate\n        pos1 = [i for i, x in enumerate(candidate) if x in seg1]\n        pos2 = [i for i, x in enumerate(candidate) if x in seg2]\n\n        if not pos1 or not pos2:\n            continue\n\n        # Swap segments\n        for i, p1 in enumerate(pos1):\n            candidate[p1] = seg2[i % len(seg2)]\n        for i, p2 in enumerate(pos2):\n            candidate[p2] = seg1[i % len(seg1)]\n\n        # Calculate new costs\n        new_cost1 = sum(distance_matrix_1[candidate[i-1], candidate[i]] for i in range(len(candidate)))\n        new_cost2 = sum(distance_matrix_2[candidate[i-1], candidate[i]] for i in range(len(candidate)))\n\n        # Accept if at least one objective improves\n        if (new_cost1 < current_cost1 and new_cost2 <= current_cost2 * 1.05) or \\\n           (new_cost2 < current_cost2 and new_cost1 <= current_cost1 * 1.05):\n            new_solution = candidate\n\n    return np.array(new_solution)\n\n",
          "score": [
               7.068931167481531,
               6.884135519117494
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with best trade-off using Pareto front analysis\n    pareto_front = []\n    for sol, obj in archive:\n        dominated = False\n        to_remove = []\n        for i, (_, p_obj) in enumerate(pareto_front):\n            if obj[0] >= p_obj[0] and obj[1] >= p_obj[1]:\n                dominated = True\n                break\n            if obj[0] <= p_obj[0] and obj[1] <= p_obj[1]:\n                to_remove.append(i)\n        if not dominated:\n            pareto_front = [pf for i, pf in enumerate(pareto_front) if i not in to_remove]\n            pareto_front.append((sol, obj))\n\n    if not pareto_front:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n    else:\n        # Select solution with best trade-off (minimize sum of normalized objectives)\n        normalized_front = []\n        min_obj1 = min(obj[0] for _, obj in pareto_front)\n        max_obj1 = max(obj[0] for _, obj in pareto_front)\n        min_obj2 = min(obj[1] for _, obj in pareto_front)\n        max_obj2 = max(obj[1] for _, obj in pareto_front)\n\n        for sol, obj in pareto_front:\n            norm_obj1 = (obj[0] - min_obj1) / (max_obj1 - min_obj1) if max_obj1 != min_obj1 else 0.5\n            norm_obj2 = (obj[1] - min_obj2) / (max_obj2 - min_obj2) if max_obj2 != min_obj2 else 0.5\n            normalized_front.append((sol, (norm_obj1, norm_obj2)))\n\n        best_idx = np.argmin([obj[0] + obj[1] for _, obj in normalized_front])\n        base_solution = normalized_front[best_idx][0].copy()\n\n    # Bi-objective k-means clustering\n    n_clusters = min(5, len(base_solution) // 3)\n    n_nodes = len(base_solution)\n\n    # Initialize centroids\n    centroids = []\n    for _ in range(n_clusters):\n        idx = np.random.randint(0, n_nodes)\n        centroids.append(instance[base_solution[idx]])\n\n    # K-means clustering\n    for _ in range(10):\n        clusters = [[] for _ in range(n_clusters)]\n        for i in range(n_nodes):\n            node = base_solution[i]\n            coords = instance[node]\n            # Calculate distances to centroids considering both objectives\n            distances = []\n            for c in centroids:\n                dist1 = np.sqrt((coords[0] - c[0])**2 + (coords[1] - c[1])**2)\n                dist2 = np.sqrt((coords[2] - c[2])**2 + (coords[3] - c[3])**2)\n                distances.append(dist1 + dist2)\n            cluster_idx = np.argmin(distances)\n            clusters[cluster_idx].append(node)\n\n        # Update centroids\n        new_centroids = []\n        for cluster in clusters:\n            if not cluster:\n                new_centroids.append(centroids[np.random.randint(0, len(centroids))])\n                continue\n            cluster_coords = instance[cluster]\n            new_centroid = np.mean(cluster_coords, axis=0)\n            new_centroids.append(new_centroid)\n        centroids = new_centroids\n\n    # Construct new tour based on clusters\n    new_solution = []\n    for cluster in clusters:\n        if not cluster:\n            continue\n        # Sort nodes in cluster by their position in both objective spaces\n        cluster_coords = instance[cluster]\n        # Calculate average position in both spaces\n        avg_pos = np.mean(cluster_coords, axis=0)\n        # Sort by distance to average position considering both objectives\n        distances = []\n        for i in range(len(cluster)):\n            coords = cluster_coords[i]\n            dist1 = np.sqrt((coords[0] - avg_pos[0])**2 + (coords[1] - avg_pos[1])**2)\n            dist2 = np.sqrt((coords[2] - avg_pos[2])**2 + (coords[3] - avg_pos[3])**2)\n            distances.append(dist1 + dist2)\n        sorted_indices = np.argsort(distances)\n        new_solution.extend([cluster[i] for i in sorted_indices])\n\n    # Apply cluster-based edge exchange\n    for _ in range(5):\n        # Randomly select two clusters\n        if len(clusters) < 2:\n            break\n        cluster1, cluster2 = random.sample(clusters, 2)\n\n        if not cluster1 or not cluster2:\n            continue\n\n        # Randomly select a segment from each cluster\n        seg1_len = min(3, len(cluster1))\n        seg2_len = min(3, len(cluster2))\n        seg1_start = np.random.randint(0, len(cluster1) - seg1_len + 1)\n        seg2_start = np.random.randint(0, len(cluster2) - seg2_len + 1)\n\n        seg1 = cluster1[seg1_start:seg1_start + seg1_len]\n        seg2 = cluster2[seg2_start:seg2_start + seg2_len]\n\n        # Calculate current costs\n        current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(len(new_solution)))\n        current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(len(new_solution)))\n\n        # Create candidate solution with segments swapped\n        candidate = new_solution.copy()\n        # Find positions of segments in candidate\n        pos1 = [i for i, x in enumerate(candidate) if x in seg1]\n        pos2 = [i for i, x in enumerate(candidate) if x in seg2]\n\n        if not pos1 or not pos2:\n            continue\n\n        # Swap segments\n        for i, p1 in enumerate(pos1):\n            candidate[p1] = seg2[i % len(seg2)]\n        for i, p2 in enumerate(pos2):\n            candidate[p2] = seg1[i % len(seg1)]\n\n        # Calculate new costs\n        new_cost1 = sum(distance_matrix_1[candidate[i-1], candidate[i]] for i in range(len(candidate)))\n        new_cost2 = sum(distance_matrix_2[candidate[i-1], candidate[i]] for i in range(len(candidate)))\n\n        # Accept if at least one objective improves\n        if (new_cost1 < current_cost1 and new_cost2 <= current_cost2 * 1.05) or \\\n           (new_cost2 < current_cost2 and new_cost1 <= current_cost1 * 1.05):\n            new_solution = candidate\n\n    return np.array(new_solution)\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (high ratio of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    ratios = objectives[:, 0] / (objectives[:, 1] + 1e-6)  # Avoid division by zero\n    selected_idx = np.argmax(ratios)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: Edge exchange followed by segment reversal\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Edge exchange: Swap two edges if it improves both objectives\n    for _ in range(10):  # Limit attempts to avoid excessive computation\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n\n        # Create candidate by swapping edges\n        candidate = new_solution.copy()\n        candidate[i:j+1] = candidate[i:j+1][::-1]  # Reverse segment\n\n        # Calculate new objectives\n        old_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        new_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n        old_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        new_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n        # Accept if both objectives improve or one improves significantly\n        if (new_cost1 < old_cost1 and new_cost2 < old_cost2) or \\\n           (new_cost1 < old_cost1 * 0.95 and new_cost2 < old_cost2 * 1.05) or \\\n           (new_cost1 < old_cost1 * 1.05 and new_cost2 < old_cost2 * 0.95):\n            new_solution = candidate\n            break\n\n    # Segment reversal: Reverse a random segment if it improves the solution\n    i, j = np.random.choice(n, 2, replace=False)\n    if i > j:\n        i, j = j, i\n    candidate = new_solution.copy()\n    candidate[i:j+1] = candidate[i:j+1][::-1]\n\n    # Calculate new objectives\n    old_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    new_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n    old_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    new_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n    # Accept if both objectives improve or one improves significantly\n    if (new_cost1 < old_cost1 and new_cost2 < old_cost2) or \\\n       (new_cost1 < old_cost1 * 0.95 and new_cost2 < old_cost2 * 1.05) or \\\n       (new_cost1 < old_cost1 * 1.05 and new_cost2 < old_cost2 * 0.95):\n        new_solution = candidate\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm combines a dynamic objective-space partitioning approach with a novel hierarchical tour decomposition strategy that adaptively identifies and preserves high-quality sub-tours from promising solutions, while intelligently breaking and reconnecting them through a constrained node sequence transformation mechanism that prioritizes segments based on their contribution to both objectives, using a hybrid multi-criteria evaluation to guide the reassembly process while maintaining solution feasibility by ensuring proper node connectivity and tour closure through a guided segment rotation and merging mechanism that adaptively adjusts the segment size and merge position based on the current trade-off between objectives, incorporating a novel edge inversion technique that considers both local topology and global objective trade-offs.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Dynamic objective-space partitioning and selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-6)\n    partition_centers = np.array([[0.1, 0.9], [0.5, 0.5], [0.9, 0.1]])\n    distances = np.linalg.norm(normalized_obj[:, None] - partition_centers, axis=2)\n    partition_assignments = np.argmin(distances, axis=1)\n\n    # Select from the most promising partition (middle partition)\n    partition_indices = np.where(partition_assignments == 1)[0]\n    if len(partition_indices) > 0:\n        selected_idx = np.random.choice(partition_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Hierarchical tour decomposition with dynamic segment size\n    for _ in range(5):\n        segment_size = np.random.randint(3, min(6, n // 3))\n        start = np.random.randint(0, n - segment_size)\n        end = start + segment_size\n        segment = base_solution[start:end]\n\n        # Evaluate segment contribution using hybrid criteria\n        segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n        total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n        # Hybrid importance weighting\n        weight1 = segment_cost1 / (total_cost1 + 1e-6)\n        weight2 = segment_cost2 / (total_cost2 + 1e-6)\n        hybrid_weight = 0.6 * weight1 + 0.4 * weight2 if weight1 > weight2 else 0.4 * weight1 + 0.6 * weight2\n\n        # Remove segment and find best merge position\n        temp_solution = np.concatenate([base_solution[:start], base_solution[end:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for i in range(len(temp_solution)):\n            # Try inserting segment at position i and its rotation variants\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(temp_solution, i, rotated_segment)\n\n                candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                score = hybrid_weight * candidate_cost1 + (1 - hybrid_weight) * candidate_cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n                    best_candidate = candidate\n\n        if best_pos != -1:\n            new_solution = best_candidate\n\n    # Guided edge inversion with adaptive trade-off consideration\n    for _ in range(4):\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n\n        # Consider edge inversion variants\n        variants = [\n            segment[::-1],  # standard inversion\n            np.roll(segment, 1),  # left rotation\n            np.roll(segment, -1),  # right rotation\n            np.concatenate([segment[:1], segment[1:][::-1]])  # partial inversion\n        ]\n\n        best_variant = segment\n        best_variant_score = float('inf')\n\n        for variant in variants:\n            candidate = np.concatenate([new_solution[:i], variant, new_solution[j+1:]])\n\n            if len(np.unique(candidate)) != n:\n                continue\n\n            candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            # Adaptive trade-off consideration\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (candidate_cost1 < current_cost1 and candidate_cost2 <= current_cost2 * 1.1) or \\\n               (candidate_cost2 < current_cost2 and candidate_cost1 <= current_cost1 * 1.1):\n                score = 0.7 * candidate_cost1 + 0.3 * candidate_cost2 if candidate_cost1 > candidate_cost2 else 0.3 * candidate_cost1 + 0.7 * candidate_cost2\n                if score < best_variant_score:\n                    best_variant_score = score\n                    best_variant = variant\n\n        if best_variant_score < float('inf'):\n            new_solution = np.concatenate([new_solution[:i], best_variant, new_solution[j+1:]])\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 305,
          "algorithm": "{The new algorithm combines a multi-objective solution clustering approach with a dynamic tour segmentation and reassembly strategy that adaptively identifies and preserves high-quality node sequences from promising solutions, while intelligently breaking them into segments based on their contribution to both objectives and then intelligently reconnecting them through a constrained node sequence transformation mechanism that prioritizes segments based on their contribution to both objectives, using a hybrid multi-criteria evaluation to guide the reassembly process while maintaining solution feasibility by ensuring proper node connectivity and tour closure through a guided segment rotation and merging mechanism that adaptively adjusts the segment size and merge position based on the current trade-off between objectives, incorporating a novel edge inversion technique that considers both local topology and global objective trade-offs, and further enhanced by a dynamic objective-space partitioning approach that selects solutions from regions of the Pareto front that show potential for improvement in both objectives simultaneously.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Multi-objective solution clustering and selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-6)\n    cluster_centers = np.array([[0.2, 0.8], [0.5, 0.5], [0.8, 0.2], [0.3, 0.7], [0.7, 0.3]])\n    distances = np.linalg.norm(normalized_obj[:, None] - cluster_centers, axis=2)\n    cluster_assignments = np.argmin(distances, axis=1)\n\n    # Select from the most promising cluster (middle cluster)\n    cluster_indices = np.where(cluster_assignments == 1)[0]\n    if len(cluster_indices) > 0:\n        selected_idx = np.random.choice(cluster_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Dynamic tour segmentation with adaptive segment size\n    for _ in range(5):\n        segment_size = np.random.randint(2, min(5, n // 4))\n        start = np.random.randint(0, n - segment_size)\n        end = start + segment_size\n        segment = base_solution[start:end]\n\n        # Evaluate segment contribution using hybrid criteria\n        segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n        total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n        # Hybrid importance weighting\n        weight1 = segment_cost1 / (total_cost1 + 1e-6)\n        weight2 = segment_cost2 / (total_cost2 + 1e-6)\n        hybrid_weight = 0.5 * weight1 + 0.5 * weight2\n\n        # Remove segment and find best merge position\n        temp_solution = np.concatenate([base_solution[:start], base_solution[end:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for i in range(len(temp_solution)):\n            # Try inserting segment at position i and its rotation variants\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(temp_solution, i, rotated_segment)\n\n                candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                score = hybrid_weight * candidate_cost1 + (1 - hybrid_weight) * candidate_cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n                    best_candidate = candidate\n\n        if best_pos != -1:\n            new_solution = best_candidate\n\n    # Adaptive edge inversion with dynamic trade-off consideration\n    for _ in range(4):\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n\n        # Consider edge inversion variants\n        variants = [\n            segment[::-1],  # standard inversion\n            np.roll(segment, 1),  # left rotation\n            np.roll(segment, -1),  # right rotation\n            np.concatenate([segment[:1], segment[1:][::-1]])  # partial inversion\n        ]\n\n        best_variant = segment\n        best_variant_score = float('inf')\n\n        for variant in variants:\n            candidate = np.concatenate([new_solution[:i], variant, new_solution[j+1:]])\n\n            if len(np.unique(candidate)) != n:\n                continue\n\n            candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            # Dynamic trade-off consideration\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (candidate_cost1 < current_cost1 and candidate_cost2 <= current_cost2 * 1.05) or \\\n               (candidate_cost2 < current_cost2 and candidate_cost1 <= current_cost1 * 1.05):\n                score = 0.6 * candidate_cost1 + 0.4 * candidate_cost2 if candidate_cost1 > candidate_cost2 else 0.4 * candidate_cost1 + 0.6 * candidate_cost2\n                if score < best_variant_score:\n                    best_variant_score = score\n                    best_variant = variant\n\n        if best_variant_score < float('inf'):\n            new_solution = np.concatenate([new_solution[:i], best_variant, new_solution[j+1:]])\n\n    # Dynamic objective-space partitioning refinement\n    objectives = np.array([sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n                          sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))])\n    normalized_obj = objectives / (np.max(objectives) + 1e-6)\n\n    # Apply small perturbation based on objective space position\n    if normalized_obj[0] > 0.7 and normalized_obj[1] < 0.3:\n        # Solution is biased towards first objective, try to improve second objective\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    elif normalized_obj[1] > 0.7 and normalized_obj[0] < 0.3:\n        # Solution is biased towards second objective, try to improve first objective\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
          "score": [
               7.012428111255211,
               4.957936909491791
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Multi-objective solution clustering and selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-6)\n    cluster_centers = np.array([[0.2, 0.8], [0.5, 0.5], [0.8, 0.2], [0.3, 0.7], [0.7, 0.3]])\n    distances = np.linalg.norm(normalized_obj[:, None] - cluster_centers, axis=2)\n    cluster_assignments = np.argmin(distances, axis=1)\n\n    # Select from the most promising cluster (middle cluster)\n    cluster_indices = np.where(cluster_assignments == 1)[0]\n    if len(cluster_indices) > 0:\n        selected_idx = np.random.choice(cluster_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Dynamic tour segmentation with adaptive segment size\n    for _ in range(5):\n        segment_size = np.random.randint(2, min(5, n // 4))\n        start = np.random.randint(0, n - segment_size)\n        end = start + segment_size\n        segment = base_solution[start:end]\n\n        # Evaluate segment contribution using hybrid criteria\n        segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n        total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n        # Hybrid importance weighting\n        weight1 = segment_cost1 / (total_cost1 + 1e-6)\n        weight2 = segment_cost2 / (total_cost2 + 1e-6)\n        hybrid_weight = 0.5 * weight1 + 0.5 * weight2\n\n        # Remove segment and find best merge position\n        temp_solution = np.concatenate([base_solution[:start], base_solution[end:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for i in range(len(temp_solution)):\n            # Try inserting segment at position i and its rotation variants\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(temp_solution, i, rotated_segment)\n\n                candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                score = hybrid_weight * candidate_cost1 + (1 - hybrid_weight) * candidate_cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n                    best_candidate = candidate\n\n        if best_pos != -1:\n            new_solution = best_candidate\n\n    # Adaptive edge inversion with dynamic trade-off consideration\n    for _ in range(4):\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n\n        # Consider edge inversion variants\n        variants = [\n            segment[::-1],  # standard inversion\n            np.roll(segment, 1),  # left rotation\n            np.roll(segment, -1),  # right rotation\n            np.concatenate([segment[:1], segment[1:][::-1]])  # partial inversion\n        ]\n\n        best_variant = segment\n        best_variant_score = float('inf')\n\n        for variant in variants:\n            candidate = np.concatenate([new_solution[:i], variant, new_solution[j+1:]])\n\n            if len(np.unique(candidate)) != n:\n                continue\n\n            candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            # Dynamic trade-off consideration\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (candidate_cost1 < current_cost1 and candidate_cost2 <= current_cost2 * 1.05) or \\\n               (candidate_cost2 < current_cost2 and candidate_cost1 <= current_cost1 * 1.05):\n                score = 0.6 * candidate_cost1 + 0.4 * candidate_cost2 if candidate_cost1 > candidate_cost2 else 0.4 * candidate_cost1 + 0.6 * candidate_cost2\n                if score < best_variant_score:\n                    best_variant_score = score\n                    best_variant = variant\n\n        if best_variant_score < float('inf'):\n            new_solution = np.concatenate([new_solution[:i], best_variant, new_solution[j+1:]])\n\n    # Dynamic objective-space partitioning refinement\n    objectives = np.array([sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n                          sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))])\n    normalized_obj = objectives / (np.max(objectives) + 1e-6)\n\n    # Apply small perturbation based on objective space position\n    if normalized_obj[0] > 0.7 and normalized_obj[1] < 0.3:\n        # Solution is biased towards first objective, try to improve second objective\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    elif normalized_obj[1] > 0.7 and normalized_obj[0] < 0.3:\n        # Solution is biased towards second objective, try to improve first objective\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (high ratio of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    ratios = objectives[:, 0] / (objectives[:, 1] + 1e-6)  # Avoid division by zero\n    selected_idx = np.argmax(ratios)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: Edge exchange followed by segment reversal\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Edge exchange: Swap two edges if it improves both objectives\n    for _ in range(10):  # Limit attempts to avoid excessive computation\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n\n        # Create candidate by swapping edges\n        candidate = new_solution.copy()\n        candidate[i:j+1] = candidate[i:j+1][::-1]  # Reverse segment\n\n        # Calculate new objectives\n        old_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        new_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n        old_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        new_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n        # Accept if both objectives improve or one improves significantly\n        if (new_cost1 < old_cost1 and new_cost2 < old_cost2) or \\\n           (new_cost1 < old_cost1 * 0.95 and new_cost2 < old_cost2 * 1.05) or \\\n           (new_cost1 < old_cost1 * 1.05 and new_cost2 < old_cost2 * 0.95):\n            new_solution = candidate\n            break\n\n    # Segment reversal: Reverse a random segment if it improves the solution\n    i, j = np.random.choice(n, 2, replace=False)\n    if i > j:\n        i, j = j, i\n    candidate = new_solution.copy()\n    candidate[i:j+1] = candidate[i:j+1][::-1]\n\n    # Calculate new objectives\n    old_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    new_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n    old_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    new_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n    # Accept if both objectives improve or one improves significantly\n    if (new_cost1 < old_cost1 and new_cost2 < old_cost2) or \\\n       (new_cost1 < old_cost1 * 0.95 and new_cost2 < old_cost2 * 1.05) or \\\n       (new_cost1 < old_cost1 * 1.05 and new_cost2 < old_cost2 * 0.95):\n        new_solution = candidate\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm combines a dynamic objective-space partitioning approach with a novel hierarchical tour decomposition strategy that adaptively identifies and preserves high-quality sub-tours from promising solutions, while intelligently breaking and reconnecting them through a constrained node sequence transformation mechanism that prioritizes segments based on their contribution to both objectives, using a hybrid multi-criteria evaluation to guide the reassembly process while maintaining solution feasibility by ensuring proper node connectivity and tour closure through a guided segment rotation and merging mechanism that adaptively adjusts the segment size and merge position based on the current trade-off between objectives, incorporating a novel edge inversion technique that considers both local topology and global objective trade-offs.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Dynamic objective-space partitioning and selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-6)\n    partition_centers = np.array([[0.1, 0.9], [0.5, 0.5], [0.9, 0.1]])\n    distances = np.linalg.norm(normalized_obj[:, None] - partition_centers, axis=2)\n    partition_assignments = np.argmin(distances, axis=1)\n\n    # Select from the most promising partition (middle partition)\n    partition_indices = np.where(partition_assignments == 1)[0]\n    if len(partition_indices) > 0:\n        selected_idx = np.random.choice(partition_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Hierarchical tour decomposition with dynamic segment size\n    for _ in range(5):\n        segment_size = np.random.randint(3, min(6, n // 3))\n        start = np.random.randint(0, n - segment_size)\n        end = start + segment_size\n        segment = base_solution[start:end]\n\n        # Evaluate segment contribution using hybrid criteria\n        segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n        total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n        # Hybrid importance weighting\n        weight1 = segment_cost1 / (total_cost1 + 1e-6)\n        weight2 = segment_cost2 / (total_cost2 + 1e-6)\n        hybrid_weight = 0.6 * weight1 + 0.4 * weight2 if weight1 > weight2 else 0.4 * weight1 + 0.6 * weight2\n\n        # Remove segment and find best merge position\n        temp_solution = np.concatenate([base_solution[:start], base_solution[end:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for i in range(len(temp_solution)):\n            # Try inserting segment at position i and its rotation variants\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(temp_solution, i, rotated_segment)\n\n                candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                score = hybrid_weight * candidate_cost1 + (1 - hybrid_weight) * candidate_cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n                    best_candidate = candidate\n\n        if best_pos != -1:\n            new_solution = best_candidate\n\n    # Guided edge inversion with adaptive trade-off consideration\n    for _ in range(4):\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n\n        # Consider edge inversion variants\n        variants = [\n            segment[::-1],  # standard inversion\n            np.roll(segment, 1),  # left rotation\n            np.roll(segment, -1),  # right rotation\n            np.concatenate([segment[:1], segment[1:][::-1]])  # partial inversion\n        ]\n\n        best_variant = segment\n        best_variant_score = float('inf')\n\n        for variant in variants:\n            candidate = np.concatenate([new_solution[:i], variant, new_solution[j+1:]])\n\n            if len(np.unique(candidate)) != n:\n                continue\n\n            candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            # Adaptive trade-off consideration\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (candidate_cost1 < current_cost1 and candidate_cost2 <= current_cost2 * 1.1) or \\\n               (candidate_cost2 < current_cost2 and candidate_cost1 <= current_cost1 * 1.1):\n                score = 0.7 * candidate_cost1 + 0.3 * candidate_cost2 if candidate_cost1 > candidate_cost2 else 0.3 * candidate_cost1 + 0.7 * candidate_cost2\n                if score < best_variant_score:\n                    best_variant_score = score\n                    best_variant = variant\n\n        if best_variant_score < float('inf'):\n            new_solution = np.concatenate([new_solution[:i], best_variant, new_solution[j+1:]])\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 305,
          "algorithm": "{The new algorithm combines a multi-objective solution clustering approach with a dynamic tour segmentation and reassembly strategy that adaptively identifies and preserves high-quality node sequences from promising solutions, while intelligently breaking them into segments based on their contribution to both objectives and then intelligently reconnecting them through a constrained node sequence transformation mechanism that prioritizes segments based on their contribution to both objectives, using a hybrid multi-criteria evaluation to guide the reassembly process while maintaining solution feasibility by ensuring proper node connectivity and tour closure through a guided segment rotation and merging mechanism that adaptively adjusts the segment size and merge position based on the current trade-off between objectives, incorporating a novel edge inversion technique that considers both local topology and global objective trade-offs, and further enhanced by a dynamic objective-space partitioning approach that selects solutions from regions of the Pareto front that show potential for improvement in both objectives simultaneously.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Multi-objective solution clustering and selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-6)\n    cluster_centers = np.array([[0.2, 0.8], [0.5, 0.5], [0.8, 0.2], [0.3, 0.7], [0.7, 0.3]])\n    distances = np.linalg.norm(normalized_obj[:, None] - cluster_centers, axis=2)\n    cluster_assignments = np.argmin(distances, axis=1)\n\n    # Select from the most promising cluster (middle cluster)\n    cluster_indices = np.where(cluster_assignments == 1)[0]\n    if len(cluster_indices) > 0:\n        selected_idx = np.random.choice(cluster_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Dynamic tour segmentation with adaptive segment size\n    for _ in range(5):\n        segment_size = np.random.randint(2, min(5, n // 4))\n        start = np.random.randint(0, n - segment_size)\n        end = start + segment_size\n        segment = base_solution[start:end]\n\n        # Evaluate segment contribution using hybrid criteria\n        segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n        total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n        # Hybrid importance weighting\n        weight1 = segment_cost1 / (total_cost1 + 1e-6)\n        weight2 = segment_cost2 / (total_cost2 + 1e-6)\n        hybrid_weight = 0.5 * weight1 + 0.5 * weight2\n\n        # Remove segment and find best merge position\n        temp_solution = np.concatenate([base_solution[:start], base_solution[end:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for i in range(len(temp_solution)):\n            # Try inserting segment at position i and its rotation variants\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(temp_solution, i, rotated_segment)\n\n                candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                score = hybrid_weight * candidate_cost1 + (1 - hybrid_weight) * candidate_cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n                    best_candidate = candidate\n\n        if best_pos != -1:\n            new_solution = best_candidate\n\n    # Adaptive edge inversion with dynamic trade-off consideration\n    for _ in range(4):\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n\n        # Consider edge inversion variants\n        variants = [\n            segment[::-1],  # standard inversion\n            np.roll(segment, 1),  # left rotation\n            np.roll(segment, -1),  # right rotation\n            np.concatenate([segment[:1], segment[1:][::-1]])  # partial inversion\n        ]\n\n        best_variant = segment\n        best_variant_score = float('inf')\n\n        for variant in variants:\n            candidate = np.concatenate([new_solution[:i], variant, new_solution[j+1:]])\n\n            if len(np.unique(candidate)) != n:\n                continue\n\n            candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            # Dynamic trade-off consideration\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (candidate_cost1 < current_cost1 and candidate_cost2 <= current_cost2 * 1.05) or \\\n               (candidate_cost2 < current_cost2 and candidate_cost1 <= current_cost1 * 1.05):\n                score = 0.6 * candidate_cost1 + 0.4 * candidate_cost2 if candidate_cost1 > candidate_cost2 else 0.4 * candidate_cost1 + 0.6 * candidate_cost2\n                if score < best_variant_score:\n                    best_variant_score = score\n                    best_variant = variant\n\n        if best_variant_score < float('inf'):\n            new_solution = np.concatenate([new_solution[:i], best_variant, new_solution[j+1:]])\n\n    # Dynamic objective-space partitioning refinement\n    objectives = np.array([sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n                          sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))])\n    normalized_obj = objectives / (np.max(objectives) + 1e-6)\n\n    # Apply small perturbation based on objective space position\n    if normalized_obj[0] > 0.7 and normalized_obj[1] < 0.3:\n        # Solution is biased towards first objective, try to improve second objective\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    elif normalized_obj[1] > 0.7 and normalized_obj[0] < 0.3:\n        # Solution is biased towards second objective, try to improve first objective\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
          "score": [
               7.012428111255211,
               4.957936909491791
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Multi-objective solution clustering and selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-6)\n    cluster_centers = np.array([[0.2, 0.8], [0.5, 0.5], [0.8, 0.2], [0.3, 0.7], [0.7, 0.3]])\n    distances = np.linalg.norm(normalized_obj[:, None] - cluster_centers, axis=2)\n    cluster_assignments = np.argmin(distances, axis=1)\n\n    # Select from the most promising cluster (middle cluster)\n    cluster_indices = np.where(cluster_assignments == 1)[0]\n    if len(cluster_indices) > 0:\n        selected_idx = np.random.choice(cluster_indices)\n        base_solution = archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[np.random.randint(0, len(archive))][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Dynamic tour segmentation with adaptive segment size\n    for _ in range(5):\n        segment_size = np.random.randint(2, min(5, n // 4))\n        start = np.random.randint(0, n - segment_size)\n        end = start + segment_size\n        segment = base_solution[start:end]\n\n        # Evaluate segment contribution using hybrid criteria\n        segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%len(segment)]] for i in range(len(segment)))\n        total_cost1 = sum(distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n        total_cost2 = sum(distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] for i in range(n))\n\n        # Hybrid importance weighting\n        weight1 = segment_cost1 / (total_cost1 + 1e-6)\n        weight2 = segment_cost2 / (total_cost2 + 1e-6)\n        hybrid_weight = 0.5 * weight1 + 0.5 * weight2\n\n        # Remove segment and find best merge position\n        temp_solution = np.concatenate([base_solution[:start], base_solution[end:]])\n        best_pos = -1\n        best_score = float('inf')\n\n        for i in range(len(temp_solution)):\n            # Try inserting segment at position i and its rotation variants\n            for rotation in range(len(segment)):\n                rotated_segment = np.roll(segment, rotation)\n                candidate = np.insert(temp_solution, i, rotated_segment)\n\n                candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n                score = hybrid_weight * candidate_cost1 + (1 - hybrid_weight) * candidate_cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n                    best_candidate = candidate\n\n        if best_pos != -1:\n            new_solution = best_candidate\n\n    # Adaptive edge inversion with dynamic trade-off consideration\n    for _ in range(4):\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n\n        # Consider edge inversion variants\n        variants = [\n            segment[::-1],  # standard inversion\n            np.roll(segment, 1),  # left rotation\n            np.roll(segment, -1),  # right rotation\n            np.concatenate([segment[:1], segment[1:][::-1]])  # partial inversion\n        ]\n\n        best_variant = segment\n        best_variant_score = float('inf')\n\n        for variant in variants:\n            candidate = np.concatenate([new_solution[:i], variant, new_solution[j+1:]])\n\n            if len(np.unique(candidate)) != n:\n                continue\n\n            candidate_cost1 = sum(distance_matrix_1[candidate[k], candidate[(k+1)%n]] for k in range(n))\n            candidate_cost2 = sum(distance_matrix_2[candidate[k], candidate[(k+1)%n]] for k in range(n))\n\n            # Dynamic trade-off consideration\n            current_cost1 = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n            if (candidate_cost1 < current_cost1 and candidate_cost2 <= current_cost2 * 1.05) or \\\n               (candidate_cost2 < current_cost2 and candidate_cost1 <= current_cost1 * 1.05):\n                score = 0.6 * candidate_cost1 + 0.4 * candidate_cost2 if candidate_cost1 > candidate_cost2 else 0.4 * candidate_cost1 + 0.6 * candidate_cost2\n                if score < best_variant_score:\n                    best_variant_score = score\n                    best_variant = variant\n\n        if best_variant_score < float('inf'):\n            new_solution = np.concatenate([new_solution[:i], best_variant, new_solution[j+1:]])\n\n    # Dynamic objective-space partitioning refinement\n    objectives = np.array([sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n                          sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))])\n    normalized_obj = objectives / (np.max(objectives) + 1e-6)\n\n    # Apply small perturbation based on objective space position\n    if normalized_obj[0] > 0.7 and normalized_obj[1] < 0.3:\n        # Solution is biased towards first objective, try to improve second objective\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    elif normalized_obj[1] > 0.7 and normalized_obj[0] < 0.3:\n        # Solution is biased towards second objective, try to improve first objective\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n"
     }
]