[
     {
          "algorithm": "{This new algorithm will select a solution from the archive based on a hybrid selection criterion that combines objective values and solution diversity, then apply a novel \"objective-aware segment rotation\" operator that rotates a randomly selected segment of the tour by a variable number of positions, with acceptance based on Pareto dominance or significant improvement in one objective while allowing controlled worsening in the other, ensuring feasibility by maintaining node uniqueness and completeness throughout the operation.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Hybrid selection: balance between objective values and solution diversity\n    archive.sort(key=lambda x: -(x[1][0] * 0.6 + x[1][1] * 0.4 + random.random() * 0.1))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Objective-aware segment rotation\n    for _ in range(5):\n        i, j = sorted(random.sample(range(n), 2))\n        k = random.randint(1, j - i) if j - i > 1 else 1\n\n        # Calculate cost before rotation\n        cost1_before = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n        cost2_before = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n\n        # Rotate the segment\n        temp_sol = new_solution.copy()\n        segment = temp_sol[i:j+1]\n        rotated = np.concatenate([segment[k:], segment[:k]])\n        temp_sol[i:j+1] = rotated\n\n        # Calculate cost after rotation\n        cost1_after = sum(distance_matrix_1[temp_sol[k-1], temp_sol[k]] for k in range(i, j+1))\n        cost2_after = sum(distance_matrix_2[temp_sol[k-1], temp_sol[k]] for k in range(i, j+1))\n\n        # Accept if Pareto dominates or significant improvement in one objective with controlled worsening in the other\n        if (cost1_after < cost1_before and cost2_after <= cost2_before) or \\\n           (cost1_after <= cost1_before and cost2_after < cost2_before) or \\\n           (cost1_after < 0.9 * cost1_before and cost2_after < 1.1 * cost2_before) or \\\n           (cost2_after < 0.9 * cost2_before and cost1_after < 1.1 * cost1_before):\n            new_solution = temp_sol\n\n    # Ensure solution validity\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               -0.9910556685809437,
               0.7008278965950012
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive based on a novel multi-objective dominance metric that balances improvement potential in both objectives, then applies a hybrid local search operator that combines a dynamic path decomposition approach with a guided multi-segment relocation strategy, which intelligently reallocates segments of the tour between critical path components while maintaining feasibility, and finally incorporates an adaptive edge insertion mechanism that selectively inserts new edges between high-potential nodes while considering the trade-off between the two objectives through a probabilistic acceptance criterion.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select the most promising solution using a dominance-based metric\n    def dominance_metric(obj):\n        return -np.sqrt(obj[0]**2 + obj[1]**2)  # Negative for minimization\n\n    archive.sort(key=lambda x: dominance_metric(x[1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic path decomposition and segment relocation\n    if n > 3:\n        # Identify critical path components\n        critical_nodes = set()\n        for i in range(n):\n            node = base_solution[i]\n            prev_node = base_solution[i-1]\n            next_node = base_solution[(i+1)%n]\n\n            # Identify nodes that are critical in either objective\n            if (distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] > np.mean(distance_matrix_1) or\n                distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] > np.mean(distance_matrix_2)):\n                critical_nodes.add(node)\n\n        # Decompose the path into segments\n        segments = []\n        current_segment = [base_solution[0]]\n        for i in range(1, n):\n            if base_solution[i] in critical_nodes and len(current_segment) > 1:\n                segments.append(current_segment)\n                current_segment = [base_solution[i]]\n            else:\n                current_segment.append(base_solution[i])\n        segments.append(current_segment)\n\n        # Relocate segments between critical components\n        if len(segments) > 1:\n            seg_idx = random.randint(0, len(segments)-1)\n            segment = segments.pop(seg_idx)\n            insert_pos = random.randint(0, len(segments)-1)\n            segments.insert(insert_pos, segment)\n\n            # Reconstruct the solution\n            new_solution = np.concatenate(segments)\n\n    # Step 3: Adaptive edge insertion mechanism\n    if n > 3:\n        # Identify high-potential insertion points\n        insertion_points = []\n        for i in range(n):\n            node = new_solution[i]\n            next_node = new_solution[(i+1)%n]\n\n            # Potential insertion points are between non-critical nodes\n            if node not in critical_nodes and next_node not in critical_nodes:\n                insertion_points.append((i, (i+1)%n))\n\n        if insertion_points:\n            # Select a random insertion point\n            i, j = random.choice(insertion_points)\n\n            # Find a high-potential node to insert\n            candidate_nodes = list(set(range(n)) - set(new_solution))\n            if candidate_nodes:\n                new_node = random.choice(candidate_nodes)\n\n                # Calculate potential improvement\n                current_cost1 = distance_matrix_1[new_solution[i], new_solution[j]]\n                current_cost2 = distance_matrix_2[new_solution[i], new_solution[j]]\n\n                new_cost1 = (distance_matrix_1[new_solution[i], new_node] +\n                             distance_matrix_1[new_node, new_solution[j]])\n                new_cost2 = (distance_matrix_2[new_solution[i], new_node] +\n                             distance_matrix_2[new_node, new_solution[j]])\n\n                # Accept with probability based on improvement\n                improvement1 = current_cost1 - new_cost1\n                improvement2 = current_cost2 - new_cost2\n\n                if (improvement1 > 0 and improvement2 > 0) or \\\n                   (random.random() < 0.5 and (improvement1 > 0 or improvement2 > 0)):\n                    new_solution = np.insert(new_solution, j, new_node)\n\n    # Ensure solution validity\n    if len(np.unique(new_solution)) != n:\n        # Simple repair: reinsert missing nodes at random positions\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            pos = random.randint(0, len(new_solution))\n            new_solution = np.insert(new_solution, pos, node)\n\n    return new_solution\n\n",
          "score": [
               -1.0196944403878097,
               0.9443355202674866
          ]
     },
     {
          "algorithm": "{The new algorithm identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive segment crossover operator that dynamically determines segment lengths based on the relative costs of the two objectives, followed by a guided multi-edge swap heuristic that selectively exchanges edges between the two tours while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space. However, this new approach introduces a dynamic objective weighting mechanism that adapts during the search process based on the current Pareto front, and incorporates a novel \"multi-objective path relinking\" operator that combines features from multiple elite solutions to create a more diverse and high-quality neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic objective weighting mechanism\n    weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n    weight2 = 1 - weight1\n\n    # Step 3: Multi-objective path relinking operator\n    if n > 3:\n        # Select two elite solutions from the archive\n        elite_indices = sorted(range(len(archive)), key=lambda i: -(archive[i][1][0] + archive[i][1][1]))\n        elite1 = archive[elite_indices[0]][0]\n        elite2 = archive[elite_indices[1]][0] if len(elite_indices) > 1 else elite1\n\n        # Create a path between the two elite solutions\n        common_nodes = set(elite1) & set(elite2)\n        if len(common_nodes) > 0:\n            # Find the longest common subsequence\n            lcs = []\n            for node in elite1:\n                if node in common_nodes:\n                    lcs.append(node)\n                    common_nodes.remove(node)\n                    if not common_nodes:\n                        break\n\n            # Reconstruct solution by combining features from both elite solutions\n            new_solution = np.array(lcs)\n            remaining_nodes = [node for node in elite1 if node not in lcs] + [node for node in elite2 if node not in lcs]\n\n            # Insert remaining nodes based on weighted distance\n            for node in remaining_nodes:\n                best_pos = 0\n                best_score = float('inf')\n\n                for i in range(len(new_solution)):\n                    prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                    next_node = new_solution[i]\n\n                    cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                    cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                    score = weight1 * cost1 + weight2 * cost2\n\n                    if score < best_score:\n                        best_score = score\n                        best_pos = i\n\n                new_solution = np.insert(new_solution, best_pos, node)\n\n    # Step 4: Adaptive segment crossover with dynamic segment lengths\n    if n > 3:\n        # Adjust segment lengths based on current weights and solution quality\n        seg_length1 = max(2, min(5, int(weight1 * n * (1 + 0.1 * random.random()))))\n        seg_length2 = max(2, min(5, int(weight2 * n * (1 + 0.1 * random.random()))))\n\n        start1 = random.randint(0, n - seg_length1)\n        start2 = random.randint(0, n - seg_length2)\n\n        temp_sol = new_solution.copy()\n        temp_sol[start1:start1+seg_length1], temp_sol[start2:start2+seg_length2] = \\\n            temp_sol[start2:start2+seg_length2].copy(), temp_sol[start1:start1+seg_length1].copy()\n\n        # Accept if both objectives improve or if one improves significantly\n        current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n        current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n        new_cost1 = sum(distance_matrix_1[temp_sol[i-1], temp_sol[i]] for i in range(n))\n        new_cost2 = sum(distance_matrix_2[temp_sol[i-1], temp_sol[i]] for i in range(n))\n\n        if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or \\\n           (new_cost1 < current_cost1 * 0.9 and new_cost2 < current_cost2 * 1.1) or \\\n           (new_cost1 < current_cost1 * 1.1 and new_cost2 < current_cost2 * 0.9):\n            new_solution = temp_sol\n\n    # Step 5: Probabilistic repair with adaptive weights\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(len(new_solution)):\n                prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                # Adjust weights based on current solution quality\n                current_weight1 = weight1 * (1 + 0.1 * random.random())\n                current_weight2 = weight2 * (1 + 0.1 * random.random())\n\n                score = current_weight1 * cost1 + current_weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.9743259273690258,
               0.6736953854560852
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive path inversion operator that dynamically determines inversion segments based on the relative costs of the two objectives, followed by a guided multi-objective node insertion heuristic that selectively inserts nodes from one tour into another while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space, while also introducing a novel adaptive path inversion operator that dynamically determines inversion segments based on the relative costs of the two objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Adaptive path inversion operator\n    if n > 3:\n        # Determine inversion segment based on relative objective weights\n        weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n        weight2 = 1 - weight1\n\n        inv_length = max(2, min(5, int(weight1 * n) if random.random() < 0.5 else int(weight2 * n)))\n\n        start = random.randint(0, n - inv_length)\n        end = start + inv_length\n\n        # Invert the segment\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Step 3: Guided multi-objective node insertion heuristic\n    if n > 3:\n        # Select a random node to insert\n        node_to_insert = random.choice(new_solution)\n\n        # Find best insertion position considering both objectives\n        best_pos = 0\n        best_score = float('inf')\n\n        for i in range(n):\n            if i > 0 and i < n:\n                prev_node = new_solution[i-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node_to_insert] + distance_matrix_1[node_to_insert, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node_to_insert] + distance_matrix_2[node_to_insert, next_node] - distance_matrix_2[prev_node, next_node]\n\n                score = weight1 * cost1 + weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n        # Insert the node\n        new_solution = np.insert(new_solution, best_pos, node_to_insert)\n\n    # Step 4: Probabilistic repair mechanism\n    if len(np.unique(new_solution)) != n:\n        # Identify missing nodes\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            # Find insertion position based on both objectives\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(n):\n                prev_node = new_solution[i-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                score = weight1 * cost1 + weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            # Insert the missing node\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.8677974261494301,
               0.18009227514266968
          ]
     },
     {
          "algorithm": "{This novel algorithm first identifies solutions in the archive with high potential for improvement by analyzing their objective trade-offs, then applies a dynamic clustering approach that groups nodes based on their relative importance across both objectives, followed by a probabilistic segment inversion mechanism that flips entire segments of the tour while maintaining feasibility, and finally incorporates a multi-objective crossover process that combines features from multiple clustered segments using a guided Pareto-based selection criterion, ensuring solution quality and diversity while preserving tour validity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify solutions with high potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic clustering based on objective trade-offs\n    if n > 5:\n        # Calculate normalized objective values\n        max_cost1 = max(x[1][0] for x in archive)\n        max_cost2 = max(x[1][1] for x in archive)\n        if max_cost1 == 0 or max_cost2 == 0:\n            return new_solution\n\n        # Cluster nodes based on their relative importance\n        cluster1 = []\n        cluster2 = []\n        for node in new_solution:\n            pos = np.where(new_solution == node)[0][0]\n            prev_node = new_solution[pos-1] if pos > 0 else new_solution[-1]\n            next_node = new_solution[(pos+1)%n]\n\n            # Calculate edge contributions\n            contrib1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node]\n            contrib2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node]\n\n            # Normalize contributions\n            norm_contrib1 = contrib1 / max_cost1\n            norm_contrib2 = contrib2 / max_cost2\n\n            # Assign to cluster based on dominance\n            if norm_contrib1 > norm_contrib2:\n                cluster1.append(node)\n            else:\n                cluster2.append(node)\n\n        # Step 3: Probabilistic segment inversion\n        if len(cluster1) > 1 and len(cluster2) > 1:\n            # Select a random segment from each cluster\n            seg1_start = random.randint(0, len(cluster1)-2)\n            seg1_length = random.randint(2, min(4, len(cluster1)-seg1_start))\n\n            seg2_start = random.randint(0, len(cluster2)-2)\n            seg2_length = random.randint(2, min(4, len(cluster2)-seg2_start))\n\n            # Find positions in the tour\n            seg1_pos = [np.where(new_solution == node)[0][0] for node in cluster1[seg1_start:seg1_start+seg1_length]]\n            seg2_pos = [np.where(new_solution == node)[0][0] for node in cluster2[seg2_start:seg2_start+seg2_length]]\n\n            # Invert segments if they don't overlap\n            if not set(seg1_pos).intersection(seg2_pos):\n                temp_sol = new_solution.copy()\n                temp_sol[min(seg1_pos):max(seg1_pos)+1] = temp_sol[min(seg1_pos):max(seg1_pos)+1][::-1]\n                temp_sol[min(seg2_pos):max(seg2_pos)+1] = temp_sol[min(seg2_pos):max(seg2_pos)+1][::-1]\n\n                # Check if solution is valid\n                if len(np.unique(temp_sol)) == n:\n                    new_solution = temp_sol\n\n        # Step 4: Multi-objective crossover\n        if len(archive) > 1:\n            # Select another solution from archive\n            other_sol = archive[random.randint(1, len(archive)-1)][0]\n\n            # Create crossover points\n            crossover1 = random.randint(1, n-2)\n            crossover2 = random.randint(crossover1+1, n-1)\n\n            # Create child solution\n            temp_sol = np.zeros_like(new_solution)\n            temp_sol[:crossover1] = new_solution[:crossover1]\n            temp_sol[crossover1:crossover2] = other_sol[crossover1:crossover2]\n            temp_sol[crossover2:] = new_solution[crossover2:]\n\n            # Repair solution if invalid\n            if len(np.unique(temp_sol)) != n:\n                missing = set(new_solution) - set(temp_sol)\n                extra = set(temp_sol) - set(new_solution)\n                for m, e in zip(missing, extra):\n                    temp_sol[np.where(temp_sol == e)[0][0]] = m\n\n            # Accept if Pareto dominates\n            cost1 = sum(distance_matrix_1[temp_sol[i-1], temp_sol[i]] for i in range(n))\n            cost2 = sum(distance_matrix_2[temp_sol[i-1], temp_sol[i]] for i in range(n))\n            if (cost1 <= archive[0][1][0] and cost2 < archive[0][1][1]) or \\\n               (cost1 < archive[0][1][0] and cost2 <= archive[0][1][1]):\n                new_solution = temp_sol\n\n    return new_solution\n\n",
          "score": [
               -0.9689141812870308,
               0.6145032644271851
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive tour reconstruction operator that dynamically partitions the tour into overlapping segments based on the relative costs of the two objectives, followed by a guided multi-objective segment permutation heuristic that selectively permutes segments within the tour while maintaining feasibility, and finally incorporates a probabilistic segment crossover mechanism to ensure solution validity by intelligently exchanging segments between solutions based on the relative importance of each objective space, while also introducing a novel adaptive segment replication operator that dynamically determines replication segments based on the relative costs of the two objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Adaptive tour reconstruction operator\n    if n > 3:\n        weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n        weight2 = 1 - weight1\n\n        # Determine segment size and overlap based on weights\n        segment_size = max(2, int(weight1 * n) if random.random() < 0.5 else int(weight2 * n))\n        overlap = max(1, int(min(weight1, weight2) * segment_size))\n\n        # Create overlapping segments\n        segments = []\n        for i in range(0, n - segment_size + 1, segment_size - overlap):\n            segments.append(new_solution[i:i+segment_size])\n\n        # Randomly permute segments\n        random.shuffle(segments)\n\n        # Reconstruct tour with permuted segments\n        new_solution = np.concatenate(segments)\n\n    # Step 3: Guided multi-objective segment permutation\n    if n > 3:\n        segment_size = max(2, n // 4)\n        start = random.randint(0, n - segment_size)\n        end = start + segment_size\n\n        segment = new_solution[start:end]\n        if random.random() < weight1:\n            # Permute segment based on first objective\n            permuted = segment.copy()\n            for i in range(len(permuted)):\n                j = random.randint(0, len(permuted)-1)\n                permuted[i], permuted[j] = permuted[j], permuted[i]\n            new_solution[start:end] = permuted\n        else:\n            # Permute segment based on second objective\n            permuted = segment.copy()\n            for i in range(len(permuted)):\n                j = random.randint(0, len(permuted)-1)\n                permuted[i], permuted[j] = permuted[j], permuted[i]\n            new_solution[start:end] = permuted\n\n    # Step 4: Probabilistic segment crossover\n    if n > 3 and random.random() < 0.4:\n        other_sol = random.choice(archive)[0]\n        segment_size = max(2, n // 5)\n        start1 = random.randint(0, n - segment_size)\n        start2 = random.randint(0, len(other_sol) - segment_size)\n\n        if random.random() < weight1:\n            # Exchange segments based on first objective\n            new_solution[start1:start1+segment_size] = other_sol[start2:start2+segment_size]\n        else:\n            # Exchange segments based on second objective\n            new_solution[start1:start1+segment_size] = other_sol[start2:start2+segment_size]\n\n    # Ensure solution validity\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            insert_pos = random.randint(0, n-1)\n            new_solution = np.insert(new_solution, insert_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.9652476544897071,
               0.24413859844207764
          ]
     },
     {
          "algorithm": "{The new algorithm begins by analyzing the archive to identify solutions with the most promising trade-off between the two objectives, then employs a novel \"objective-aware node reallocation\" strategy that dynamically redistributes nodes between the two objective spaces based on their relative importance, followed by a \"multi-objective edge contraction\" operator that selectively merges adjacent nodes while preserving feasibility, and finally incorporates an \"adaptive tour fusion\" mechanism that intelligently combines features from multiple elite solutions using a weighted consensus approach that considers both objective spaces, ensuring the generated neighbor solution maintains feasibility and explores the search space more effectively than standard approaches.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with best trade-off between objectives\n    best_idx = 0\n    best_ratio = float('inf')\n    for i, (sol, obj) in enumerate(archive):\n        ratio = max(obj[0]/(obj[1]+1e-10), obj[1]/(obj[0]+1e-10))\n        if ratio < best_ratio:\n            best_ratio = ratio\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Objective-aware node reallocation\n    if n > 3:\n        # Calculate node importance for each objective\n        node_importance1 = np.zeros(n)\n        node_importance2 = np.zeros(n)\n\n        for i in range(n):\n            prev = new_solution[i-1]\n            next_node = new_solution[(i+1)%n]\n            node_importance1[i] = distance_matrix_1[prev, new_solution[i]] + distance_matrix_1[new_solution[i], next_node]\n            node_importance2[i] = distance_matrix_2[prev, new_solution[i]] + distance_matrix_2[new_solution[i], next_node]\n\n        # Redistribute nodes based on importance\n        for i in range(n):\n            if random.random() < 0.3:  # 30% chance to reallocate\n                # Find best position considering both objectives\n                best_pos = i\n                best_score = float('inf')\n\n                for j in range(n):\n                    if j == i:\n                        continue\n\n                    # Calculate potential score\n                    prev_i = new_solution[i-1]\n                    next_i = new_solution[(i+1)%n]\n\n                    prev_j = new_solution[j-1]\n                    next_j = new_solution[(j+1)%n]\n\n                    # Current cost\n                    current_cost1 = distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                    current_cost2 = distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n\n                    # Potential new cost\n                    if i < j:\n                        # Insert after j\n                        new_cost1 = (distance_matrix_1[prev_j, new_solution[i]] + distance_matrix_1[new_solution[i], next_j] -\n                                    distance_matrix_1[prev_j, next_j])\n                        new_cost2 = (distance_matrix_2[prev_j, new_solution[i]] + distance_matrix_2[new_solution[i], next_j] -\n                                    distance_matrix_2[prev_j, next_j])\n                    else:\n                        # Insert before j\n                        new_cost1 = (distance_matrix_1[prev_i, next_i] - distance_matrix_1[prev_i, new_solution[i]] -\n                                    distance_matrix_1[new_solution[i], next_i] + distance_matrix_1[prev_i, new_solution[i]] +\n                                    distance_matrix_1[new_solution[i], new_solution[j]] + distance_matrix_1[new_solution[j], next_i])\n                        new_cost2 = (distance_matrix_2[prev_i, next_i] - distance_matrix_2[prev_i, new_solution[i]] -\n                                    distance_matrix_2[new_solution[i], next_i] + distance_matrix_2[prev_i, new_solution[i]] +\n                                    distance_matrix_2[new_solution[i], new_solution[j]] + distance_matrix_2[new_solution[j], next_i])\n\n                    # Weighted score\n                    weight1 = node_importance1[i] / (node_importance1[i] + node_importance2[i] + 1e-10)\n                    weight2 = 1 - weight1\n\n                    score = weight1 * new_cost1 + weight2 * new_cost2\n\n                    if score < best_score:\n                        best_score = score\n                        best_pos = j\n\n                # Perform the move\n                if best_pos != i:\n                    node = new_solution[i]\n                    new_solution = np.delete(new_solution, i)\n                    new_solution = np.insert(new_solution, best_pos, node)\n\n    # Step 3: Multi-objective edge contraction\n    if n > 4:\n        for _ in range(2):  # Try 2 contractions\n            i = random.randint(0, n-1)\n            j = (i + random.randint(2, min(4, n-1))) % n\n\n            # Calculate contraction cost\n            prev_i = new_solution[i-1]\n            next_i = new_solution[(i+1)%n]\n            prev_j = new_solution[j-1]\n            next_j = new_solution[(j+1)%n]\n\n            # Current cost\n            current_cost1 = (distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i] +\n                            distance_matrix_1[prev_j, new_solution[j]] + distance_matrix_1[new_solution[j], next_j])\n            current_cost2 = (distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i] +\n                            distance_matrix_2[prev_j, new_solution[j]] + distance_matrix_2[new_solution[j], next_j])\n\n            # Potential new cost\n            new_cost1 = (distance_matrix_1[prev_i, new_solution[j]] + distance_matrix_1[new_solution[j], next_i] -\n                        distance_matrix_1[prev_i, new_solution[i]] - distance_matrix_1[new_solution[i], next_i])\n            new_cost2 = (distance_matrix_2[prev_i, new_solution[j]] + distance_matrix_2[new_solution[j], next_i] -\n                        distance_matrix_2[prev_i, new_solution[i]] - distance_matrix_2[new_solution[i], next_i])\n\n            # Accept if both objectives improve\n            if new_cost1 < current_cost1 and new_cost2 < current_cost2:\n                # Contract the edges\n                if i < j:\n                    new_solution = np.delete(new_solution, slice(i+1, j))\n                else:\n                    new_solution = np.delete(new_solution, slice(i+1, n))\n                    new_solution = np.delete(new_solution, slice(0, j))\n                n = len(new_solution)\n\n    # Step 4: Adaptive tour fusion\n    if len(archive) > 1 and n > 3:\n        # Select another elite solution\n        elite_indices = sorted(range(len(archive)), key=lambda i: archive[i][1][0] + archive[i][1][1])\n        elite_idx = elite_indices[1] if len(elite_indices) > 1 else elite_indices[0]\n        elite_solution = archive[elite_idx][0]\n\n        # Create a weighted consensus tour\n        consensus = []\n        i = j = 0\n        while i < n and j < len(elite_solution):\n            if new_solution[i] == elite_solution[j]:\n                consensus.append(new_solution[i])\n                i += 1\n                j += 1\n            else:\n                # Choose based on importance\n                weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n                weight2 = 1 - weight1\n\n                if random.random() < weight1:\n                    consensus.append(new_solution[i])\n                    i += 1\n                else:\n                    consensus.append(elite_solution[j])\n                    j += 1\n\n        # Add remaining nodes\n        consensus.extend(new_solution[i:])\n        consensus.extend(elite_solution[j:])\n\n        # Remove duplicates while preserving order\n        seen = set()\n        unique_consensus = []\n        for node in consensus:\n            if node not in seen:\n                seen.add(node)\n                unique_consensus.append(node)\n\n        new_solution = np.array(unique_consensus[:n])\n\n    # Ensure solution is valid\n    if len(np.unique(new_solution)) != n:\n        # Reconstruct solution from scratch\n        remaining = list(range(n))\n        new_solution = np.zeros(n, dtype=int)\n        new_solution[0] = remaining.pop(random.randint(0, len(remaining)-1))\n\n        for i in range(1, n):\n            best_node = None\n            best_score = float('inf')\n\n            for node in remaining:\n                prev_node = new_solution[i-1]\n                cost1 = distance_matrix_1[prev_node, node]\n                cost2 = distance_matrix_2[prev_node, node]\n\n                weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n                weight2 = 1 - weight1\n\n                score = weight1 * cost1 + weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_node = node\n\n            new_solution[i] = best_node\n            remaining.remove(best_node)\n\n    return new_solution\n\n",
          "score": [
               -0.9967708161998995,
               5.318395137786865
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive segment crossover operator that dynamically determines segment lengths based on the relative costs of the two objectives, followed by a guided multi-edge swap heuristic that selectively exchanges edges between the two tours while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on non-dominated sorting\n    front = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            front.append(i)\n\n    if not front:\n        front = [0]  # Fallback to first solution if no non-dominated solutions\n\n    best_idx = random.choice(front)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Adaptive segment crossover with objective-aware segment selection\n    if n > 3:\n        obj1, obj2 = archive[best_idx][1]\n        total_obj = obj1 + obj2\n        if total_obj == 0:\n            weight1, weight2 = 0.5, 0.5\n        else:\n            weight1 = obj1 / total_obj\n            weight2 = obj2 / total_obj\n\n        seg_length = max(2, min(5, int(weight1 * n)))\n        start = random.randint(0, n - seg_length)\n\n        # Create a new segment by combining nodes from both objectives\n        new_segment = []\n        for i in range(seg_length):\n            if random.random() < weight1:\n                new_segment.append(new_solution[(start + i) % n])\n            else:\n                new_segment.append(new_solution[(start + i + seg_length) % n])\n\n        new_solution[start:start+seg_length] = new_segment\n\n    # Step 3: Multi-objective edge insertion heuristic\n    if n > 3:\n        # Select a random edge to remove\n        i = random.randint(0, n-1)\n        removed_node = new_solution[i]\n\n        # Find best insertion position considering both objectives\n        best_pos = 0\n        best_score = float('inf')\n\n        for j in range(n-1):\n            if j == i or j == (i-1) % n:\n                continue\n\n            prev_node = new_solution[j]\n            next_node = new_solution[(j+1) % n]\n\n            cost1 = distance_matrix_1[prev_node, removed_node] + distance_matrix_1[removed_node, next_node] - distance_matrix_1[prev_node, next_node]\n            cost2 = distance_matrix_2[prev_node, removed_node] + distance_matrix_2[removed_node, next_node] - distance_matrix_2[prev_node, next_node]\n\n            score = weight1 * cost1 + weight2 * cost2\n\n            if score < best_score:\n                best_score = score\n                best_pos = j + 1\n\n        # Insert the removed node at the best position\n        new_solution = np.insert(new_solution, best_pos, removed_node)\n        if best_pos <= i:\n            new_solution = np.delete(new_solution, i+1)\n        else:\n            new_solution = np.delete(new_solution, i)\n\n    # Step 4: Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = random.randint(0, n-1)\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.44041365474180505,
               0.18295890092849731
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by selecting the one with the highest combined improvement potential, then applies a novel adaptive segment reversal operator that dynamically determines reversal segments based on the relative costs of the two objectives, followed by a guided multi-objective edge contraction heuristic that selectively contracts edges between nodes while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space, while also introducing a dynamic objective weighting mechanism that adapts during the search process based on the current Pareto front, and incorporating a novel \"multi-objective path merging\" operator that combines features from multiple elite solutions to create a more diverse and high-quality neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic objective weighting mechanism\n    weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n    weight2 = 1 - weight1\n\n    # Step 3: Adaptive segment reversal operator\n    if n > 3:\n        # Determine reversal segment based on relative objective weights\n        seg_length = max(2, min(5, int(weight1 * n) if random.random() < 0.5 else int(weight2 * n)))\n\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n\n        # Reverse the segment\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Step 4: Multi-objective edge contraction heuristic\n    if n > 4:\n        # Select two consecutive nodes to potentially contract\n        i = random.randint(0, n - 2)\n        node1, node2 = new_solution[i], new_solution[i+1]\n\n        # Calculate potential contraction cost\n        cost1 = distance_matrix_1[node1, node2]\n        cost2 = distance_matrix_2[node1, node2]\n\n        # Calculate current cost of the edges\n        prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n        next_node = new_solution[(i+2) % n]\n\n        current_cost1 = distance_matrix_1[prev_node, node1] + distance_matrix_1[node1, node2] + distance_matrix_1[node2, next_node]\n        current_cost2 = distance_matrix_2[prev_node, node1] + distance_matrix_2[node1, node2] + distance_matrix_2[node2, next_node]\n\n        new_cost1 = distance_matrix_1[prev_node, node2] + distance_matrix_1[node2, next_node]\n        new_cost2 = distance_matrix_2[prev_node, node2] + distance_matrix_2[node2, next_node]\n\n        # Calculate improvement\n        improvement1 = current_cost1 - new_cost1\n        improvement2 = current_cost2 - new_cost2\n\n        # Accept if both objectives improve or if one improves significantly\n        if (improvement1 > 0 and improvement2 > 0) or \\\n           (improvement1 > 0.1 * current_cost1 and improvement2 > -0.1 * current_cost2) or \\\n           (improvement1 > -0.1 * current_cost1 and improvement2 > 0.1 * current_cost2):\n            # Contract the edge by removing node1 and connecting prev_node to node2\n            new_solution = np.delete(new_solution, i)\n\n    # Step 5: Multi-objective path merging operator\n    if n > 3 and len(archive) > 1:\n        # Select another elite solution\n        elite_indices = sorted(range(len(archive)), key=lambda i: -(archive[i][1][0] + archive[i][1][1]))\n        elite2 = archive[elite_indices[min(1, len(elite_indices)-1)]][0]\n\n        # Find common nodes\n        common_nodes = set(new_solution) & set(elite2)\n        if len(common_nodes) > 0:\n            # Create merged path\n            merged_path = []\n            i, j = 0, 0\n\n            while i < len(new_solution) and j < len(elite2):\n                if new_solution[i] == elite2[j]:\n                    merged_path.append(new_solution[i])\n                    i += 1\n                    j += 1\n                elif new_solution[i] in common_nodes and elite2[j] in common_nodes:\n                    # Choose based on weighted distance\n                    cost1 = distance_matrix_1[merged_path[-1], new_solution[i]] if merged_path else 0\n                    cost2 = distance_matrix_2[merged_path[-1], new_solution[i]] if merged_path else 0\n                    score1 = weight1 * cost1 + weight2 * cost2\n\n                    cost1 = distance_matrix_1[merged_path[-1], elite2[j]] if merged_path else 0\n                    cost2 = distance_matrix_2[merged_path[-1], elite2[j]] if merged_path else 0\n                    score2 = weight1 * cost1 + weight2 * cost2\n\n                    if score1 < score2:\n                        merged_path.append(new_solution[i])\n                        i += 1\n                    else:\n                        merged_path.append(elite2[j])\n                        j += 1\n                elif new_solution[i] in common_nodes:\n                    merged_path.append(new_solution[i])\n                    i += 1\n                else:\n                    merged_path.append(elite2[j])\n                    j += 1\n\n            # Add remaining nodes\n            merged_path.extend(new_solution[i:])\n            merged_path.extend(elite2[j:])\n\n            # Update solution\n            new_solution = np.array(merged_path)\n\n    # Step 6: Probabilistic repair mechanism\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(len(new_solution)):\n                prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                # Adjust weights based on current solution quality\n                current_weight1 = weight1 * (1 + 0.1 * random.random())\n                current_weight2 = weight2 * (1 + 0.1 * random.random())\n\n                score = current_weight1 * cost1 + current_weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.9640835146920266,
               0.3065415024757385
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive objective-aware tour fragmentation and reassembly operator that dynamically partitions the tour into non-overlapping segments based on the relative costs of the two objectives, followed by a guided multi-objective segment rotation heuristic that selectively rotates segments within the tour while maintaining feasibility, and finally incorporates a probabilistic segment merging mechanism to ensure solution validity by intelligently combining segments or resolving conflicts based on the relative importance of each objective space, while also introducing a novel adaptive segment insertion operator that dynamically determines insertion points based on the relative costs of the two objectives and then intelligently merges segments to create new segments that balance the trade-off between the two objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Adaptive objective-aware tour fragmentation\n    if n > 3:\n        obj1, obj2 = archive[best_idx][1]\n        total_obj = obj1 + obj2\n        if total_obj == 0:\n            weight1, weight2 = 0.5, 0.5\n        else:\n            weight1 = obj1 / total_obj\n            weight2 = obj2 / total_obj\n\n        # Determine number of segments based on weights\n        num_segments = max(2, min(5, int(weight1 * n) if random.random() < 0.5 else int(weight2 * n)))\n\n        # Split tour into segments\n        segment_size = n // num_segments\n        segments = [new_solution[i*segment_size:(i+1)*segment_size] for i in range(num_segments)]\n\n        # Step 3: Guided multi-objective segment rotation\n        for i in range(len(segments)):\n            if random.random() < weight1:\n                rotate_pos = random.randint(1, len(segments[i])-1)\n                segments[i] = np.concatenate([segments[i][rotate_pos:], segments[i][:rotate_pos]])\n\n        # Reassemble tour\n        new_solution = np.concatenate(segments)\n\n    # Step 4: Probabilistic segment merging\n    if n > 3 and random.random() < 0.3:\n        # Select two random segments\n        segment_size = max(2, n // 5)\n        start1 = random.randint(0, n - segment_size)\n        start2 = random.randint(0, n - segment_size)\n\n        # Determine merge direction based on objectives\n        if random.random() < weight1:\n            # Merge first segment into second\n            merged = np.concatenate([new_solution[start1:start1+segment_size], new_solution[start2:start2+segment_size]])\n            new_solution = np.concatenate([new_solution[:start2], merged, new_solution[start2+segment_size:]])\n        else:\n            # Merge second segment into first\n            merged = np.concatenate([new_solution[start2:start2+segment_size], new_solution[start1:start1+segment_size]])\n            new_solution = np.concatenate([new_solution[:start1], merged, new_solution[start1+segment_size:]])\n\n    # Step 5: Adaptive segment insertion\n    if n > 3 and random.random() < 0.2:\n        # Select a segment to insert\n        segment_size = max(2, n // 5)\n        start = random.randint(0, n - segment_size)\n        inserted_segment = new_solution[start:start+segment_size]\n\n        # Determine insertion point based on objectives\n        insert_pos = random.randint(0, n - segment_size)\n\n        # Insert based on objectives\n        if random.random() < weight1:\n            new_solution = np.concatenate([new_solution[:insert_pos], inserted_segment, new_solution[insert_pos:]])\n        else:\n            new_solution = np.concatenate([new_solution[:insert_pos], inserted_segment[::-1], new_solution[insert_pos:]])\n\n    # Ensure solution validity\n    if len(np.unique(new_solution)) != n:\n        # Reconstruct solution if invalid\n        new_solution = np.random.permutation(n)\n\n    return new_solution\n\n",
          "score": [
               -0.8428047649979995,
               0.29560166597366333
          ]
     }
]