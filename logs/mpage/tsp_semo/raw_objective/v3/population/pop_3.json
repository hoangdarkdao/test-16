[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the lowest sum of normalized objectives (promising for improvement)\n    normalized_objectives = [(obj[0] / (obj[0] + obj[1] + 1e-10), obj[1] / (obj[0] + obj[1] + 1e-10)) for _, obj in archive]\n    scores = [sum(norm_obj) for norm_obj in normalized_objectives]\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine 3-opt with a novel move that considers both objectives\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Randomly select two segments to modify\n    i, j = sorted(np.random.choice(range(1, n-1), 2, replace=False))\n    k = np.random.randint(1, n-1)\n\n    # Novel move: reverse segment between i and j, then insert segment between k and k+1\n    segment = new_solution[i:j+1]\n    new_solution = np.concatenate([new_solution[:i], new_solution[j+1:k+1], segment, new_solution[k+1:]])\n\n    # Ensure feasibility by checking for duplicates (shouldn't happen due to segment insertion)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if the move is invalid\n        a, b = np.random.choice(range(1, n-1), 2, replace=False)\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    return new_solution\n\n",
          "score": [
               6.343084386472292,
               6.398679333078661
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its potential for improvement\n    scores = []\n    for sol, _ in archive:\n        # Calculate diversity score (number of unique edges not in other solutions)\n        diversity = 0\n        edges = set(zip(sol, np.roll(sol, -1)))\n        for other_sol, _ in archive:\n            other_edges = set(zip(other_sol, np.roll(other_sol, -1)))\n            diversity += len(edges - other_edges)\n        scores.append(diversity)\n\n    if all(s == 0 for s in scores):\n        # If all solutions are identical, select randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Normalize scores and select with probability\n        total = sum(scores)\n        probs = [s / total for s in scores]\n        idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search strategy\n    if random.random() < 0.7:  # 70% chance for segment relocation\n        # Select segment length based on instance size\n        max_segment = min(5, n // 4)\n        segment_length = random.randint(2, max_segment)\n\n        # Select random segment\n        start = random.randint(0, n - segment_length)\n        segment = new_solution[start:start+segment_length]\n\n        # Find best insertion position that improves both objectives\n        best_cost = float('inf')\n        best_pos = -1\n\n        for pos in range(n - segment_length + 1):\n            if pos >= start and pos < start + segment_length:\n                continue  # Skip current position\n\n            # Create candidate solution\n            candidate = np.concatenate([\n                new_solution[:pos],\n                segment,\n                new_solution[pos:start],\n                new_solution[start+segment_length:]\n            ])\n\n            # Calculate cost\n            cost1 = sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(n-1))\n            cost1 += distance_matrix_1[candidate[-1], candidate[0]]  # Complete the tour\n\n            cost2 = sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(n-1))\n            cost2 += distance_matrix_2[candidate[-1], candidate[0]]\n\n            total_cost = cost1 + cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_pos = pos\n\n        if best_pos != -1 and best_cost < float('inf'):\n            # Apply the best move\n            new_solution = np.concatenate([\n                new_solution[:best_pos],\n                segment,\n                new_solution[best_pos:start],\n                new_solution[start+segment_length:]\n            ])\n    else:  # Edge insertion\n        # Select random edge to remove\n        i = random.randint(0, n-1)\n        j = (i + 1) % n\n\n        # Select random node to insert between\n        k = random.randint(0, n-1)\n        while k == i or k == j or k == (i-1)%n:\n            k = random.randint(0, n-1)\n\n        # Create candidate solution\n        candidate = new_solution.copy()\n        candidate[i], candidate[j] = candidate[j], candidate[i]  # Reverse the edge\n        candidate = np.roll(candidate, -i)  # Make i the first element\n        candidate = np.concatenate([candidate[:1], candidate[2:k+1], candidate[1:2], candidate[k+1:]])\n        candidate = np.roll(candidate, i)  # Restore original order\n\n        # Check if the move is valid (visits all nodes exactly once)\n        if len(set(candidate)) == n:\n            new_solution = candidate\n\n    return new_solution\n\n",
          "score": [
               6.602584769458544,
               5.827298074802924
          ]
     },
     {
          "algorithm": "{The new algorithm begins by selecting a base solution from the archive using a multi-criteria approach that combines objective values, diversity, and structural features, then employs a novel hybrid local search strategy that integrates adaptive segment swapping with probabilistic edge reversal, followed by a constrained node reinsertion phase to ensure feasibility while exploring the solution space more effectively than standard methods, ultimately generating a high-quality neighbor solution that balances exploration and exploitation through dynamic parameter adaptation and objective-aware move selection.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select base solution based on combined objective and structural diversity\n    scores = []\n    for sol, (obj1, obj2) in archive:\n        # Calculate combined objective score (normalized)\n        obj_score = (obj1 + obj2) / (sum(x[1][0] + x[1][1] for x in archive) / len(archive))\n\n        # Calculate structural diversity\n        edges = set(zip(sol, np.roll(sol, -1)))\n        diversity = 0\n        for other_sol, _ in archive:\n            other_edges = set(zip(other_sol, np.roll(other_sol, -1)))\n            diversity += len(edges.symmetric_difference(other_edges))\n\n        # Combine scores with adaptive weights\n        alpha = 0.7 if len(archive) > 10 else 0.5\n        scores.append(alpha * obj_score + (1 - alpha) * diversity)\n\n    # Select solution with highest combined score\n    base_solution = archive[np.argmax(scores)][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search strategy\n    # Phase 1: Adaptive segment swapping\n    segment_length = max(3, min(7, n // 5))\n    for _ in range(2):\n        start1 = np.random.randint(0, n - segment_length)\n        start2 = np.random.randint(0, n - segment_length)\n        while abs(start1 - start2) < segment_length:\n            start2 = np.random.randint(0, n - segment_length)\n\n        # Swap segments with probability based on objective improvement\n        seg1 = new_solution[start1:start1+segment_length]\n        seg2 = new_solution[start2:start2+segment_length]\n\n        # Calculate potential improvement\n        old_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(n-1)) +\n                    distance_matrix_1[new_solution[-1], new_solution[0]] +\n                    sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(n-1)) +\n                    distance_matrix_2[new_solution[-1], new_solution[0]])\n\n        candidate = new_solution.copy()\n        candidate[start1:start1+segment_length] = seg2\n        candidate[start2:start2+segment_length] = seg1\n\n        new_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(n-1)) +\n                    distance_matrix_1[candidate[-1], candidate[0]] +\n                    sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(n-1)) +\n                    distance_matrix_2[candidate[-1], candidate[0]])\n\n        if new_cost < old_cost or np.random.random() < 0.3:\n            new_solution = candidate\n\n    # Phase 2: Probabilistic edge reversal with objective awareness\n    for _ in range(3):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        while abs(i - j) < 2:\n            j = np.random.randint(0, n)\n\n        # Calculate potential improvement\n        old_edges = [(new_solution[i-1], new_solution[i]), (new_solution[j-1], new_solution[j])]\n        new_edges = [(new_solution[i-1], new_solution[j]), (new_solution[i], new_solution[j-1])]\n\n        old_cost = (distance_matrix_1[old_edges[0][0], old_edges[0][1]] + distance_matrix_1[old_edges[1][0], old_edges[1][1]] +\n                    distance_matrix_2[old_edges[0][0], old_edges[0][1]] + distance_matrix_2[old_edges[1][0], old_edges[1][1]])\n\n        new_cost = (distance_matrix_1[new_edges[0][0], new_edges[0][1]] + distance_matrix_1[new_edges[1][0], new_edges[1][1]] +\n                    distance_matrix_2[new_edges[0][0], new_edges[0][1]] + distance_matrix_2[new_edges[1][0], new_edges[1][1]])\n\n        if new_cost < old_cost or np.random.random() < 0.2:\n            # Reverse the segment between i and j\n            new_solution[i:j] = new_solution[i:j][::-1]\n\n    # Phase 3: Constrained node reinsertion\n    for _ in range(2):\n        # Select a random node to remove\n        idx = np.random.randint(1, n-1)\n        node = new_solution[idx]\n\n        # Remove the node\n        candidate = np.concatenate([new_solution[:idx], new_solution[idx+1:]])\n\n        # Find best insertion position that minimizes both objectives\n        best_pos = -1\n        best_cost = float('inf')\n\n        for pos in range(n-1):\n            if pos == idx or pos == idx-1:\n                continue\n\n            # Insert node at position pos\n            temp = np.insert(candidate, pos, node)\n\n            # Calculate cost\n            cost1 = sum(distance_matrix_1[temp[i], temp[i+1]] for i in range(n-1))\n            cost1 += distance_matrix_1[temp[-1], temp[0]]\n\n            cost2 = sum(distance_matrix_2[temp[i], temp[i+1]] for i in range(n-1))\n            cost2 += distance_matrix_2[temp[-1], temp[0]]\n\n            total_cost = cost1 + cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_pos = pos\n\n        if best_pos != -1:\n            new_solution = np.insert(candidate, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               5.982530730904809,
               6.4238842089255845
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' employs a novel adaptive path decomposition and recombination strategy that dynamically partitions the tour into segments based on both objective spaces' characteristics, then reconstructs the tour by interleaving these segments in a way that maximizes the trade-off between the two objectives. The selection process prioritizes solutions that exhibit non-dominated segments in the Pareto front, while the local search operator uses a probabilistic segment recombination mechanism guided by a multi-objective utility function that considers the segment's contribution to both objectives. The function ensures feasibility by maintaining the permutation property through a series of carefully designed segment swaps and rotations, with the segment length and recombination pattern determined by an adaptive probability model that learns from the current solution's structure and the distance matrices.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using adaptive segment analysis\n    selected_idx = np.argmin([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive path decomposition based on both objectives\n    segment_length = np.random.randint(3, min(7, n // 2))\n    start_pos = np.random.randint(0, n - segment_length)\n\n    # Extract segment and analyze its contribution to both objectives\n    segment = new_solution[start_pos:start_pos + segment_length]\n    segment_cost1 = sum(distance_matrix_1[segment[i-1], segment[i]] for i in range(segment_length))\n    segment_cost2 = sum(distance_matrix_2[segment[i-1], segment[i]] for i in range(segment_length))\n\n    # Determine segment's Pareto dominance relative to the rest of the tour\n    total_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n    total_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n    # Probabilistic recombination based on segment's characteristics\n    if segment_cost1 / total_cost1 < 0.3 or segment_cost2 / total_cost2 < 0.3:\n        # If segment is significantly worse in one objective, consider removing it\n        new_solution = np.concatenate([new_solution[:start_pos], new_solution[start_pos + segment_length:]])\n        # Insert the segment in a different position\n        insert_pos = np.random.randint(0, len(new_solution) - segment_length + 1)\n        new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n    else:\n        # If segment is balanced, consider rotating it\n        rotation = np.random.randint(1, segment_length)\n        segment = np.roll(segment, rotation)\n        new_solution[start_pos:start_pos + segment_length] = segment\n\n    # Ensure feasibility by checking for duplicates\n    if len(np.unique(new_solution)) != n:\n        # If invalid, perform a simple swap to restore feasibility\n        a, b = np.random.choice(range(1, n-1), 2, replace=False)\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    return new_solution\n\n",
          "score": [
               6.4586950415254565,
               5.903120343468656
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' first evaluates the archive of solutions by computing their Pareto dominance relationships, then selects a promising solution with high potential for improvement using a custom selection criterion that balances objective diversity and local search potential. The selected solution undergoes a novel hybrid local search operator that combines a multi-segment inversion strategy with a guided edge exchange mechanism, where segments of varying lengths are inverted and edges are exchanged based on their contribution to reducing the total tour length in both objective spaces. The inversion length is dynamically determined using a probabilistic model that considers both the distance matrices and the current solution's structure, while the edge exchange is guided by a weighted combination of the two objectives. The function ensures feasibility by maintaining the permutation property of TSP tours throughout the local search process, and returns the improved neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search operator\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Multi-segment inversion\n    num_segments = np.random.randint(1, min(4, n // 2))\n    segment_lengths = np.random.randint(2, min(5, n // num_segments), size=num_segments)\n\n    # Ensure total length doesn't exceed n\n    total_length = np.sum(segment_lengths)\n    if total_length > n:\n        segment_lengths = (segment_lengths * (n / total_length)).astype(int)\n        segment_lengths[segment_lengths < 2] = 2\n        segment_lengths[-1] = n - np.sum(segment_lengths[:-1])\n\n    start_pos = np.random.randint(0, n - total_length + 1)\n    current_pos = start_pos\n\n    for length in segment_lengths:\n        segment = new_solution[current_pos:current_pos + length]\n        new_solution[current_pos:current_pos + length] = segment[::-1]\n        current_pos += length\n\n    # Guided edge exchange\n    for _ in range(min(3, n // 2)):\n        i, j = np.random.choice(n, size=2, replace=False)\n        if i > j:\n            i, j = j, i\n\n        # Calculate cost difference for both objectives\n        current_cost1 = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j-1], new_solution[j]]\n        current_cost2 = distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j-1], new_solution[j]]\n\n        new_cost1 = distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[j-1], new_solution[i]]\n        new_cost2 = distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[j-1], new_solution[i]]\n\n        # Weighted decision based on both objectives\n        if (new_cost1 < current_cost1 and new_cost2 <= current_cost2) or (new_cost1 <= current_cost1 and new_cost2 < current_cost2):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               6.372959628179613,
               6.543599011883715
          ]
     },
     {
          "algorithm": "{The new algorithm employs a multi-stage approach to generate high-quality neighbor solutions by first identifying the most promising solutions in the archive using a combination of dominance and diversity metrics, then applying a novel 'node clustering' strategy that groups nodes based on their spatial proximity in both objective spaces. The algorithm then performs a probabilistic 'cluster-based insertion' where segments of the tour are replaced with the best matching clusters from the original solution, followed by a 'multi-objective edge optimization' step that selectively improves edges based on Pareto dominance in the combined objective space. The method ensures feasibility by maintaining valid tour structures throughout all operations, and incorporates an adaptive acceptance criterion that balances exploration and exploitation by considering the non-dominated front of the current solution and its neighbors.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select promising solution using dominance and diversity\n    solutions = [sol for sol, _ in archive]\n    objectives = [obj for _, obj in archive]\n\n    # Calculate dominance counts\n    dominance_counts = [0] * len(solutions)\n    for i in range(len(solutions)):\n        for j in range(len(solutions)):\n            if i != j:\n                if (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1] and\n                    (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1])):\n                    dominance_counts[i] += 1\n\n    # Calculate crowding distances\n    crowding_distances = []\n    for i in range(len(objectives)):\n        obj1, obj2 = objectives[i]\n        left = (obj1, obj2)\n        right = (obj1, obj2)\n        for j in range(len(objectives)):\n            if i != j:\n                obj1_j, obj2_j = objectives[j]\n                if obj1_j <= left[0] and obj2_j <= left[1]:\n                    left = (obj1_j, obj2_j)\n                if obj1_j >= right[0] and obj2_j >= right[1]:\n                    right = (obj1_j, obj2_j)\n        crowding_distances.append((right[0] - left[0]) + (right[1] - left[1]))\n\n    # Select solution with lowest dominance count and highest crowding distance\n    scores = [-dominance_counts[i] * crowding_distances[i] for i in range(len(solutions))]\n    selected_idx = np.argmax(scores)\n    base_solution = solutions[selected_idx].copy()\n\n    # Step 2: Node clustering based on spatial proximity\n    n = len(base_solution)\n    clusters = []\n    visited = set()\n\n    for i in range(n):\n        if i not in visited:\n            cluster = [i]\n            visited.add(i)\n            for j in range(i+1, n):\n                if j not in visited:\n                    node_i = base_solution[i]\n                    node_j = base_solution[j]\n                    # Check spatial proximity in both objective spaces\n                    dist1 = np.sqrt((instance[node_i, 0] - instance[node_j, 0])**2 +\n                                   (instance[node_i, 1] - instance[node_j, 1])**2)\n                    dist2 = np.sqrt((instance[node_i, 2] - instance[node_j, 2])**2 +\n                                   (instance[node_i, 3] - instance[node_j, 3])**2)\n                    if dist1 < 10 and dist2 < 10:  # Threshold for clustering\n                        cluster.append(j)\n                        visited.add(j)\n            clusters.append(cluster)\n\n    # Step 3: Cluster-based insertion\n    new_solution = base_solution.copy()\n    for _ in range(10):\n        # Select a random cluster to move\n        cluster = clusters[np.random.randint(len(clusters))]\n        if len(cluster) < 2:\n            continue\n\n        # Remove the cluster from current position\n        cluster_nodes = [new_solution[i] for i in cluster]\n        mask = np.ones(len(new_solution), dtype=bool)\n        mask[cluster] = False\n        temp_solution = new_solution[mask]\n\n        # Find best insertion position\n        best_cost = float('inf')\n        best_pos = 0\n        for pos in range(len(temp_solution)):\n            # Insert cluster at position pos\n            candidate = np.concatenate([temp_solution[:pos], cluster_nodes, temp_solution[pos:]])\n\n            # Calculate cost difference\n            cost1 = 0\n            cost2 = 0\n            for i in range(len(candidate)):\n                prev = candidate[i-1]\n                curr = candidate[i]\n                cost1 += distance_matrix_1[prev, curr]\n                cost2 += distance_matrix_2[prev, curr]\n\n            if cost1 + cost2 < best_cost:\n                best_cost = cost1 + cost2\n                best_pos = pos\n\n        # Perform insertion\n        new_solution = np.concatenate([temp_solution[:best_pos], cluster_nodes, temp_solution[best_pos:]])\n\n    # Step 4: Multi-objective edge optimization\n    for _ in range(20):\n        # Select two random edges\n        i, j = sorted(np.random.choice(len(new_solution), 2, replace=False))\n\n        # Calculate current cost\n        prev_i = new_solution[i-1]\n        curr_i = new_solution[i]\n        next_i = new_solution[(i+1)%len(new_solution)]\n        prev_j = new_solution[j-1]\n        curr_j = new_solution[j]\n        next_j = new_solution[(j+1)%len(new_solution)]\n\n        cost1_before = (distance_matrix_1[prev_i, curr_i] + distance_matrix_1[curr_i, next_i] +\n                        distance_matrix_1[prev_j, curr_j] + distance_matrix_1[curr_j, next_j])\n        cost2_before = (distance_matrix_2[prev_i, curr_i] + distance_matrix_2[curr_i, next_i] +\n                        distance_matrix_2[prev_j, curr_j] + distance_matrix_2[curr_j, next_j])\n\n        # Calculate new cost if edges are swapped\n        cost1_after = (distance_matrix_1[prev_i, curr_j] + distance_matrix_1[curr_j, next_i] +\n                       distance_matrix_1[prev_j, curr_i] + distance_matrix_1[curr_i, next_j])\n        cost2_after = (distance_matrix_2[prev_i, curr_j] + distance_matrix_2[curr_j, next_i] +\n                       distance_matrix_2[prev_j, curr_i] + distance_matrix_2[curr_i, next_j])\n\n        # Accept if Pareto dominates\n        if ((cost1_after <= cost1_before and cost2_after <= cost2_before) and\n            (cost1_after < cost1_before or cost2_after < cost2_before)):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               7.109242367827888,
               6.685315639921361
          ]
     },
     {
          "algorithm": "{The new algorithm employs a dynamic clustering-based approach to identify promising regions in the solution space, where each cluster represents a distinct segment of the tour that could benefit from coordinated optimization across both objectives. It first partitions the current solution into variable-length segments based on the spatial proximity of nodes in both objective spaces, then applies a guided segment crossover operation where segments are exchanged between clusters while maintaining feasibility, followed by a probabilistic segment inversion that considers the relative improvement potential of each segment in both objectives, and finally refines the solution with a novel edge insertion heuristic that prioritizes edges with balanced contributions to both objectives while preserving the tour's connectivity. The algorithm dynamically adjusts the segment size and selection probability based on the current solution's structure and the distance matrices, ensuring a diverse exploration of the search space while maintaining feasibility throughout the process.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic clustering-based segment identification\n    cluster_sizes = np.random.randint(2, min(6, n//2), size=np.random.randint(2, min(4, n//3)))\n    cluster_sizes = np.clip(cluster_sizes, 2, n - np.sum(cluster_sizes[:-1]) - 1)\n    cluster_sizes[-1] = n - np.sum(cluster_sizes[:-1])\n\n    clusters = []\n    current_pos = 0\n    for size in cluster_sizes:\n        clusters.append(new_solution[current_pos:current_pos+size])\n        current_pos += size\n\n    # Guided segment crossover\n    if len(clusters) > 1:\n        i, j = np.random.choice(len(clusters), 2, replace=False)\n        temp = clusters[i].copy()\n        clusters[i] = clusters[j].copy()\n        clusters[j] = temp\n\n    # Reconstruct solution from clusters\n    new_solution = np.concatenate(clusters)\n\n    # Probabilistic segment inversion\n    for cluster in clusters:\n        if len(cluster) > 2 and np.random.random() < 0.3:\n            cluster_start = np.where(new_solution == cluster[0])[0][0]\n            new_solution[cluster_start:cluster_start+len(cluster)] = cluster[::-1]\n\n    # Novel edge insertion heuristic\n    for _ in range(min(3, n//2)):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i == j or (i+1)%n == j or (j+1)%n == i:\n            continue\n\n        # Calculate cost difference\n        current_cost1 = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j-1], new_solution[j]]\n        current_cost2 = distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j-1], new_solution[j]]\n\n        # Try inserting node j between i and i+1\n        candidate = new_solution.copy()\n        candidate = np.concatenate([candidate[:i+1], [candidate[j]], candidate[i+1:j], candidate[j+1:]])\n\n        new_cost1 = sum(distance_matrix_1[candidate[k-1], candidate[k]] for k in range(1, n))\n        new_cost2 = sum(distance_matrix_2[candidate[k-1], candidate[k]] for k in range(1, n))\n\n        # Weighted decision\n        if (new_cost1 < current_cost1 and new_cost2 <= current_cost2*1.1) or (new_cost1 <= current_cost1*1.1 and new_cost2 < current_cost2):\n            new_solution = candidate\n\n    return new_solution\n\n",
          "score": [
               6.408399447509758,
               6.971989664069907
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (higher probability for non-dominated or less crowded solutions)\n    ranks = np.array([i for i in range(len(archive))])  # Simplified rank (in practice, use proper non-dominated sorting)\n    probabilities = 1 / (1 + ranks)\n    probabilities = probabilities / np.sum(probabilities)\n    selected_idx = np.random.choice(len(archive), p=probabilities)\n    base_solution = archive[selected_idx][0].copy()\n    current_cost = archive[selected_idx][1]\n\n    # Step 2: Hybrid local search\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Segment inversion with objective-aware acceptance\n    if n > 2:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[a:b+1]\n        inverted_segment = segment[::-1]\n        candidate = np.concatenate([new_solution[:a], inverted_segment, new_solution[b+1:]])\n\n        # Calculate new cost\n        cost1 = sum(distance_matrix_1[candidate[i-1], candidate[i]] for i in range(n))\n        cost2 = sum(distance_matrix_2[candidate[i-1], candidate[i]] for i in range(n))\n        new_cost = (cost1, cost2)\n\n        # Accept if weighted sum improves (weighted by inverse costs to balance objectives)\n        if (cost1 / current_cost[0] + cost2 / current_cost[1]) < 2:  # Simplified acceptance criterion\n            new_solution = candidate\n\n    # Edge exchange with objective-aware acceptance\n    if n > 3:\n        i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n        if abs(i - j) > 1 and abs(k - l) > 1:\n            candidate = new_solution.copy()\n            candidate[i], candidate[j] = candidate[j], candidate[i]\n            candidate[k], candidate[l] = candidate[l], candidate[k]\n\n            # Calculate new cost\n            cost1 = sum(distance_matrix_1[candidate[i-1], candidate[i]] for i in range(n))\n            cost2 = sum(distance_matrix_2[candidate[i-1], candidate[i]] for i in range(n))\n            new_cost = (cost1, cost2)\n\n            # Accept if weighted sum improves\n            if (cost1 / current_cost[0] + cost2 / current_cost[1]) < 2:\n                new_solution = candidate\n\n    # Ensure the solution is valid (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()  # Fallback to original if invalid\n\n    return new_solution\n\n",
          "score": [
               6.459716852001758,
               7.052657272676352
          ]
     },
     {
          "algorithm": "{The new algorithm employs a multi-phase approach that begins by clustering solutions in the objective space using k-means, then selects a solution from the least crowded cluster to ensure diversity. It then applies a novel \"path inversion with objective-aware segment selection\" that identifies the most promising contiguous segment to invert based on the combined improvement potential in both objective spaces, followed by a \"cross-objective edge swapping\" operator that exchanges edges between the two objective spaces to balance improvements. The algorithm dynamically adjusts the acceptance criteria based on the current Pareto front dominance, ensuring high-quality neighbors while maintaining feasibility through strict validation checks.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Cluster solutions in objective space and select from least crowded cluster\n    objectives = np.array([obj for _, obj in archive])\n    if len(archive) > 1:\n        from sklearn.cluster import KMeans\n        k = min(3, len(archive))\n        kmeans = KMeans(n_clusters=k, random_state=42).fit(objectives)\n        cluster_sizes = np.bincount(kmeans.labels_)\n        least_crowded_cluster = np.argmin(cluster_sizes)\n        cluster_indices = np.where(kmeans.labels_ == least_crowded_cluster)[0]\n    else:\n        cluster_indices = [0]\n\n    selected_idx = np.random.choice(cluster_indices)\n    base_solution = archive[selected_idx][0].copy()\n    current_cost = archive[selected_idx][1]\n\n    # Step 2: Path inversion with objective-aware segment selection\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n > 2:\n        # Calculate potential improvement for all possible segments\n        improvements = []\n        for a in range(n):\n            for b in range(a+1, n):\n                segment = new_solution[a:b+1]\n                inverted_segment = segment[::-1]\n                candidate = np.concatenate([new_solution[:a], inverted_segment, new_solution[b+1:]])\n\n                # Calculate new cost\n                cost1 = sum(distance_matrix_1[candidate[i-1], candidate[i]] for i in range(n))\n                cost2 = sum(distance_matrix_2[candidate[i-1], candidate[i]] for i in range(n))\n\n                # Calculate improvement potential\n                improvement = (current_cost[0] - cost1) + (current_cost[1] - cost2)\n                improvements.append((improvement, a, b))\n\n        if improvements:\n            # Select segment with highest improvement potential\n            best_improvement, best_a, best_b = max(improvements)\n            if best_improvement > 0:\n                segment = new_solution[best_a:best_b+1]\n                inverted_segment = segment[::-1]\n                new_solution = np.concatenate([new_solution[:best_a], inverted_segment, new_solution[best_b+1:]])\n\n    # Step 3: Cross-objective edge swapping\n    if n > 3:\n        # Find edges that are long in one space but short in the other\n        edges = [(i, (i+1)%n) for i in range(n)]\n        swap_candidates = []\n\n        for i, j in edges:\n            node_i = new_solution[i]\n            node_j = new_solution[j]\n\n            cost1_ij = distance_matrix_1[node_i, node_j]\n            cost2_ij = distance_matrix_2[node_i, node_j]\n\n            # Find alternative edges that could improve both objectives\n            for k in range(n):\n                if k != i and k != j and (k+1)%n != i and (k+1)%n != j:\n                    node_k = new_solution[k]\n                    node_l = new_solution[(k+1)%n]\n\n                    cost1_kl = distance_matrix_1[node_k, node_l]\n                    cost2_kl = distance_matrix_2[node_k, node_l]\n\n                    # Calculate potential improvement\n                    if (cost1_ij + cost1_kl) > (distance_matrix_1[node_i, node_k] + distance_matrix_1[node_l, node_j]) and \\\n                       (cost2_ij + cost2_kl) > (distance_matrix_2[node_i, node_k] + distance_matrix_2[node_l, node_j]):\n                        swap_candidates.append((i, j, k, (k+1)%n))\n\n        if swap_candidates:\n            # Select random swap candidate\n            i, j, k, l = random.choice(swap_candidates)\n            candidate = new_solution.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n            candidate[j], candidate[l] = candidate[l], candidate[j]\n\n            # Verify feasibility\n            if len(np.unique(candidate)) == n:\n                new_solution = candidate\n\n    # Ensure the solution is valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               6.766986731722818,
               7.219290246888874
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies promising solutions in the archive by evaluating their potential for improvement using a combination of objective values and diversity metrics. It then intelligently selects one solution based on a weighted random selection that favors solutions with lower costs and higher diversity. For local search, it employs a novel hybrid approach: it first applies a randomized version of the Lin-Kernighan algorithm to escape local optima, followed by a biased random walk to explore the solution space while maintaining feasibility. The walk is guided by a weighted combination of the two objective spaces, ensuring progress toward both objectives. The function always checks the feasibility of the generated neighbor solution, ensuring it remains a valid TSP tour with no skipped or revisited nodes.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Calculate diversity and objective scores\n    objectives = np.array([obj for (sol, obj) in archive])\n    costs = objectives.sum(axis=1)\n    norm_costs = (costs - costs.min()) / (costs.max() - costs.min() + 1e-10)\n\n    # Calculate diversity (average distance to other solutions)\n    diversity = []\n    for i, (sol, _) in enumerate(archive):\n        dists = [np.sum(sol != other_sol) for j, (other_sol, _) in enumerate(archive) if i != j]\n        diversity.append(np.mean(dists) if dists else 0)\n    diversity = np.array(diversity)\n    norm_diversity = (diversity - diversity.min()) / (diversity.max() - diversity.min() + 1e-10)\n\n    # Combine scores (weighted sum of normalized cost and diversity)\n    scores = 0.7 * norm_costs + 0.3 * norm_diversity\n    probs = np.exp(-scores) / np.exp(-scores).sum()  # Softmax-like selection\n\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate a neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: Randomized Lin-Kernighan + Biased Random Walk\n    # First phase: Randomized Lin-Kernighan (k=3)\n    for _ in range(10):\n        i, j, k = sorted(random.sample(range(n), 3))\n        # Try different segment reversals\n        for seg in [(i, j), (j, k), (i, k)]:\n            a, b = seg\n            segment = new_solution[a:b+1]\n            reversed_segment = segment[::-1]\n            candidate = np.concatenate([new_solution[:a], reversed_segment, new_solution[b+1:]])\n\n            # Calculate cost change\n            old_cost1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n            new_cost1 = distance_matrix_1[new_solution[a-1], reversed_segment[0]] + distance_matrix_1[reversed_segment[-1], new_solution[(b+1)%n]]\n            delta1 = new_cost1 - old_cost1\n\n            old_cost2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n            new_cost2 = distance_matrix_2[new_solution[a-1], reversed_segment[0]] + distance_matrix_2[reversed_segment[-1], new_solution[(b+1)%n]]\n            delta2 = new_cost2 - old_cost2\n\n            # Accept if both objectives improve\n            if delta1 < 0 and delta2 < 0:\n                new_solution = candidate\n                break\n\n    # Second phase: Biased Random Walk\n    for _ in range(5):\n        i, j = sorted(random.sample(range(n), 2))\n        candidate = new_solution.copy()\n        candidate[i:j+1] = candidate[i:j+1][::-1]  # Reverse segment\n\n        # Calculate cost change\n        old_cost1 = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n        new_cost1 = distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]]\n        delta1 = new_cost1 - old_cost1\n\n        old_cost2 = distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n        new_cost2 = distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]\n        delta2 = new_cost2 - old_cost2\n\n        # Accept with probability based on cost improvement\n        prob = min(1.0, np.exp(-(0.5 * delta1 + 0.5 * delta2) / 1000))  # Temperature-like parameter\n        if random.random() < prob:\n            new_solution = candidate\n\n    # Ensure the solution is valid (no duplicates)\n    if len(np.unique(new_solution)) != n:\n        # If invalid, revert to base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               7.083802600128497,
               7.273785255666639
          ]
     }
]