[
     {
          "algorithm": "{The proposed algorithm, named \"Adaptive Multi-Objective Tour Fragmentation and Reconstruction,\" builds upon the common backbone of solution selection and local improvement from the provided algorithms but introduces a fundamentally different approach. It first identifies promising solutions by analyzing the archive's Pareto front, then adaptively selects and fragments the tour into multiple segments based on their contribution to each objective. These segments are then reconstructed using a novel \"objective-aware segment merging\" heuristic that prioritizes the most beneficial segments for each objective while maintaining tour feasibility. The method dynamically adjusts the fragmentation size and merging strategy based on the current solution's performance in both objective spaces, allowing for both fine-grained local improvements and more disruptive global explorations. The algorithm ensures feasibility by maintaining a valid tour structure throughout the process and includes a \"segment quality assessment\" mechanism that evaluates each segment's impact on both objectives before merging.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(sol)\n\n    if not non_dominated:\n        non_dominated = [sol for sol, _ in archive]\n\n    # Step 2: Select base solution with probability based on solution quality\n    base_solution = random.choices(\n        non_dominated,\n        weights=[1/(i+1) for i in range(len(non_dominated))],\n        k=1\n    )[0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 3: Adaptive tour fragmentation and reconstruction\n    if n > 3:\n        # Determine fragmentation size based on solution quality\n        fragment_size = min(3, max(1, n // 10))\n        num_fragments = max(2, n // fragment_size)\n\n        # Randomly select fragments to reconstruct\n        fragment_indices = sorted(random.sample(range(1, n-1), num_fragments-1))\n        fragments = []\n        start = 0\n        for idx in fragment_indices:\n            fragments.append(new_solution[start:idx])\n            start = idx\n        fragments.append(new_solution[start:])\n\n        # Shuffle fragments with probability based on objective performance\n        if random.random() < 0.7:\n            random.shuffle(fragments)\n\n        # Reconstruct solution with objective-aware merging\n        merged_solution = []\n        for i in range(len(fragments)):\n            # Calculate fragment quality for each objective\n            frag = fragments[i]\n            if len(frag) < 2:\n                merged_solution.extend(frag)\n                continue\n\n            # Calculate objective contributions\n            obj1_contrib = sum(distance_matrix_1[frag[j], frag[j+1]] for j in range(len(frag)-1))\n            obj2_contrib = sum(distance_matrix_2[frag[j], frag[j+1]] for j in range(len(frag)-1))\n\n            # Decide whether to reverse the fragment based on objective performance\n            if i > 0 and i < len(fragments)-1:\n                prev_node = merged_solution[-1] if merged_solution else fragments[i-1][-1]\n                next_node = fragments[i+1][0] if i < len(fragments)-1 else frag[-1]\n\n                # Calculate potential improvement if reversed\n                rev_obj1 = sum(distance_matrix_1[frag[j], frag[j+1]] for j in range(len(frag)-1))\n                rev_obj2 = sum(distance_matrix_2[frag[j], frag[j+1]] for j in range(len(frag)-1))\n\n                if (rev_obj1 < obj1_contrib and rev_obj2 < obj2_contrib) or \\\n                   (random.random() < 0.3 and (rev_obj1 < obj1_contrib or rev_obj2 < obj2_contrib)):\n                    frag = frag[::-1]\n\n            merged_solution.extend(frag)\n\n        # Ensure the tour is circular\n        if merged_solution[0] != merged_solution[-1]:\n            merged_solution.append(merged_solution[0])\n\n        new_solution = np.array(merged_solution)\n\n    return new_solution\n\n",
          "score": [
               -0.9578128800630137,
               0.3399670124053955
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Objective-Centric Tour Recombination and Adaptive Edge Refinement,\" builds upon the common backbone of solution selection and local improvement from the provided algorithms but introduces a fundamentally different approach. It first identifies promising solutions by analyzing the archive's Pareto front, then selects a base solution based on its objective performance and structural diversity. The algorithm then partitions the tour into multiple segments and recombines them using an objective-centric approach that prioritizes the most beneficial edges for each objective while maintaining tour feasibility. This is followed by an adaptive edge refinement phase that selectively improves the tour by replacing edges with better alternatives from a candidate pool, where the selection of candidates is guided by both objective improvements and spatial proximity in the coordinate spaces. The method dynamically adjusts the refinement intensity based on the current solution's performance in both objective spaces, allowing for both fine-grained local improvements and more disruptive global explorations. The algorithm ensures feasibility by maintaining a valid tour structure throughout the process and includes a \"edge quality assessment\" mechanism that evaluates each edge's impact on both objectives before refinement.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify non-dominated solutions\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(sol)\n\n    if not non_dominated:\n        non_dominated = [sol for sol, _ in archive]\n\n    # Select base solution with probability based on solution quality\n    base_solution = random.choices(\n        non_dominated,\n        weights=[1/(i+1) for i in range(len(non_dominated))],\n        k=1\n    )[0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Objective-centric tour recombination\n    if n > 3:\n        # Partition the tour into segments\n        num_segments = max(2, n // 5)\n        segment_length = n // num_segments\n        segments = [new_solution[i*segment_length:(i+1)*segment_length] for i in range(num_segments)]\n\n        # For each segment, identify the best edges for each objective\n        for i in range(len(segments)):\n            seg = segments[i]\n            if len(seg) < 2:\n                continue\n\n            # Find the best edge in the segment for each objective\n            best_edge1 = (0, 1)\n            best_edge2 = (0, 1)\n            min_dist1 = distance_matrix_1[seg[0], seg[1]]\n            min_dist2 = distance_matrix_2[seg[0], seg[1]]\n\n            for j in range(len(seg)-1):\n                if distance_matrix_1[seg[j], seg[j+1]] < min_dist1:\n                    min_dist1 = distance_matrix_1[seg[j], seg[j+1]]\n                    best_edge1 = (j, j+1)\n                if distance_matrix_2[seg[j], seg[j+1]] < min_dist2:\n                    min_dist2 = distance_matrix_2[seg[j], seg[j+1]]\n                    best_edge2 = (j, j+1)\n\n            # Decide which edges to keep based on objective priorities\n            if random.random() < 0.5:\n                # Prioritize first objective\n                if best_edge1 != best_edge2:\n                    # Replace the non-optimal edges with optimal ones\n                    if best_edge1[0] < best_edge2[0]:\n                        seg[best_edge2[0]:best_edge2[1]] = seg[best_edge1[0]:best_edge1[1]]\n                    else:\n                        seg[best_edge1[0]:best_edge1[1]] = seg[best_edge2[0]:best_edge2[1]]\n            else:\n                # Prioritize second objective\n                if best_edge1 != best_edge2:\n                    if best_edge2[0] < best_edge1[0]:\n                        seg[best_edge1[0]:best_edge1[1]] = seg[best_edge2[0]:best_edge2[1]]\n                    else:\n                        seg[best_edge2[0]:best_edge2[1]] = seg[best_edge1[0]:best_edge1[1]]\n\n            segments[i] = seg\n\n        # Recombine segments with adaptive edge refinement\n        merged_solution = []\n        for i in range(len(segments)):\n            seg = segments[i]\n            if not merged_solution:\n                merged_solution.extend(seg)\n            else:\n                # Find the best connection between current end and next segment start\n                last_node = merged_solution[-1]\n                next_seg = segments[(i+1) % len(segments)]\n                first_node = next_seg[0]\n\n                # Create candidate edges\n                candidates = []\n                for node in seg:\n                    candidates.append((last_node, node))\n                    candidates.append((node, first_node))\n\n                # Evaluate candidates based on both objectives\n                best_candidate = candidates[0]\n                min_cost1 = distance_matrix_1[last_node, seg[0]] + distance_matrix_1[seg[-1], first_node]\n                min_cost2 = distance_matrix_2[last_node, seg[0]] + distance_matrix_2[seg[-1], first_node]\n\n                for (a, b) in candidates:\n                    cost1 = distance_matrix_1[a, b]\n                    cost2 = distance_matrix_2[a, b]\n                    if (cost1 < min_cost1 and cost2 <= min_cost2) or (cost1 <= min_cost1 and cost2 < min_cost2):\n                        min_cost1 = cost1\n                        min_cost2 = cost2\n                        best_candidate = (a, b)\n\n                # Apply the best connection\n                if best_candidate[0] == last_node:\n                    merged_solution.extend(seg)\n                else:\n                    # Find the node in seg that connects to first_node\n                    connection_node = None\n                    for node in seg:\n                        if distance_matrix_1[node, first_node] < distance_matrix_1[seg[0], first_node] or \\\n                           distance_matrix_2[node, first_node] < distance_matrix_2[seg[0], first_node]:\n                            connection_node = node\n                            break\n\n                    if connection_node is not None:\n                        # Split the segment at the connection node\n                        idx = np.where(seg == connection_node)[0][0]\n                        merged_solution.extend(seg[:idx+1])\n                        merged_solution.extend(seg[idx+1:])\n                    else:\n                        merged_solution.extend(seg)\n\n        # Ensure the tour is circular\n        if merged_solution[0] != merged_solution[-1]:\n            merged_solution.append(merged_solution[0])\n\n        new_solution = np.array(merged_solution)\n\n    return new_solution\n\n",
          "score": [
               -0.9645529101975834,
               0.40858298540115356
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_idx = np.random.choice(min(5, len(archive_sorted)))  # Select from top 5 or all if fewer\n    base_solution = archive_sorted[selected_idx][0].copy()\n\n    # Step 2: Apply a hybrid local search operator\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid operator: Combine 3-opt with a novel segment reversal strategy\n    # First, perform a random 3-opt move\n    i, j, k = sorted(np.random.choice(n, 3, replace=False))\n    if i == 0 and k == n-1:  # Avoid full reversal which is equivalent to a swap\n        i, j, k = 0, 1, 2\n\n    # Create three segments and reverse the middle one\n    segment1 = new_solution[:i]\n    segment2 = new_solution[i:j+1][::-1]\n    segment3 = new_solution[j+1:k+1][::-1]\n    segment4 = new_solution[k+1:]\n\n    # Combine segments with a novel crossover pattern\n    new_solution = np.concatenate([segment1, segment3, segment2, segment4])\n\n    # Step 3: Ensure the solution remains feasible\n    # Verify all nodes are present and unique\n    if len(set(new_solution)) != n or len(new_solution) != n:\n        # If invalid, revert to the base solution\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               -0.5515284065342554,
               0.4913042187690735
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify non-dominated solutions in the archive\n    non_dominated = []\n    for sol, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive  # Fallback to all solutions if none are non-dominated\n\n    # Step 2: Select a solution with high diversity (sum of distances in both objectives)\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in non_dominated])\n    base_solution = non_dominated[selected_idx][0].copy()\n\n    # Step 3: Segmented inversion operator\n    n = len(base_solution)\n    new_solution = base_solution.copy()\n\n    # Determine segment lengths dynamically based on instance size\n    segment_length = max(2, n // 10)  # At least 2 nodes per segment\n\n    for i in range(0, n, segment_length):\n        segment_start = i\n        segment_end = min(i + segment_length, n)\n\n        # Calculate segment cost in both objectives\n        segment_cost_1 = 0\n        segment_cost_2 = 0\n        for j in range(segment_start, segment_end - 1):\n            node_a = base_solution[j]\n            node_b = base_solution[j + 1]\n            segment_cost_1 += distance_matrix_1[node_a, node_b]\n            segment_cost_2 += distance_matrix_2[node_a, node_b]\n\n        # Probability of inversion is inversely proportional to segment cost\n        total_cost = segment_cost_1 + segment_cost_2\n        if total_cost > 0:\n            inversion_prob = 1.0 / (1.0 + total_cost / (distance_matrix_1.sum() + distance_matrix_2.sum()))\n        else:\n            inversion_prob = 0.5\n\n        if np.random.rand() < inversion_prob:\n            # Invert the segment\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n\n    # Ensure the solution remains feasible (all nodes visited exactly once)\n    assert len(set(new_solution)) == len(base_solution), \"Generated solution is not feasible\"\n\n    return new_solution\n\n",
          "score": [
               -0.9562401881074726,
               0.8160168528556824
          ]
     },
     {
          "algorithm": "{The proposed local search strategy, named \"Adaptive Multi-Objective Edge Insertion with Dynamic Neighborhood Exploration,\" combines adaptive edge selection based on Pareto dominance and objective-specific distance matrices with dynamic neighborhood exploration to balance exploration and exploitation. It first identifies promising edges by analyzing the Pareto front of the archive, then adaptively selects edges with high potential for improvement by considering both objective-specific distances and their contribution to the overall solution quality. The dynamic neighborhood exploration phase employs a hybrid approach that alternates between edge-based and segment-based operations, guided by the current solution's performance in each objective space. The method ensures feasibility by maintaining a valid tour structure and includes a novel \"objective-aware edge insertion\" operator that selectively inserts edges based on their impact on both objectives, while a \"segment reordering\" heuristic reorders segments of the tour to optimize both spaces simultaneously. The adaptive selection of operations and the dynamic adjustment of neighborhood size based on the solution's convergence properties enhance the method's ability to escape local optima and explore diverse regions of the search space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if len(archive) > 1:\n        # Sort solutions by non-dominated rank and crowding distance\n        sorted_archive = sorted(archive, key=lambda x: (sum(x[1]), -len(x[0])))\n        # Select a solution with probability proportional to its rank\n        selected_idx = random.choices(range(len(sorted_archive)), weights=[1/(i+1) for i in range(len(sorted_archive))])[0]\n        base_solution = sorted_archive[selected_idx][0].copy()\n    else:\n        base_solution = archive[0][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search operator\n    if random.random() < 0.7:  # 70% chance for edge-based operation\n        # Objective-aware edge insertion\n        i, j = sorted(random.sample(range(n), 2))\n        # Calculate potential improvement in both objectives\n        obj1_improvement = (distance_matrix_1[new_solution[i-1], new_solution[j]] +\n                           distance_matrix_1[new_solution[j], new_solution[(i+1)%n]]) - \\\n                          (distance_matrix_1[new_solution[i-1], new_solution[i]] +\n                           distance_matrix_1[new_solution[i], new_solution[(i+1)%n]])\n        obj2_improvement = (distance_matrix_2[new_solution[i-1], new_solution[j]] +\n                           distance_matrix_2[new_solution[j], new_solution[(i+1)%n]]) - \\\n                          (distance_matrix_2[new_solution[i-1], new_solution[i]] +\n                           distance_matrix_2[new_solution[i], new_solution[(i+1)%n]])\n\n        # Accept if both objectives improve or one improves significantly\n        if obj1_improvement < 0 and obj2_improvement < 0:\n            # Insert edge (i,j) between i and j\n            new_solution = np.concatenate([new_solution[:i+1], new_solution[j:j+1], new_solution[i+1:j], new_solution[j+1:]])\n        elif (obj1_improvement < 0 and obj2_improvement < 10) or (obj2_improvement < 0 and obj1_improvement < 10):\n            # Insert edge (i,j) between i and j\n            new_solution = np.concatenate([new_solution[:i+1], new_solution[j:j+1], new_solution[i+1:j], new_solution[j+1:]])\n    else:\n        # Segment reordering operation\n        if n > 3:\n            # Select two random segments and reverse one of them\n            k1, k2 = sorted(random.sample(range(1, n-1), 2))\n            if random.random() < 0.5:\n                # Reverse segment between k1 and k2\n                new_solution[k1:k2+1] = new_solution[k1:k2+1][::-1]\n            else:\n                # Swap segments\n                segment1 = new_solution[k1:k2+1]\n                k3 = random.randint(0, n-1)\n                new_solution = np.concatenate([new_solution[:k3], segment1, new_solution[k3:k1], new_solution[k2+1:]])\n\n    return new_solution\n\n",
          "score": [
               -0.8044547072753083,
               0.5334844589233398
          ]
     },
     {
          "algorithm": "{The new algorithm combines objective-aware selection with a novel segment-based local search that dynamically adapts to the problem's multi-objective landscape. It first identifies promising solutions by considering both non-dominated status and objective diversity, then applies a hybrid operator that simultaneously optimizes both objectives by selectively reversing segments based on their individual and combined costs, while incorporating a probabilistic acceptance criterion that balances exploration and exploitation. This approach differs from standard methods by treating each objective's segment contribution separately and using a novel acceptance probability that considers both the segment's performance and its position in the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with balanced objectives and good diversity\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0] + x[1][1], abs(x[1][0] - x[1][1])))\n    selected_idx = min(len(archive_sorted) // 3, len(archive_sorted) - 1)\n    base_solution = archive_sorted[selected_idx][0].copy()\n    base_obj = archive_sorted[selected_idx][1]\n\n    # Step 2: Segment-based local search with objective-aware segment reversal\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Determine segment length based on instance size\n    segment_length = max(3, n // 8)\n\n    for i in range(0, n, segment_length):\n        segment_start = i\n        segment_end = min(i + segment_length, n)\n\n        # Calculate segment costs in both objectives\n        segment_cost_1 = 0\n        segment_cost_2 = 0\n        for j in range(segment_start, segment_end - 1):\n            node_a = new_solution[j]\n            node_b = new_solution[j + 1]\n            segment_cost_1 += distance_matrix_1[node_a, node_b]\n            segment_cost_2 += distance_matrix_2[node_a, node_b]\n\n        # Calculate normalized improvement potential\n        total_cost = segment_cost_1 + segment_cost_2\n        avg_cost = total_cost / (segment_end - segment_start - 1) if (segment_end - segment_start - 1) > 0 else 0\n\n        # Probability of reversal based on both objectives and position in Pareto front\n        if total_cost > 0:\n            # Check if this segment is part of the non-dominated front\n            is_non_dominated = True\n            for _, obj in archive:\n                if (obj[0] <= base_obj[0] and obj[1] < base_obj[1]) or (obj[0] < base_obj[0] and obj[1] <= base_obj[1]):\n                    is_non_dominated = False\n                    break\n\n            # Higher probability if segment is worse or not on Pareto front\n            if is_non_dominated:\n                prob = 0.2 * (1.0 - min(segment_cost_1 / distance_matrix_1.sum(), segment_cost_2 / distance_matrix_2.sum()))\n            else:\n                prob = 0.7 * (1.0 - min(segment_cost_1 / distance_matrix_1.sum(), segment_cost_2 / distance_matrix_2.sum()))\n        else:\n            prob = 0.1\n\n        if np.random.rand() < prob:\n            # Reverse the segment with probability based on both objectives\n            obj_prob_1 = segment_cost_1 / total_cost if total_cost > 0 else 0.5\n            if np.random.rand() < obj_prob_1:\n                new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n            else:\n                # Reverse with probability based on second objective\n                new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n\n    # Ensure the solution is valid\n    if len(set(new_solution)) != len(base_solution):\n        # Fallback to simple swap if invalid\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               -0.8360507854661878,
               0.5987046360969543
          ]
     },
     {
          "algorithm": "{This new algorithm selects a base solution from the archive by first identifying the Pareto front solutions (non-dominated solutions) and then choosing the one with the highest combined objective value among them. It then applies a novel \"node swapping with adaptive neighborhood\" strategy, where it randomly selects a node and swaps it with another node within a dynamically determined neighborhood radius. The neighborhood radius is calculated based on the current solution's quality, with higher-quality solutions having a larger neighborhood to explore more distant swaps. The algorithm ensures feasibility by maintaining the TSP tour structure and verifies that all nodes are visited exactly once before returning the new solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Step 2: Select the solution with highest combined objective from non-dominated\n    selected = max(non_dominated, key=lambda x: sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 3: Apply node swapping with adaptive neighborhood\n    n = len(base_solution)\n    node_to_swap = np.random.randint(0, n)\n\n    # Calculate neighborhood radius based on solution quality\n    current_cost = sum(selected[1])\n    avg_cost = sum(sum(obj) for _, obj in archive) / len(archive)\n    neighborhood_radius = min(5, max(1, int((current_cost / avg_cost) * 2)))\n\n    # Find valid nodes to swap with\n    swap_candidates = []\n    for i in range(max(0, node_to_swap - neighborhood_radius), min(n, node_to_swap + neighborhood_radius + 1)):\n        if i != node_to_swap:\n            swap_candidates.append(i)\n\n    if swap_candidates:\n        swap_node = np.random.choice(swap_candidates)\n        new_solution[node_to_swap], new_solution[swap_node] = new_solution[swap_node], new_solution[node_to_swap]\n\n    # Step 4: Verify feasibility\n    if len(set(new_solution)) != n or len(new_solution) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               -0.6669497474635347,
               0.5746572613716125
          ]
     },
     {
          "algorithm": "{This new algorithm, named \"Bi-Objective Path Refinement with Multi-Dimensional Rebalancing,\" operates by first selecting the solution from the archive with the most balanced objectives (closest to Pareto-optimal) as the base solution. It then identifies critical segments where the path's balance between objectives is most imbalanced, using a novel segment scoring metric that combines the absolute difference in segment costs with their relative positions in the tour. These segments are subjected to a hybrid local search that includes: 1) a probabilistic node replacement mechanism that prioritizes nodes which improve both objectives simultaneously, 2) a cross-dimensional alignment phase that swaps nodes between segments to better align their contributions to each objective, and 3) a dynamic segment reversal operation that flips segments to potentially improve both objectives. The algorithm ensures feasibility by maintaining a permutation of nodes and validates the solution before returning it, falling back to a simple swap if invalid. The method's novelty lies in its multi-faceted approach that simultaneously addresses both objectives through coordinated segment operations and cross-dimensional alignment.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive_sorted = sorted(archive, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = archive_sorted[0][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify critical segments for improvement\n    segment_length = max(2, n // 4)\n    segment_scores = []\n\n    for i in range(n - segment_length + 1):\n        segment = new_solution[i:i+segment_length]\n        # Calculate segment costs\n        cost1 = sum(distance_matrix_1[segment[j], segment[j+1]] for j in range(segment_length-1))\n        cost2 = sum(distance_matrix_2[segment[j], segment[j+1]] for j in range(segment_length-1))\n\n        # Score based on imbalance and potential for improvement\n        imbalance = abs(cost1 - cost2)\n        total_cost = cost1 + cost2\n        score = imbalance * (1 / (total_cost + 1e-6)) + 0.5 * (cost1 + cost2) / (distance_matrix_1[segment[0], segment[-1]] + distance_matrix_2[segment[0], segment[-1]] + 1e-6)\n        segment_scores.append((i, score))\n\n    if not segment_scores:\n        segment_scores = [(0, 0)]\n\n    # Select top segments for refinement\n    segment_scores.sort(key=lambda x: x[1], reverse=True)\n    selected_segments = [x[0] for x in segment_scores[:3]]\n\n    # Process selected segments\n    for start_idx in selected_segments:\n        segment = new_solution[start_idx:start_idx+segment_length]\n\n        # Multi-dimensional node replacement\n        for i in range(len(segment)):\n            current_node = segment[i]\n            best_node = current_node\n            best_improvement = 0\n\n            # Find best replacement node\n            for candidate_node in range(n):\n                if candidate_node not in segment:\n                    # Calculate improvement in both objectives\n                    prev_node = segment[(i-1)%len(segment)]\n                    next_node = segment[(i+1)%len(segment)]\n\n                    current_cost = (distance_matrix_1[prev_node, current_node] + distance_matrix_1[current_node, next_node] +\n                                   distance_matrix_2[prev_node, current_node] + distance_matrix_2[current_node, next_node])\n\n                    candidate_cost = (distance_matrix_1[prev_node, candidate_node] + distance_matrix_1[candidate_node, next_node] +\n                                     distance_matrix_2[prev_node, candidate_node] + distance_matrix_2[candidate_node, next_node])\n\n                    improvement = current_cost - candidate_cost\n\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_node = candidate_node\n\n            if best_node != current_node:\n                segment[i] = best_node\n\n        # Cross-dimensional alignment\n        if random.random() < 0.6:\n            # Find nodes that are better in one objective but worse in another\n            for i in range(len(segment)):\n                node = segment[i]\n                prev_node = segment[(i-1)%len(segment)]\n                next_node = segment[(i+1)%len(segment)]\n\n                cost1_prev = distance_matrix_1[prev_node, node]\n                cost2_prev = distance_matrix_2[prev_node, node]\n                cost1_next = distance_matrix_1[node, next_node]\n                cost2_next = distance_matrix_2[node, next_node]\n\n                # Find potential swap partner\n                for j in range(i+1, len(segment)):\n                    other_node = segment[j]\n                    other_prev = segment[(j-1)%len(segment)]\n                    other_next = segment[(j+1)%len(segment)]\n\n                    # Check if swapping would improve both objectives\n                    new_cost1 = (distance_matrix_1[prev_node, other_node] + distance_matrix_1[other_node, next_node] +\n                                 distance_matrix_1[other_prev, node] + distance_matrix_1[node, other_next])\n                    new_cost2 = (distance_matrix_2[prev_node, other_node] + distance_matrix_2[other_node, next_node] +\n                                 distance_matrix_2[other_prev, node] + distance_matrix_2[node, other_next])\n\n                    old_cost1 = cost1_prev + cost1_next + distance_matrix_1[other_prev, other_node] + distance_matrix_1[other_node, other_next]\n                    old_cost2 = cost2_prev + cost2_next + distance_matrix_2[other_prev, other_node] + distance_matrix_2[other_node, other_next]\n\n                    if (new_cost1 < old_cost1 and new_cost2 < old_cost2):\n                        # Perform swap\n                        segment[i], segment[j] = segment[j], segment[i]\n                        break\n\n        # Dynamic segment reversal\n        if random.random() < 0.4:\n            # Reverse the segment and check if it improves both objectives\n            reversed_segment = segment[::-1]\n            original_cost1 = sum(distance_matrix_1[segment[j], segment[j+1]] for j in range(len(segment)-1))\n            reversed_cost1 = sum(distance_matrix_1[reversed_segment[j], reversed_segment[j+1]] for j in range(len(reversed_segment)-1))\n            original_cost2 = sum(distance_matrix_2[segment[j], segment[j+1]] for j in range(len(segment)-1))\n            reversed_cost2 = sum(distance_matrix_2[reversed_segment[j], reversed_segment[j+1]] for j in range(len(reversed_segment)-1))\n\n            if (reversed_cost1 < original_cost1 and reversed_cost2 < original_cost2):\n                segment = reversed_segment\n\n        # Reinsert processed segment\n        new_solution = np.concatenate([new_solution[:start_idx], segment, new_solution[start_idx+segment_length:]])\n\n    # Validate solution\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n or len(new_solution) != n:\n        # If invalid, perform a simple swap\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               -0.9512152601147608,
               9.916679382324219
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' begins by evaluating the archive of solutions to identify those with the highest potential for improvement, prioritizing solutions with lower objective values and higher diversity in their tour structures. It then intelligently selects a base solution using a tournament selection mechanism that balances exploration and exploitation, favoring solutions that are not only Pareto-optimal but also exhibit structural diversity. The selected base solution undergoes a novel hybrid local search operator that combines a multi-segment inversion strategy with a guided edge insertion mechanism. This operator first partitions the tour into multiple segments, inverts a randomly selected segment to disrupt the current structure, and then intelligently reinserts edges from the inverted segment back into the tour using a guided approach that minimizes the increase in both objective costs. The operator ensures feasibility by maintaining a valid TSP tour throughout the process, and it employs a dynamic acceptance criterion to accept non-improving solutions with a small probability, preventing premature convergence. The generated neighbor solution is then returned, representing a high-quality candidate for further exploration in the optimization process.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution based on objective values and diversity\n    def select_base(archive):\n        # Rank solutions based on objective values (lower is better)\n        objectives = np.array([obj for _, obj in archive])\n        ranks = np.lexsort((objectives[:, 1], objectives[:, 0]))\n\n        # Select top 10% of solutions for tournament\n        tournament_size = max(1, len(archive) // 10)\n        candidates = [archive[i] for i in ranks[:tournament_size]]\n\n        # Select the solution with the highest diversity (most different from others)\n        def diversity(sol):\n            total_dist = 0\n            for other_sol, _ in candidates:\n                if not np.array_equal(sol, other_sol):\n                    total_dist += np.sum(sol != other_sol)\n            return total_dist\n\n        base_sol, _ = max(candidates, key=lambda x: diversity(x[0]))\n        return base_sol.copy()\n\n    base_solution = select_base(archive)\n\n    # Hybrid local search operator\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Multi-segment inversion\n    if n > 3:\n        # Randomly select a segment to invert\n        start = np.random.randint(0, n - 2)\n        end = np.random.randint(start + 1, n)\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Guided edge insertion\n    def calculate_cost(sol, distance_matrix_1, distance_matrix_2):\n        cost1 = sum(distance_matrix_1[sol[i], sol[(i + 1) % n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[sol[i], sol[(i + 1) % n]] for i in range(n))\n        return cost1, cost2\n\n    current_cost1, current_cost2 = calculate_cost(new_solution, distance_matrix_1, distance_matrix_2)\n\n    for _ in range(10):  # Limit the number of insertion attempts\n        # Randomly select two edges to reconnect\n        i, j = np.random.choice(n, size=2, replace=False)\n        if i > j:\n            i, j = j, i\n\n        # Create a new candidate solution by reconnecting edges\n        candidate = np.concatenate([\n            new_solution[:i+1],\n            new_solution[j+1:],\n            new_solution[i+1:j+1]\n        ])\n\n        # Ensure the candidate is a valid tour\n        if len(np.unique(candidate)) == n:\n            candidate_cost1, candidate_cost2 = calculate_cost(candidate, distance_matrix_1, distance_matrix_2)\n\n            # Accept the candidate if it improves both objectives\n            if (candidate_cost1 <= current_cost1 and candidate_cost2 <= current_cost2) or \\\n               (np.random.rand() < 0.1):  # Small probability to accept non-improving solutions\n                new_solution = candidate\n                current_cost1, current_cost2 = candidate_cost1, candidate_cost2\n\n    return new_solution\n\n",
          "score": [
               -0.9394132083738742,
               1.2528079152107239
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Step 2: Select base solution with probabilistic approach\n    weights = []\n    for _, obj in non_dominated:\n        # Calculate solution quality metric (harmonic mean of objectives)\n        if obj[0] + obj[1] == 0:\n            quality = 0\n        else:\n            quality = 2 / ((1/obj[0]) + (1/obj[1]))\n        weights.append(quality)\n\n    # Normalize weights\n    total_weight = sum(weights)\n    if total_weight > 0:\n        weights = [w/total_weight for w in weights]\n    else:\n        weights = [1/len(weights)] * len(weights)\n\n    base_solution = random.choices([sol for sol, _ in non_dominated], weights=weights, k=1)[0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 3: Hybrid local search with multi-segment inversion and dynamic exchange\n    # Select multiple non-overlapping segments\n    num_segments = random.randint(1, min(3, n//4))\n    segment_lengths = random.sample(range(2, min(5, n//2)), num_segments)\n    segment_lengths = sorted(segment_lengths, reverse=True)\n\n    # Generate non-overlapping segments\n    segments = []\n    remaining_positions = list(range(n))\n    for length in segment_lengths:\n        if len(remaining_positions) < length:\n            break\n        start = random.choice(remaining_positions)\n        segment = []\n        for i in range(length):\n            pos = (start + i) % n\n            if pos in remaining_positions:\n                segment.append(pos)\n                remaining_positions.remove(pos)\n        if len(segment) == length:\n            segments.append(segment)\n\n    # Invert each segment\n    for seg in segments:\n        seg_start = seg[0]\n        seg_end = seg[-1]\n        new_solution[seg_start:seg_end+1] = new_solution[seg_start:seg_end+1][::-1]\n\n    # Dynamic node exchange between segments\n    for _ in range(min(3, len(segments))):\n        if len(segments) < 2:\n            break\n        seg1, seg2 = random.sample(segments, 2)\n        if len(seg1) > 1 and len(seg2) > 1:\n            pos1 = random.choice(seg1)\n            pos2 = random.choice(seg2)\n            new_solution[pos1], new_solution[pos2] = new_solution[pos2], new_solution[pos1]\n\n    # Step 4: Acceptance criterion with objective diversity\n    # Calculate current and new objective values\n    def calculate_objectives(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[i+1]] for i in range(n-1)) + distance_matrix_1[solution[-1], solution[0]]\n        cost2 = sum(distance_matrix_2[solution[i], solution[i+1]] for i in range(n-1)) + distance_matrix_2[solution[-1], solution[0]]\n        return cost1, cost2\n\n    current_obj = archive[[sol.tolist() for sol, _ in archive].index(base_solution.tolist())][1]\n    new_obj = calculate_objectives(new_solution)\n\n    # Accept if either objective improves or if both are within 10% of the current values\n    accept = (new_obj[0] < current_obj[0] or new_obj[1] < current_obj[1] or\n              (new_obj[0] <= 1.1 * current_obj[0] and new_obj[1] <= 1.1 * current_obj[1]))\n\n    if not accept:\n        # Revert to base solution if not accepted\n        new_solution = base_solution.copy()\n\n    # Step 5: Fine-tuning with restricted variable neighborhood descent\n    neighborhoods = [\n        lambda sol: sol[::-1],  # Complete reversal\n        lambda sol: np.roll(sol, random.randint(1, n-1)),  # Circular shift\n        lambda sol: np.concatenate([sol[:n//2][::-1], sol[n//2:][::-1]])  # Double reversal\n    ]\n\n    for _ in range(3):\n        for neighborhood in neighborhoods:\n            candidate = neighborhood(new_solution.copy())\n            candidate_obj = calculate_objectives(candidate)\n            if (candidate_obj[0] < new_obj[0] or candidate_obj[1] < new_obj[1] or\n                (candidate_obj[0] <= 1.05 * new_obj[0] and candidate_obj[1] <= 1.05 * new_obj[1])):\n                new_solution = candidate.copy()\n                new_obj = candidate_obj\n                break\n\n    return new_solution\n\n",
          "score": [
               -0.7234902892166956,
               0.8977619409561157
          ]
     }
]