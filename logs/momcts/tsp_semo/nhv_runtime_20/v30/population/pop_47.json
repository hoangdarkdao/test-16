[
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized objective product) and applies a multi-stage local search: first an adaptive segment inversion that reverses a random segment if it improves both objectives, followed by probabilistic node relocation that moves a node to the best position with a 70% chance. The method ensures feasibility by maintaining unique node visits and uses simulated annealing for occasional uphill moves.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized objective product\n    max_obj = max(max(obj) for _, obj in archive)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0]/max_obj) * (x[1][1]/max_obj), reverse=True)\n    base_solution = archive_sorted[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Multi-stage local search\n    # Stage 1: Adaptive segment inversion\n    max_seg_size = min(5, n//2)\n    seg_size = np.random.randint(2, max_seg_size+1)\n    i = np.random.randint(0, n - seg_size)\n    segment = new_solution[i:i+seg_size]\n\n    # Evaluate segment in both objectives\n    original_cost1 = sum(distance_matrix_1[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n    original_cost2 = sum(distance_matrix_2[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n\n    reversed_segment = segment[::-1]\n    reversed_cost1 = (distance_matrix_1[new_solution[(i-1)%n], reversed_segment[0]] +\n                     distance_matrix_1[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                     sum(distance_matrix_1[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n    reversed_cost2 = (distance_matrix_2[new_solution[(i-1)%n], reversed_segment[0]] +\n                     distance_matrix_2[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                     sum(distance_matrix_2[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n\n    delta_cost = (reversed_cost1 + reversed_cost2) - (original_cost1 + original_cost2)\n    if delta_cost < 0 or (delta_cost > 0 and np.random.random() < np.exp(-delta_cost/1.0)):\n        new_solution[i:i+seg_size] = reversed_segment\n\n    # Stage 2: Probabilistic node relocation\n    if n > 4 and np.random.random() < 0.7:\n        node_idx = np.random.randint(1, n-1)\n        node = new_solution[node_idx]\n        new_solution = np.delete(new_solution, node_idx)\n\n        best_pos = -1\n        best_cost = float('inf')\n\n        for pos in range(1, n):\n            temp_solution = np.insert(new_solution, pos, node)\n            cost1 = (distance_matrix_1[temp_solution[pos-1], node] +\n                    distance_matrix_1[node, temp_solution[pos]] -\n                    distance_matrix_1[temp_solution[pos-1], temp_solution[pos]])\n            cost2 = (distance_matrix_2[temp_solution[pos-1], node] +\n                    distance_matrix_2[node, temp_solution[pos]] -\n                    distance_matrix_2[temp_solution[pos-1], temp_solution[pos]])\n            total_cost = cost1 + cost2\n\n            if total_cost < best_cost or (total_cost == best_cost and np.random.random() < 0.5):\n                best_cost = total_cost\n                best_pos = pos\n\n        if best_pos != -1:\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    # Ensure feasibility\n    assert len(new_solution) == n, \"Solution length changed\"\n    assert len(np.unique(new_solution)) == n, \"Duplicate nodes in solution\"\n\n    return new_solution\n\n",
        "score": [
            -0.9784972097067457,
            2.5674105882644653
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume-based selection with an adaptive segment-swapping mechanism, prioritizing solutions with high hypervolume and crowding distance while dynamically adjusting segment sizes and swap probabilities based on temperature. It ensures feasibility by validating and repairing tours after segment swaps, with the temperature parameter gradually decreasing to focus on high-quality local improvements. The key variables are the base solution (selected via hypervolume/crowding), segment size (adaptive to temperature), and repair mechanism (handling missing/duplicate nodes). The structure alternates between selection, segment swaps, and validation, with temperature controlling exploration/exploitation trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj1, obj2):\n        return max(0, obj1[0] - obj2[0]) * max(0, obj1[1] - obj2[1])\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    # Select solution with highest hypervolume and crowding distance\n    archive.sort(key=lambda x: (-hypervolume(x[1], (0, 0)), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Temperature parameter for adaptive control\n    temperature = max(1.0, n / 10)\n\n    # Adaptive segment swapping\n    segment_size = max(2, min(n // 3, int(temperature)))\n    num_swaps = min(3, max(1, n // (segment_size * 2)))\n\n    for _ in range(num_swaps):\n        if random.random() < (0.8 * temperature / max(1.0, n / 5)):\n            # Select two non-overlapping segments\n            seg1_start = random.randint(1, n - 2 * segment_size - 1)\n            seg2_start = random.randint(seg1_start + segment_size, n - segment_size - 1)\n\n            seg1 = new_solution[seg1_start:seg1_start+segment_size]\n            seg2 = new_solution[seg2_start:seg2_start+segment_size]\n\n            # Swap segments\n            new_solution[seg1_start:seg1_start+segment_size] = seg2\n            new_solution[seg2_start:seg2_start+segment_size] = seg1\n\n            # Decrease temperature\n            temperature *= 0.95\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            new_solution[np.where(np.isin(new_solution, list(extra)))[0][0]] = next(iter(missing))\n\n    return new_solution\n\n",
        "score": [
            -0.971151372604398,
            0.7450237274169922
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using hypervolume and crowding distance metrics, then applies adaptive 3-opt with temperature-based probabilistic acceptance to generate a neighbor solution while ensuring tour feasibility through validation and repair. It prioritizes solutions with higher hypervolume and lower crowding distance, then explores 3-opt moves probabilistically based on a temperature parameter that decreases with solution quality, and finally repairs any infeasibilities in the tour.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    # Select solution with highest hypervolume and least crowded neighbors\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive 3-opt with temperature-based acceptance\n    temperature = max(0.1, 1.0 - (selected[2] / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6)))\n\n    for _ in range(min(3, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        # Evaluate all possible 3-opt moves\n        moves = [\n            # Original order\n            (new_solution, 0),\n            # a-b-c reversed\n            (np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]]), 1),\n            # a-c-b reversed\n            (np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]]), 2),\n            # b-a-c reversed\n            (np.concatenate([new_solution[:b], new_solution[a:b-1:-1], new_solution[c:a-1:-1], new_solution[c+1:]]), 3),\n            # b-c-a reversed\n            (np.concatenate([new_solution[:b], new_solution[c:b-1:-1], new_solution[a:c-1:-1], new_solution[a+1:]]), 4),\n            # c-a-b reversed\n            (np.concatenate([new_solution[:c], new_solution[a:c-1:-1], new_solution[b:a-1:-1], new_solution[b+1:]]), 5),\n            # c-b-a reversed\n            (np.concatenate([new_solution[:c], new_solution[b:c-1:-1], new_solution[a:b-1:-1], new_solution[a+1:]]), 6)\n        ]\n\n        # Calculate costs for each move\n        move_costs = []\n        for move, idx in moves:\n            if idx == 0:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, n-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, n-1))\n            else:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, len(move)-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, len(move)-1))\n            move_costs.append((move, cost1, cost2))\n\n        # Select best move with temperature-based probability\n        best_move = min(move_costs, key=lambda x: (x[1] + x[2]))\n        if (move_costs[0][1] + move_costs[0][2]) > (best_move[1] + best_move[2]) or \\\n           (random.random() < temperature and len(np.unique(best_move[0])) == n):\n            new_solution = best_move[0].copy()\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Simple repair mechanism\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -0.9931873366440623,
            3.3111976385116577
        ]
    },
    {
        "algorithm": "The algorithm selects solutions from the archive using hypervolume and crowding distance metrics, then applies an adaptive 3-opt local search with temperature-based probabilistic acceptance to generate neighbors, balancing Pareto diversity and local refinement while ensuring tour feasibility. It prioritizes solutions with higher hypervolume and lower crowding distance, then evaluates multiple 3-opt moves to find the most promising neighbor, occasionally accepting worse solutions probabilistically based on temperature, and includes a repair mechanism to maintain feasibility. The temperature is dynamically adjusted based on the solution's hypervolume relative to the archive.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    # Select solution with highest hypervolume and least crowded neighbors\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive 3-opt with temperature-based acceptance\n    temperature = max(0.1, 1.0 - (selected[2] / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6)))\n\n    for _ in range(min(3, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        # Evaluate all possible 3-opt moves\n        moves = [\n            # Original order\n            (new_solution, 0),\n            # a-b-c reversed\n            (np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]]), 1),\n            # a-c-b reversed\n            (np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]]), 2),\n            # b-a-c reversed\n            (np.concatenate([new_solution[:b], new_solution[a:b-1:-1], new_solution[c:a-1:-1], new_solution[c+1:]]), 3),\n            # b-c-a reversed\n            (np.concatenate([new_solution[:b], new_solution[c:b-1:-1], new_solution[a:c-1:-1], new_solution[a+1:]]), 4),\n            # c-a-b reversed\n            (np.concatenate([new_solution[:c], new_solution[a:c-1:-1], new_solution[b:a-1:-1], new_solution[b+1:]]), 5),\n            # c-b-a reversed\n            (np.concatenate([new_solution[:c], new_solution[b:c-1:-1], new_solution[a:b-1:-1], new_solution[a+1:]]), 6)\n        ]\n\n        # Calculate costs for each move\n        move_costs = []\n        for move, idx in moves:\n            if idx == 0:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, n-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, n-1))\n            else:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, len(move)-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, len(move)-1))\n            move_costs.append((move, cost1, cost2))\n\n        # Select best move with temperature-based probability\n        best_move = min(move_costs, key=lambda x: (x[1] + x[2]))\n        if (move_costs[0][1] + move_costs[0][2]) > (best_move[1] + best_move[2]) or \\\n           (random.random() < temperature and len(np.unique(best_move[0])) == n):\n            new_solution = best_move[0].copy()\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Simple repair mechanism\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -1.0251145125491288,
            3.4849088191986084
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive by prioritizing non-dominated ones with balanced objectives, then applies an adaptive segment-swap local search to generate neighbors while ensuring feasibility through dynamic validation and repair. It balances exploration and exploitation through mutation intensity proportional to solution quality, and uses segment swaps to diversify the search space while maintaining tour validity. The critical design ideas are dominance-based selection, adaptive mutation intensity, and a novel segment-swap operator with feasibility repair.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    # Select non-dominated solutions\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with best balance between objectives\n    selected = min(non_dominated, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive mutation intensity\n    mutation_intensity = min(0.5, 0.1 + (selected[1][0] + selected[1][1]) / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    # Novel segment-swap local search\n    for _ in range(int(mutation_intensity * n)):\n        # Random segment selection\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n\n        # Random insertion point\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Perform segment swap\n        segment = new_solution[start:end]\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Reconstruct tour from scratch if too many errors\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if len(missing) > n//2 or len(extra) > n//2:\n            new_solution = np.random.permutation(n)\n        else:\n            # Local repair\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -0.7524281480617852,
            0.43341946601867676
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive using hypervolume and dominance ranking, then applies an adaptive 3-opt+ local search with temperature-based probabilistic edge swaps to generate neighbors, ensuring tour feasibility through dynamic validation and repair. It prioritizes non-dominated solutions with high hypervolume, uses a mix of segment-based operations (reverse, shift, swap, rotate, edge_swap), and dynamically adjusts the intensity of exploration based on temperature derived from solution quality. The method ensures feasibility by repairing missing or duplicate nodes in the generated tour.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    # Select non-dominated solutions\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with highest hypervolume\n    selected = max(non_dominated, key=lambda x: hypervolume(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = 1.0 - (hypervolume(selected[1]) / (max(hypervolume(obj) for _, obj in archive) + 1e-6))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'rotate', 'swap', 'edge_swap'], weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            elif op == 'rotate':\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n            else:  # edge_swap\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n                if random.random() < 0.3:\n                    new_solution = np.concatenate([\n                        new_solution[:a],\n                        new_solution[b:b+1],\n                        new_solution[a+1:b],\n                        new_solution[a:a+1],\n                        new_solution[b+1:]\n                    ])\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.9451053711144494,
            0.7004020810127258
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume-based selection with a novel adaptive segment-swapping mechanism, prioritizing high-potential solutions and dynamically adjusting segment sizes and swap probabilities based on temperature, while incorporating probabilistic edge-swaps to balance exploration and exploitation. It ensures feasibility through dynamic validation and repair, gradually focusing on local improvements as temperature decreases.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj1, obj2):\n        return max(0, obj1[0] - obj2[0]) * max(0, obj1[1] - obj2[1])\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    archive.sort(key=lambda x: (-hypervolume(x[1], (0, 0)), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    temperature = max(1.0, n / 10)\n    segment_size = max(2, min(n // 3, int(temperature)))\n    num_swaps = min(3, max(1, n // (segment_size * 2)))\n\n    for _ in range(num_swaps):\n        if random.random() < (0.8 * temperature / max(1.0, n / 5)):\n            seg1_start = random.randint(1, n - 2 * segment_size - 1)\n            seg2_start = random.randint(seg1_start + segment_size, n - segment_size - 1)\n\n            seg1 = new_solution[seg1_start:seg1_start+segment_size]\n            seg2 = new_solution[seg2_start:seg2_start+segment_size]\n\n            new_solution[seg1_start:seg1_start+segment_size] = seg2\n            new_solution[seg2_start:seg2_start+segment_size] = seg1\n\n            temperature *= 0.95\n\n    for _ in range(min(3, n // 2)):\n        i, j = random.sample(range(1, n-1), 2)\n        if random.random() < temperature:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            if random.random() < 0.3:\n                new_solution = np.concatenate([\n                    new_solution[:i],\n                    new_solution[j:j+1],\n                    new_solution[i+1:j],\n                    new_solution[i:i+1],\n                    new_solution[j+1:]\n                ])\n\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.8652254946245918,
            0.5802222490310669
        ]
    },
    {
        "algorithm": "The algorithm selects non-dominated solutions from the archive using hypervolume-based ranking, then applies a temperature-controlled hybrid local search with probabilistic segment operations (reverse, shift, swap, rotate, edge_swap) to generate neighbors, ensuring feasibility through dynamic repair of duplicate nodes. The temperature parameter adapts the search intensity based on solution quality, while segment size and operation selection are dynamically adjusted to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    selected = max(non_dominated, key=lambda x: hypervolume(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = 1.0 - (hypervolume(selected[1]) / (max(hypervolume(obj) for _, obj in archive) + 1e-6))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'rotate', 'swap', 'edge_swap'], weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            elif op == 'rotate':\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n            else:\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n                if random.random() < 0.3:\n                    new_solution = np.concatenate([\n                        new_solution[:a],\n                        new_solution[b:b+1],\n                        new_solution[a+1:b],\n                        new_solution[a:a+1],\n                        new_solution[b+1:]\n                    ])\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.8599462098775423,
            0.515205979347229
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from an archive using a novel objective improvement metric that combines normalized costs and problem size, then generates neighbors by adaptively applying segment reversals and probabilistic edge swaps, followed by multi-phase validation to ensure feasibility while preserving high-quality segments. The selection prioritizes solutions with balanced normalized objectives, while the local search emphasizes larger segments and distance-based probabilities, with validation phases repairing infeasibilities by prioritizing local and global segment recovery.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def objective_improvement(solution, obj):\n        norm_obj = (obj[0]/np.mean(distance_matrix_1), obj[1]/np.mean(distance_matrix_2))\n        return (norm_obj[0] + norm_obj[1]) * (1 - np.abs(norm_obj[0] - norm_obj[1])) * (len(solution)/100)\n\n    archive.sort(key=lambda x: -objective_improvement(x[0], x[1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    # Adaptive segment reversal with dynamic size\n    segment_size = max(2, int(n * 0.25))\n    num_reversals = min(3, max(1, n // segment_size))\n    for _ in range(num_reversals):\n        start = random.randint(1, n - segment_size - 1)\n        segment = new_solution[start:start+segment_size]\n        new_solution[start:start+segment_size] = segment[::-1]\n\n    # Probabilistic edge swaps with distance-based probability\n    for i in range(1, n-1):\n        swap_prob = 0.3 + 0.7 * (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[i-1], new_solution[i]]) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        if random.random() < swap_prob:\n            j = random.randint(1, n-1)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Multi-phase validation with segment recovery\n    if len(np.unique(new_solution)) != n:\n        # Phase 1: Local repair with distance-based selection\n        for i in range(1, n):\n            if new_solution[i] == new_solution[i-1]:\n                candidates = [node for node in base_solution if node not in new_solution[:i]]\n                if candidates:\n                    best_node = min(candidates, key=lambda x: distance_matrix_1[new_solution[i-1], x] + distance_matrix_2[new_solution[i-1], x])\n                    new_solution[i] = best_node\n\n        # Phase 2: Global segment recovery\n        if len(np.unique(new_solution)) != n:\n            missing = set(base_solution) - set(new_solution)\n            for node in missing:\n                best_pos = min(range(1, n), key=lambda pos: distance_matrix_1[new_solution[pos-1], node] + distance_matrix_1[node, new_solution[pos]] +\n                                                distance_matrix_2[new_solution[pos-1], node] + distance_matrix_2[node, new_solution[pos]])\n                new_solution[best_pos] = node\n\n    return new_solution\n\n",
        "score": [
            -0.9756508847866323,
            2.5381047129631042
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using hypervolume and crowding distance, then applies an adaptive 3-opt+ with probabilistic edge swaps to generate neighbors while ensuring tour feasibility through dynamic validation and repair. It prioritizes solutions with higher hypervolume and lower crowding distance, and uses temperature-based randomness to balance exploration and exploitation. The local search dynamically selects among reverse, shift, rotate, swap, and edge-swap operations, with repair mechanisms to maintain feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = 1.0 - (selected[2] / (max(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'rotate', 'swap', 'edge_swap'], weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            elif op == 'rotate':\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n            else:  # edge_swap\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n                if random.random() < 0.3:\n                    new_solution = np.concatenate([\n                        new_solution[:a],\n                        new_solution[b:b+1],\n                        new_solution[a+1:b],\n                        new_solution[a:a+1],\n                        new_solution[b+1:]\n                    ])\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.8556725245408373,
            0.5864564180374146
        ]
    }
]