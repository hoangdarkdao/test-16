[
     {
          "algorithm": "{This new algorithm will select a solution from the archive based on a hybrid selection criterion that combines objective values and solution diversity, then apply a novel \"objective-aware segment rotation\" operator that rotates a randomly selected segment of the tour by a variable number of positions, with acceptance based on Pareto dominance or significant improvement in one objective while allowing controlled worsening in the other, ensuring feasibility by maintaining node uniqueness and completeness throughout the operation.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Hybrid selection: balance between objective values and solution diversity\n    archive.sort(key=lambda x: -(x[1][0] * 0.6 + x[1][1] * 0.4 + random.random() * 0.1))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Objective-aware segment rotation\n    for _ in range(5):\n        i, j = sorted(random.sample(range(n), 2))\n        k = random.randint(1, j - i) if j - i > 1 else 1\n\n        # Calculate cost before rotation\n        cost1_before = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n        cost2_before = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n\n        # Rotate the segment\n        temp_sol = new_solution.copy()\n        segment = temp_sol[i:j+1]\n        rotated = np.concatenate([segment[k:], segment[:k]])\n        temp_sol[i:j+1] = rotated\n\n        # Calculate cost after rotation\n        cost1_after = sum(distance_matrix_1[temp_sol[k-1], temp_sol[k]] for k in range(i, j+1))\n        cost2_after = sum(distance_matrix_2[temp_sol[k-1], temp_sol[k]] for k in range(i, j+1))\n\n        # Accept if Pareto dominates or significant improvement in one objective with controlled worsening in the other\n        if (cost1_after < cost1_before and cost2_after <= cost2_before) or \\\n           (cost1_after <= cost1_before and cost2_after < cost2_before) or \\\n           (cost1_after < 0.9 * cost1_before and cost2_after < 1.1 * cost2_before) or \\\n           (cost2_after < 0.9 * cost2_before and cost1_after < 1.1 * cost1_before):\n            new_solution = temp_sol\n\n    # Ensure solution validity\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               -0.9910556685809437,
               0.7008278965950012
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive based on a novel multi-objective dominance metric that balances improvement potential in both objectives, then applies a hybrid local search operator that combines a dynamic path decomposition approach with a guided multi-segment relocation strategy, which intelligently reallocates segments of the tour between critical path components while maintaining feasibility, and finally incorporates an adaptive edge insertion mechanism that selectively inserts new edges between high-potential nodes while considering the trade-off between the two objectives through a probabilistic acceptance criterion.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select the most promising solution using a dominance-based metric\n    def dominance_metric(obj):\n        return -np.sqrt(obj[0]**2 + obj[1]**2)  # Negative for minimization\n\n    archive.sort(key=lambda x: dominance_metric(x[1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic path decomposition and segment relocation\n    if n > 3:\n        # Identify critical path components\n        critical_nodes = set()\n        for i in range(n):\n            node = base_solution[i]\n            prev_node = base_solution[i-1]\n            next_node = base_solution[(i+1)%n]\n\n            # Identify nodes that are critical in either objective\n            if (distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] > np.mean(distance_matrix_1) or\n                distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] > np.mean(distance_matrix_2)):\n                critical_nodes.add(node)\n\n        # Decompose the path into segments\n        segments = []\n        current_segment = [base_solution[0]]\n        for i in range(1, n):\n            if base_solution[i] in critical_nodes and len(current_segment) > 1:\n                segments.append(current_segment)\n                current_segment = [base_solution[i]]\n            else:\n                current_segment.append(base_solution[i])\n        segments.append(current_segment)\n\n        # Relocate segments between critical components\n        if len(segments) > 1:\n            seg_idx = random.randint(0, len(segments)-1)\n            segment = segments.pop(seg_idx)\n            insert_pos = random.randint(0, len(segments)-1)\n            segments.insert(insert_pos, segment)\n\n            # Reconstruct the solution\n            new_solution = np.concatenate(segments)\n\n    # Step 3: Adaptive edge insertion mechanism\n    if n > 3:\n        # Identify high-potential insertion points\n        insertion_points = []\n        for i in range(n):\n            node = new_solution[i]\n            next_node = new_solution[(i+1)%n]\n\n            # Potential insertion points are between non-critical nodes\n            if node not in critical_nodes and next_node not in critical_nodes:\n                insertion_points.append((i, (i+1)%n))\n\n        if insertion_points:\n            # Select a random insertion point\n            i, j = random.choice(insertion_points)\n\n            # Find a high-potential node to insert\n            candidate_nodes = list(set(range(n)) - set(new_solution))\n            if candidate_nodes:\n                new_node = random.choice(candidate_nodes)\n\n                # Calculate potential improvement\n                current_cost1 = distance_matrix_1[new_solution[i], new_solution[j]]\n                current_cost2 = distance_matrix_2[new_solution[i], new_solution[j]]\n\n                new_cost1 = (distance_matrix_1[new_solution[i], new_node] +\n                             distance_matrix_1[new_node, new_solution[j]])\n                new_cost2 = (distance_matrix_2[new_solution[i], new_node] +\n                             distance_matrix_2[new_node, new_solution[j]])\n\n                # Accept with probability based on improvement\n                improvement1 = current_cost1 - new_cost1\n                improvement2 = current_cost2 - new_cost2\n\n                if (improvement1 > 0 and improvement2 > 0) or \\\n                   (random.random() < 0.5 and (improvement1 > 0 or improvement2 > 0)):\n                    new_solution = np.insert(new_solution, j, new_node)\n\n    # Ensure solution validity\n    if len(np.unique(new_solution)) != n:\n        # Simple repair: reinsert missing nodes at random positions\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            pos = random.randint(0, len(new_solution))\n            new_solution = np.insert(new_solution, pos, node)\n\n    return new_solution\n\n",
          "score": [
               -1.0196944403878097,
               0.9443355202674866
          ]
     },
     {
          "algorithm": "{The new algorithm identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive segment crossover operator that dynamically determines segment lengths based on the relative costs of the two objectives, followed by a guided multi-edge swap heuristic that selectively exchanges edges between the two tours while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space. However, this new approach introduces a dynamic objective weighting mechanism that adapts during the search process based on the current Pareto front, and incorporates a novel \"multi-objective path relinking\" operator that combines features from multiple elite solutions to create a more diverse and high-quality neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic objective weighting mechanism\n    weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n    weight2 = 1 - weight1\n\n    # Step 3: Multi-objective path relinking operator\n    if n > 3:\n        # Select two elite solutions from the archive\n        elite_indices = sorted(range(len(archive)), key=lambda i: -(archive[i][1][0] + archive[i][1][1]))\n        elite1 = archive[elite_indices[0]][0]\n        elite2 = archive[elite_indices[1]][0] if len(elite_indices) > 1 else elite1\n\n        # Create a path between the two elite solutions\n        common_nodes = set(elite1) & set(elite2)\n        if len(common_nodes) > 0:\n            # Find the longest common subsequence\n            lcs = []\n            for node in elite1:\n                if node in common_nodes:\n                    lcs.append(node)\n                    common_nodes.remove(node)\n                    if not common_nodes:\n                        break\n\n            # Reconstruct solution by combining features from both elite solutions\n            new_solution = np.array(lcs)\n            remaining_nodes = [node for node in elite1 if node not in lcs] + [node for node in elite2 if node not in lcs]\n\n            # Insert remaining nodes based on weighted distance\n            for node in remaining_nodes:\n                best_pos = 0\n                best_score = float('inf')\n\n                for i in range(len(new_solution)):\n                    prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                    next_node = new_solution[i]\n\n                    cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                    cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                    score = weight1 * cost1 + weight2 * cost2\n\n                    if score < best_score:\n                        best_score = score\n                        best_pos = i\n\n                new_solution = np.insert(new_solution, best_pos, node)\n\n    # Step 4: Adaptive segment crossover with dynamic segment lengths\n    if n > 3:\n        # Adjust segment lengths based on current weights and solution quality\n        seg_length1 = max(2, min(5, int(weight1 * n * (1 + 0.1 * random.random()))))\n        seg_length2 = max(2, min(5, int(weight2 * n * (1 + 0.1 * random.random()))))\n\n        start1 = random.randint(0, n - seg_length1)\n        start2 = random.randint(0, n - seg_length2)\n\n        temp_sol = new_solution.copy()\n        temp_sol[start1:start1+seg_length1], temp_sol[start2:start2+seg_length2] = \\\n            temp_sol[start2:start2+seg_length2].copy(), temp_sol[start1:start1+seg_length1].copy()\n\n        # Accept if both objectives improve or if one improves significantly\n        current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n        current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n        new_cost1 = sum(distance_matrix_1[temp_sol[i-1], temp_sol[i]] for i in range(n))\n        new_cost2 = sum(distance_matrix_2[temp_sol[i-1], temp_sol[i]] for i in range(n))\n\n        if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or \\\n           (new_cost1 < current_cost1 * 0.9 and new_cost2 < current_cost2 * 1.1) or \\\n           (new_cost1 < current_cost1 * 1.1 and new_cost2 < current_cost2 * 0.9):\n            new_solution = temp_sol\n\n    # Step 5: Probabilistic repair with adaptive weights\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(len(new_solution)):\n                prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                # Adjust weights based on current solution quality\n                current_weight1 = weight1 * (1 + 0.1 * random.random())\n                current_weight2 = weight2 * (1 + 0.1 * random.random())\n\n                score = current_weight1 * cost1 + current_weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.9743259273690258,
               0.6736953854560852
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive path inversion operator that dynamically determines inversion segments based on the relative costs of the two objectives, followed by a guided multi-objective node insertion heuristic that selectively inserts nodes from one tour into another while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space, while also introducing a novel adaptive path inversion operator that dynamically determines inversion segments based on the relative costs of the two objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Adaptive path inversion operator\n    if n > 3:\n        # Determine inversion segment based on relative objective weights\n        weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n        weight2 = 1 - weight1\n\n        inv_length = max(2, min(5, int(weight1 * n) if random.random() < 0.5 else int(weight2 * n)))\n\n        start = random.randint(0, n - inv_length)\n        end = start + inv_length\n\n        # Invert the segment\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Step 3: Guided multi-objective node insertion heuristic\n    if n > 3:\n        # Select a random node to insert\n        node_to_insert = random.choice(new_solution)\n\n        # Find best insertion position considering both objectives\n        best_pos = 0\n        best_score = float('inf')\n\n        for i in range(n):\n            if i > 0 and i < n:\n                prev_node = new_solution[i-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node_to_insert] + distance_matrix_1[node_to_insert, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node_to_insert] + distance_matrix_2[node_to_insert, next_node] - distance_matrix_2[prev_node, next_node]\n\n                score = weight1 * cost1 + weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n        # Insert the node\n        new_solution = np.insert(new_solution, best_pos, node_to_insert)\n\n    # Step 4: Probabilistic repair mechanism\n    if len(np.unique(new_solution)) != n:\n        # Identify missing nodes\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            # Find insertion position based on both objectives\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(n):\n                prev_node = new_solution[i-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                score = weight1 * cost1 + weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            # Insert the missing node\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.8677974261494301,
               0.18009227514266968
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by selecting the one with the highest combined improvement potential, then applies a novel adaptive segment reversal operator that dynamically determines reversal segments based on the relative costs of the two objectives, followed by a guided multi-objective edge contraction heuristic that selectively contracts edges between nodes while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space, while also introducing a dynamic objective weighting mechanism that adapts during the search process based on the current Pareto front, and incorporating a novel \"multi-objective path merging\" operator that combines features from multiple elite solutions to create a more diverse and high-quality neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic objective weighting mechanism\n    weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n    weight2 = 1 - weight1\n\n    # Step 3: Adaptive segment reversal operator\n    if n > 3:\n        # Determine reversal segment based on relative objective weights\n        seg_length = max(2, min(5, int(weight1 * n) if random.random() < 0.5 else int(weight2 * n)))\n\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n\n        # Reverse the segment\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Step 4: Multi-objective edge contraction heuristic\n    if n > 4:\n        # Select two consecutive nodes to potentially contract\n        i = random.randint(0, n - 2)\n        node1, node2 = new_solution[i], new_solution[i+1]\n\n        # Calculate potential contraction cost\n        cost1 = distance_matrix_1[node1, node2]\n        cost2 = distance_matrix_2[node1, node2]\n\n        # Calculate current cost of the edges\n        prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n        next_node = new_solution[(i+2) % n]\n\n        current_cost1 = distance_matrix_1[prev_node, node1] + distance_matrix_1[node1, node2] + distance_matrix_1[node2, next_node]\n        current_cost2 = distance_matrix_2[prev_node, node1] + distance_matrix_2[node1, node2] + distance_matrix_2[node2, next_node]\n\n        new_cost1 = distance_matrix_1[prev_node, node2] + distance_matrix_1[node2, next_node]\n        new_cost2 = distance_matrix_2[prev_node, node2] + distance_matrix_2[node2, next_node]\n\n        # Calculate improvement\n        improvement1 = current_cost1 - new_cost1\n        improvement2 = current_cost2 - new_cost2\n\n        # Accept if both objectives improve or if one improves significantly\n        if (improvement1 > 0 and improvement2 > 0) or \\\n           (improvement1 > 0.1 * current_cost1 and improvement2 > -0.1 * current_cost2) or \\\n           (improvement1 > -0.1 * current_cost1 and improvement2 > 0.1 * current_cost2):\n            # Contract the edge by removing node1 and connecting prev_node to node2\n            new_solution = np.delete(new_solution, i)\n\n    # Step 5: Multi-objective path merging operator\n    if n > 3 and len(archive) > 1:\n        # Select another elite solution\n        elite_indices = sorted(range(len(archive)), key=lambda i: -(archive[i][1][0] + archive[i][1][1]))\n        elite2 = archive[elite_indices[min(1, len(elite_indices)-1)]][0]\n\n        # Find common nodes\n        common_nodes = set(new_solution) & set(elite2)\n        if len(common_nodes) > 0:\n            # Create merged path\n            merged_path = []\n            i, j = 0, 0\n\n            while i < len(new_solution) and j < len(elite2):\n                if new_solution[i] == elite2[j]:\n                    merged_path.append(new_solution[i])\n                    i += 1\n                    j += 1\n                elif new_solution[i] in common_nodes and elite2[j] in common_nodes:\n                    # Choose based on weighted distance\n                    cost1 = distance_matrix_1[merged_path[-1], new_solution[i]] if merged_path else 0\n                    cost2 = distance_matrix_2[merged_path[-1], new_solution[i]] if merged_path else 0\n                    score1 = weight1 * cost1 + weight2 * cost2\n\n                    cost1 = distance_matrix_1[merged_path[-1], elite2[j]] if merged_path else 0\n                    cost2 = distance_matrix_2[merged_path[-1], elite2[j]] if merged_path else 0\n                    score2 = weight1 * cost1 + weight2 * cost2\n\n                    if score1 < score2:\n                        merged_path.append(new_solution[i])\n                        i += 1\n                    else:\n                        merged_path.append(elite2[j])\n                        j += 1\n                elif new_solution[i] in common_nodes:\n                    merged_path.append(new_solution[i])\n                    i += 1\n                else:\n                    merged_path.append(elite2[j])\n                    j += 1\n\n            # Add remaining nodes\n            merged_path.extend(new_solution[i:])\n            merged_path.extend(elite2[j:])\n\n            # Update solution\n            new_solution = np.array(merged_path)\n\n    # Step 6: Probabilistic repair mechanism\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(len(new_solution)):\n                prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                # Adjust weights based on current solution quality\n                current_weight1 = weight1 * (1 + 0.1 * random.random())\n                current_weight2 = weight2 * (1 + 0.1 * random.random())\n\n                score = current_weight1 * cost1 + current_weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.9640835146920266,
               0.3065415024757385
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive segment crossover operator that dynamically determines segment lengths based on the relative costs of the two objectives, followed by a guided multi-edge swap heuristic that selectively exchanges edges between the two tours while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on non-dominated sorting\n    front = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            front.append(i)\n\n    if not front:\n        front = [0]  # Fallback to first solution if no non-dominated solutions\n\n    best_idx = random.choice(front)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Adaptive segment crossover with objective-aware segment selection\n    if n > 3:\n        obj1, obj2 = archive[best_idx][1]\n        total_obj = obj1 + obj2\n        if total_obj == 0:\n            weight1, weight2 = 0.5, 0.5\n        else:\n            weight1 = obj1 / total_obj\n            weight2 = obj2 / total_obj\n\n        seg_length = max(2, min(5, int(weight1 * n)))\n        start = random.randint(0, n - seg_length)\n\n        # Create a new segment by combining nodes from both objectives\n        new_segment = []\n        for i in range(seg_length):\n            if random.random() < weight1:\n                new_segment.append(new_solution[(start + i) % n])\n            else:\n                new_segment.append(new_solution[(start + i + seg_length) % n])\n\n        new_solution[start:start+seg_length] = new_segment\n\n    # Step 3: Multi-objective edge insertion heuristic\n    if n > 3:\n        # Select a random edge to remove\n        i = random.randint(0, n-1)\n        removed_node = new_solution[i]\n\n        # Find best insertion position considering both objectives\n        best_pos = 0\n        best_score = float('inf')\n\n        for j in range(n-1):\n            if j == i or j == (i-1) % n:\n                continue\n\n            prev_node = new_solution[j]\n            next_node = new_solution[(j+1) % n]\n\n            cost1 = distance_matrix_1[prev_node, removed_node] + distance_matrix_1[removed_node, next_node] - distance_matrix_1[prev_node, next_node]\n            cost2 = distance_matrix_2[prev_node, removed_node] + distance_matrix_2[removed_node, next_node] - distance_matrix_2[prev_node, next_node]\n\n            score = weight1 * cost1 + weight2 * cost2\n\n            if score < best_score:\n                best_score = score\n                best_pos = j + 1\n\n        # Insert the removed node at the best position\n        new_solution = np.insert(new_solution, best_pos, removed_node)\n        if best_pos <= i:\n            new_solution = np.delete(new_solution, i+1)\n        else:\n            new_solution = np.delete(new_solution, i)\n\n    # Step 4: Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = random.randint(0, n-1)\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.44041365474180505,
               0.18295890092849731
          ]
     },
     {
          "algorithm": "{The new algorithm begins by analyzing the archive to identify solutions with the most promising trade-off between the two objectives, then employs a novel \"objective-aware node reallocation\" strategy that dynamically redistributes nodes between the two objective spaces based on their relative importance, followed by a \"multi-objective edge contraction\" operator that selectively merges adjacent nodes while preserving feasibility, and finally incorporates an \"adaptive tour fusion\" mechanism that intelligently combines features from multiple elite solutions using a weighted consensus approach that considers both objective spaces, ensuring the generated neighbor solution maintains feasibility and explores the search space more effectively than standard approaches.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with best trade-off between objectives\n    best_idx = 0\n    best_ratio = float('inf')\n    for i, (sol, obj) in enumerate(archive):\n        ratio = max(obj[0]/(obj[1]+1e-10), obj[1]/(obj[0]+1e-10))\n        if ratio < best_ratio:\n            best_ratio = ratio\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Objective-aware node reallocation\n    if n > 3:\n        # Calculate node importance for each objective\n        node_importance1 = np.zeros(n)\n        node_importance2 = np.zeros(n)\n\n        for i in range(n):\n            prev = new_solution[i-1]\n            next_node = new_solution[(i+1)%n]\n            node_importance1[i] = distance_matrix_1[prev, new_solution[i]] + distance_matrix_1[new_solution[i], next_node]\n            node_importance2[i] = distance_matrix_2[prev, new_solution[i]] + distance_matrix_2[new_solution[i], next_node]\n\n        # Redistribute nodes based on importance\n        for i in range(n):\n            if random.random() < 0.3:  # 30% chance to reallocate\n                # Find best position considering both objectives\n                best_pos = i\n                best_score = float('inf')\n\n                for j in range(n):\n                    if j == i:\n                        continue\n\n                    # Calculate potential score\n                    prev_i = new_solution[i-1]\n                    next_i = new_solution[(i+1)%n]\n\n                    prev_j = new_solution[j-1]\n                    next_j = new_solution[(j+1)%n]\n\n                    # Current cost\n                    current_cost1 = distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                    current_cost2 = distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n\n                    # Potential new cost\n                    if i < j:\n                        # Insert after j\n                        new_cost1 = (distance_matrix_1[prev_j, new_solution[i]] + distance_matrix_1[new_solution[i], next_j] -\n                                    distance_matrix_1[prev_j, next_j])\n                        new_cost2 = (distance_matrix_2[prev_j, new_solution[i]] + distance_matrix_2[new_solution[i], next_j] -\n                                    distance_matrix_2[prev_j, next_j])\n                    else:\n                        # Insert before j\n                        new_cost1 = (distance_matrix_1[prev_i, next_i] - distance_matrix_1[prev_i, new_solution[i]] -\n                                    distance_matrix_1[new_solution[i], next_i] + distance_matrix_1[prev_i, new_solution[i]] +\n                                    distance_matrix_1[new_solution[i], new_solution[j]] + distance_matrix_1[new_solution[j], next_i])\n                        new_cost2 = (distance_matrix_2[prev_i, next_i] - distance_matrix_2[prev_i, new_solution[i]] -\n                                    distance_matrix_2[new_solution[i], next_i] + distance_matrix_2[prev_i, new_solution[i]] +\n                                    distance_matrix_2[new_solution[i], new_solution[j]] + distance_matrix_2[new_solution[j], next_i])\n\n                    # Weighted score\n                    weight1 = node_importance1[i] / (node_importance1[i] + node_importance2[i] + 1e-10)\n                    weight2 = 1 - weight1\n\n                    score = weight1 * new_cost1 + weight2 * new_cost2\n\n                    if score < best_score:\n                        best_score = score\n                        best_pos = j\n\n                # Perform the move\n                if best_pos != i:\n                    node = new_solution[i]\n                    new_solution = np.delete(new_solution, i)\n                    new_solution = np.insert(new_solution, best_pos, node)\n\n    # Step 3: Multi-objective edge contraction\n    if n > 4:\n        for _ in range(2):  # Try 2 contractions\n            i = random.randint(0, n-1)\n            j = (i + random.randint(2, min(4, n-1))) % n\n\n            # Calculate contraction cost\n            prev_i = new_solution[i-1]\n            next_i = new_solution[(i+1)%n]\n            prev_j = new_solution[j-1]\n            next_j = new_solution[(j+1)%n]\n\n            # Current cost\n            current_cost1 = (distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i] +\n                            distance_matrix_1[prev_j, new_solution[j]] + distance_matrix_1[new_solution[j], next_j])\n            current_cost2 = (distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i] +\n                            distance_matrix_2[prev_j, new_solution[j]] + distance_matrix_2[new_solution[j], next_j])\n\n            # Potential new cost\n            new_cost1 = (distance_matrix_1[prev_i, new_solution[j]] + distance_matrix_1[new_solution[j], next_i] -\n                        distance_matrix_1[prev_i, new_solution[i]] - distance_matrix_1[new_solution[i], next_i])\n            new_cost2 = (distance_matrix_2[prev_i, new_solution[j]] + distance_matrix_2[new_solution[j], next_i] -\n                        distance_matrix_2[prev_i, new_solution[i]] - distance_matrix_2[new_solution[i], next_i])\n\n            # Accept if both objectives improve\n            if new_cost1 < current_cost1 and new_cost2 < current_cost2:\n                # Contract the edges\n                if i < j:\n                    new_solution = np.delete(new_solution, slice(i+1, j))\n                else:\n                    new_solution = np.delete(new_solution, slice(i+1, n))\n                    new_solution = np.delete(new_solution, slice(0, j))\n                n = len(new_solution)\n\n    # Step 4: Adaptive tour fusion\n    if len(archive) > 1 and n > 3:\n        # Select another elite solution\n        elite_indices = sorted(range(len(archive)), key=lambda i: archive[i][1][0] + archive[i][1][1])\n        elite_idx = elite_indices[1] if len(elite_indices) > 1 else elite_indices[0]\n        elite_solution = archive[elite_idx][0]\n\n        # Create a weighted consensus tour\n        consensus = []\n        i = j = 0\n        while i < n and j < len(elite_solution):\n            if new_solution[i] == elite_solution[j]:\n                consensus.append(new_solution[i])\n                i += 1\n                j += 1\n            else:\n                # Choose based on importance\n                weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n                weight2 = 1 - weight1\n\n                if random.random() < weight1:\n                    consensus.append(new_solution[i])\n                    i += 1\n                else:\n                    consensus.append(elite_solution[j])\n                    j += 1\n\n        # Add remaining nodes\n        consensus.extend(new_solution[i:])\n        consensus.extend(elite_solution[j:])\n\n        # Remove duplicates while preserving order\n        seen = set()\n        unique_consensus = []\n        for node in consensus:\n            if node not in seen:\n                seen.add(node)\n                unique_consensus.append(node)\n\n        new_solution = np.array(unique_consensus[:n])\n\n    # Ensure solution is valid\n    if len(np.unique(new_solution)) != n:\n        # Reconstruct solution from scratch\n        remaining = list(range(n))\n        new_solution = np.zeros(n, dtype=int)\n        new_solution[0] = remaining.pop(random.randint(0, len(remaining)-1))\n\n        for i in range(1, n):\n            best_node = None\n            best_score = float('inf')\n\n            for node in remaining:\n                prev_node = new_solution[i-1]\n                cost1 = distance_matrix_1[prev_node, node]\n                cost2 = distance_matrix_2[prev_node, node]\n\n                weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n                weight2 = 1 - weight1\n\n                score = weight1 * cost1 + weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_node = node\n\n            new_solution[i] = best_node\n            remaining.remove(best_node)\n\n    return new_solution\n\n",
          "score": [
               -0.9967708161998995,
               5.318395137786865
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive segment crossover operator that dynamically determines segment lengths based on the relative costs of the two objectives, followed by a guided multi-edge swap heuristic that selectively exchanges edges between the two tours while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space. However, this new approach introduces a dynamic objective weighting mechanism that adapts during the search process based on the current Pareto front, and incorporates a novel \"multi-objective path relinking\" operator that combines features from multiple elite solutions to create a more diverse and high-quality neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic objective weighting mechanism\n    weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n    weight2 = 1 - weight1\n\n    # Step 3: Multi-objective path relinking operator\n    if n > 3:\n        # Select two elite solutions from the archive\n        elite_indices = sorted(range(len(archive)), key=lambda i: -(archive[i][1][0] + archive[i][1][1]))\n        elite1 = archive[elite_indices[0]][0]\n        elite2 = archive[elite_indices[1]][0] if len(elite_indices) > 1 else elite1\n\n        # Create a path between the two elite solutions\n        common_nodes = set(elite1) & set(elite2)\n        if len(common_nodes) > 0:\n            # Find the longest common subsequence\n            lcs = []\n            for node in elite1:\n                if node in common_nodes:\n                    lcs.append(node)\n                    common_nodes.remove(node)\n                    if not common_nodes:\n                        break\n\n            # Reconstruct solution by combining features from both elite solutions\n            new_solution = np.array(lcs)\n            remaining_nodes = [node for node in elite1 if node not in lcs] + [node for node in elite2 if node not in lcs]\n\n            # Insert remaining nodes based on weighted distance\n            for node in remaining_nodes:\n                best_pos = 0\n                best_score = float('inf')\n\n                for i in range(len(new_solution)):\n                    prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                    next_node = new_solution[i]\n\n                    cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                    cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                    score = weight1 * cost1 + weight2 * cost2\n\n                    if score < best_score:\n                        best_score = score\n                        best_pos = i\n\n                new_solution = np.insert(new_solution, best_pos, node)\n\n    # Step 4: Adaptive segment crossover with dynamic segment lengths\n    if n > 3:\n        # Adjust segment lengths based on current weights and solution quality\n        seg_length1 = max(2, min(5, int(weight1 * n * (1 + 0.1 * random.random()))))\n        seg_length2 = max(2, min(5, int(weight2 * n * (1 + 0.1 * random.random()))))\n\n        start1 = random.randint(0, n - seg_length1)\n        start2 = random.randint(0, n - seg_length2)\n\n        temp_sol = new_solution.copy()\n        temp_sol[start1:start1+seg_length1], temp_sol[start2:start2+seg_length2] = \\\n            temp_sol[start2:start2+seg_length2].copy(), temp_sol[start1:start1+seg_length1].copy()\n\n        # Accept if both objectives improve or if one improves significantly\n        current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n        current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n        new_cost1 = sum(distance_matrix_1[temp_sol[i-1], temp_sol[i]] for i in range(n))\n        new_cost2 = sum(distance_matrix_2[temp_sol[i-1], temp_sol[i]] for i in range(n))\n\n        if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or \\\n           (new_cost1 < current_cost1 * 0.9 and new_cost2 < current_cost2 * 1.1) or \\\n           (new_cost1 < current_cost1 * 1.1 and new_cost2 < current_cost2 * 0.9):\n            new_solution = temp_sol\n\n    # Step 5: Probabilistic repair with adaptive weights\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(len(new_solution)):\n                prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                # Adjust weights based on current solution quality\n                current_weight1 = weight1 * (1 + 0.1 * random.random())\n                current_weight2 = weight2 * (1 + 0.1 * random.random())\n\n                score = current_weight1 * cost1 + current_weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.9556855400746798,
               1.158942997455597
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive segment crossover operator that dynamically determines segment lengths based on the relative costs of the two objectives, followed by a guided multi-edge swap heuristic that selectively exchanges edges between the two tours while maintaining feasibility, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Adaptive segment crossover operator\n    if n > 3:\n        # Determine segment lengths based on relative objective weights\n        weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n        weight2 = 1 - weight1\n\n        seg_length1 = max(2, min(5, int(weight1 * n)))\n        seg_length2 = max(2, min(5, int(weight2 * n)))\n\n        # Randomly select segments\n        start1 = random.randint(0, n - seg_length1)\n        start2 = random.randint(0, n - seg_length2)\n\n        # Swap segments\n        new_solution[start1:start1+seg_length1], new_solution[start2:start2+seg_length2] = \\\n            new_solution[start2:start2+seg_length2].copy(), new_solution[start1:start1+seg_length1].copy()\n\n    # Step 3: Guided multi-edge swap heuristic\n    if n > 3:\n        # Select two random edges from each tour\n        i1, j1 = sorted(random.sample(range(n), 2))\n        i2, j2 = sorted(random.sample(range(n), 2))\n\n        # Calculate potential improvements\n        current_cost1 = distance_matrix_1[new_solution[i1-1], new_solution[i1]] + distance_matrix_1[new_solution[j1-1], new_solution[j1]]\n        current_cost2 = distance_matrix_2[new_solution[i1-1], new_solution[i1]] + distance_matrix_2[new_solution[j1-1], new_solution[j1]]\n\n        # Try swapping edges\n        temp_sol = new_solution.copy()\n        temp_sol[i1], temp_sol[j1] = temp_sol[j1], temp_sol[i1]\n\n        new_cost1 = distance_matrix_1[temp_sol[i1-1], temp_sol[i1]] + distance_matrix_1[temp_sol[j1-1], temp_sol[j1]]\n        new_cost2 = distance_matrix_2[temp_sol[i1-1], temp_sol[i1]] + distance_matrix_2[temp_sol[j1-1], temp_sol[j1]]\n\n        # Accept if both objectives improve or if one improves significantly\n        if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or \\\n           (new_cost1 < current_cost1 * 0.9 and new_cost2 < current_cost2 * 1.1) or \\\n           (new_cost1 < current_cost1 * 1.1 and new_cost2 < current_cost2 * 0.9):\n            new_solution = temp_sol\n\n    # Step 4: Probabilistic repair mechanism\n    if len(np.unique(new_solution)) != n:\n        # Identify missing nodes\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            # Find insertion position based on both objectives\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(n):\n                # Calculate insertion cost considering both objectives\n                prev_node = new_solution[i-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                # Weighted score based on relative objective importance\n                score = weight1 * cost1 + weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            # Insert the missing node\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.8752514100007711,
               0.4954751133918762
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating both objective values and selecting the one with the highest combined improvement potential, then applies a novel adaptive segment crossover operator that dynamically determines segment lengths based on the relative costs of the two objectives, followed by a guided multi-objective path relinking operator that combines features from multiple elite solutions to create a more diverse and high-quality neighbor solution, and finally incorporates a probabilistic repair mechanism to ensure solution validity by intelligently reinserting missing nodes or resolving conflicts based on the relative importance of each objective space, while introducing a dynamic objective weighting mechanism that adapts during the search process based on the current Pareto front and incorporating a novel \"multi-objective segment inversion\" operator that selectively inverts segments of the tour while considering the trade-off between the two objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined improvement potential\n    best_idx = 0\n    best_potential = float('-inf')\n    for i, (sol, obj) in enumerate(archive):\n        potential = -(obj[0] + obj[1])  # Negative for minimization\n        if potential > best_potential:\n            best_potential = potential\n            best_idx = i\n\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Dynamic objective weighting mechanism\n    weight1 = archive[best_idx][1][0] / (archive[best_idx][1][0] + archive[best_idx][1][1] + 1e-10)\n    weight2 = 1 - weight1\n\n    # Step 3: Multi-objective segment inversion operator\n    if n > 3:\n        # Determine segment length based on weights\n        seg_length = max(2, min(5, int(weight1 * n * (1 + 0.1 * random.random()))))\n\n        # Select random segment to invert\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n\n        # Create inverted segment\n        inverted_segment = new_solution[start:end][::-1]\n\n        # Evaluate the inversion\n        current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n        current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n        temp_sol = new_solution.copy()\n        temp_sol[start:end] = inverted_segment\n\n        new_cost1 = sum(distance_matrix_1[temp_sol[i-1], temp_sol[i]] for i in range(n))\n        new_cost2 = sum(distance_matrix_2[temp_sol[i-1], temp_sol[i]] for i in range(n))\n\n        # Accept if both objectives improve or if one improves significantly\n        if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or \\\n           (new_cost1 < current_cost1 * 0.9 and new_cost2 < current_cost2 * 1.1) or \\\n           (new_cost1 < current_cost1 * 1.1 and new_cost2 < current_cost2 * 0.9):\n            new_solution = temp_sol\n\n    # Step 4: Multi-objective path relinking operator\n    if n > 3:\n        # Select two elite solutions from the archive\n        elite_indices = sorted(range(len(archive)), key=lambda i: -(archive[i][1][0] + archive[i][1][1]))\n        elite1 = archive[elite_indices[0]][0]\n        elite2 = archive[elite_indices[1]][0] if len(elite_indices) > 1 else elite1\n\n        # Find common nodes\n        common_nodes = set(elite1) & set(elite2)\n        if len(common_nodes) > 0:\n            # Create a new solution by combining features\n            new_solution = np.array(list(common_nodes))\n            remaining_nodes = [node for node in elite1 if node not in common_nodes] + [node for node in elite2 if node not in common_nodes]\n\n            # Insert remaining nodes based on weighted distance\n            for node in remaining_nodes:\n                best_pos = 0\n                best_score = float('inf')\n\n                for i in range(len(new_solution)):\n                    prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                    next_node = new_solution[i]\n\n                    cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                    cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                    score = weight1 * cost1 + weight2 * cost2\n\n                    if score < best_score:\n                        best_score = score\n                        best_pos = i\n\n                new_solution = np.insert(new_solution, best_pos, node)\n\n    # Step 5: Probabilistic repair with adaptive weights\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_score = float('inf')\n\n            for i in range(len(new_solution)):\n                prev_node = new_solution[i-1] if i > 0 else new_solution[-1]\n                next_node = new_solution[i]\n\n                cost1 = distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] - distance_matrix_1[prev_node, next_node]\n                cost2 = distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] - distance_matrix_2[prev_node, next_node]\n\n                # Adjust weights based on current solution quality\n                current_weight1 = weight1 * (1 + 0.1 * random.random())\n                current_weight2 = weight2 * (1 + 0.1 * random.random())\n\n                score = current_weight1 * cost1 + current_weight2 * cost2\n\n                if score < best_score:\n                    best_score = score\n                    best_pos = i\n\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
          "score": [
               -0.9416093930681992,
               0.6625726819038391
          ]
     }
]