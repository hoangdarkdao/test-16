[
     {
          "algorithm": "{The new algorithm employs a multi-phase approach that combines probabilistic node selection, geometric transformation-based local search, and adaptive objective-weighted edge swapping to generate high-quality neighbors. It first identifies critical nodes based on their geometric properties and objective contributions, then applies a series of geometric transformations (scaling, rotation, and translation) to the solution's node coordinates in both objective spaces, followed by a targeted edge swapping phase that prioritizes edges with high potential for improving both objectives, with the swap probability dynamically adjusted based on the current solution's structure and the relative weights of the two objectives. The algorithm ensures feasibility by maintaining the permutation property and using a validation step to confirm the generated solution remains a valid TSP tour before returning it.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select base solution with probability based on objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    diversity = np.sum(np.abs(objectives[:, None] - objectives), axis=2)\n    probs = np.sum(diversity, axis=1)\n    probs = probs / np.sum(probs) if np.sum(probs) > 0 else np.ones(len(archive)) / len(archive)\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Geometric transformation phase\n    coords1 = instance[base_solution, :2]  # First objective coordinates\n    coords2 = instance[base_solution, 2:]  # Second objective coordinates\n\n    # Calculate centroids\n    centroid1 = np.mean(coords1, axis=0)\n    centroid2 = np.mean(coords2, axis=0)\n\n    # Apply random geometric transformations\n    if np.random.random() < 0.5:\n        # Scale transformation\n        scale_factor = np.random.uniform(0.9, 1.1)\n        coords1 = centroid1 + (coords1 - centroid1) * scale_factor\n        coords2 = centroid2 + (coords2 - centroid2) * scale_factor\n    else:\n        # Rotation transformation\n        angle = np.random.uniform(-np.pi/6, np.pi/6)\n        rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)],\n                                   [np.sin(angle), np.cos(angle)]])\n        coords1 = centroid1 + (coords1 - centroid1) @ rotation_matrix\n        coords2 = centroid2 + (coords2 - centroid2) @ rotation_matrix\n\n    # Find nearest nodes in transformed spaces\n    transformed_instance1 = np.hstack([coords1, instance[:, 2:]])\n    transformed_instance2 = np.hstack([instance[:, :2], coords2])\n\n    # Create distance matrices for transformed spaces\n    def create_distance_matrix(coords):\n        n = len(coords)\n        dist_matrix = np.zeros((n, n))\n        for i in range(n):\n            for j in range(n):\n                dist_matrix[i, j] = np.linalg.norm(coords[i] - coords[j])\n        return dist_matrix\n\n    transformed_dist1 = create_distance_matrix(transformed_instance1[base_solution, :2])\n    transformed_dist2 = create_distance_matrix(transformed_instance2[base_solution, 2:])\n\n    # Adaptive edge swapping phase\n    for _ in range(min(5, n // 2)):\n        # Calculate edge weights in both original and transformed spaces\n        edge_weights = []\n        for i in range(n):\n            j = (i + 1) % n\n            original_cost = distance_matrix_1[base_solution[i], base_solution[j]] + distance_matrix_2[base_solution[i], base_solution[j]]\n            transformed_cost = transformed_dist1[i, j] + transformed_dist2[i, j]\n            edge_weights.append(original_cost + transformed_cost)\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        # Select edges to swap with probability based on weights\n        if np.random.random() < 0.7:  # 70% chance for weighted selection\n            i = np.random.choice(n, p=edge_weights)\n        else:\n            i = np.random.randint(0, n)\n        j = (i + 1) % n\n\n        # Find best swap candidate\n        best_cost = float('inf')\n        best_k = -1\n\n        for k in range(n):\n            if k == i or k == j or k == (i-1)%n or k == (j+1)%n:\n                continue\n\n            # Create candidate solution\n            candidate = new_solution.copy()\n            candidate[i], candidate[j] = candidate[j], candidate[i]\n            candidate = np.roll(candidate, -i)\n            candidate = np.concatenate([candidate[:1], candidate[2:k+1], candidate[1:2], candidate[k+1:]])\n            candidate = np.roll(candidate, i)\n\n            # Check validity\n            if len(set(candidate)) != n:\n                continue\n\n            # Calculate cost\n            cost1 = sum(distance_matrix_1[candidate[l], candidate[l+1]] for l in range(n-1)) + distance_matrix_1[candidate[-1], candidate[0]]\n            cost2 = sum(distance_matrix_2[candidate[l], candidate[l+1]] for l in range(n-1)) + distance_matrix_2[candidate[-1], candidate[0]]\n            total_cost = cost1 + cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_k = k\n\n        if best_k != -1:\n            # Apply the best swap\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            new_solution = np.roll(new_solution, -i)\n            new_solution = np.concatenate([new_solution[:1], new_solution[2:best_k+1], new_solution[1:2], new_solution[best_k+1:]])\n            new_solution = np.roll(new_solution, i)\n\n    return new_solution\n\n",
          "score": [
               6.96520938589318,
               5.376564571653562
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a novel approach by combining adaptive tour partitioning with multi-objective aware node swapping and insertion, which first segments the solution into dynamic partitions based on the combined spatial proximity and edge strength in both objective spaces, then selectively swaps nodes between partitions while considering their potential to improve both objectives, followed by a guided node insertion phase that prioritizes nodes with complementary improvement potential in both objectives, while dynamically adjusting the insertion depth based on the current solution's structure and the relative improvement potential in both objectives. The algorithm ensures feasibility by maintaining the permutation property of TSP tours throughout the process and returns the improved neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Adaptive tour partitioning\n    from scipy.spatial.distance import pdist, squareform\n\n    # Calculate combined spatial proximity and edge strength\n    coords1 = instance[base_solution, :2]\n    coords2 = instance[base_solution, 2:]\n    dist1 = squareform(pdist(coords1))\n    dist2 = squareform(pdist(coords2))\n    combined_dist = 0.5 * dist1 + 0.5 * dist2\n\n    # Calculate edge strength in both objectives\n    edge_strength = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                edge_strength[i,j] = (distance_matrix_1[base_solution[i], base_solution[j]] +\n                                    distance_matrix_2[base_solution[i], base_solution[j]])\n\n    # Find partitions based on combined metrics\n    partition_size = max(3, min(7, n // 4))\n    partitions = []\n    for i in range(0, n, partition_size):\n        partition = base_solution[i:i+partition_size]\n        if len(partition) < 2:\n            continue\n\n        # Calculate partition strength\n        strength = sum(combined_dist[i,j] + edge_strength[i,j] for i in range(len(partition)-1) for j in range(i+1, len(partition)))\n        partitions.append((i, i+partition_size, strength))\n\n    # Sort partitions by strength (descending)\n    partitions.sort(key=lambda x: -x[2])\n\n    # Node swapping between partitions\n    for _ in range(min(3, len(partitions))):\n        if len(partitions) < 2:\n            break\n\n        # Select two partitions with high strength\n        part1_idx, part1_end, _ = partitions[0]\n        part2_idx, part2_end, _ = partitions[1]\n\n        # Select nodes from each partition\n        node1_idx = np.random.randint(part1_idx, part1_end)\n        node2_idx = np.random.randint(part2_idx, part2_end)\n\n        # Calculate potential improvement\n        old_cost = (distance_matrix_1[new_solution[node1_idx-1], new_solution[node1_idx]] +\n                    distance_matrix_1[new_solution[node1_idx], new_solution[(node1_idx+1)%n]] +\n                    distance_matrix_1[new_solution[node2_idx-1], new_solution[node2_idx]] +\n                    distance_matrix_1[new_solution[node2_idx], new_solution[(node2_idx+1)%n]] +\n                    distance_matrix_2[new_solution[node1_idx-1], new_solution[node1_idx]] +\n                    distance_matrix_2[new_solution[node1_idx], new_solution[(node1_idx+1)%n]] +\n                    distance_matrix_2[new_solution[node2_idx-1], new_solution[node2_idx]] +\n                    distance_matrix_2[new_solution[node2_idx], new_solution[(node2_idx+1)%n]])\n\n        # Try swapping the nodes\n        candidate = new_solution.copy()\n        candidate[node1_idx], candidate[node2_idx] = candidate[node2_idx], candidate[node1_idx]\n\n        new_cost = (distance_matrix_1[candidate[node1_idx-1], candidate[node1_idx]] +\n                   distance_matrix_1[candidate[node1_idx], candidate[(node1_idx+1)%n]] +\n                   distance_matrix_1[candidate[node2_idx-1], candidate[node2_idx]] +\n                   distance_matrix_1[candidate[node2_idx], candidate[(node2_idx+1)%n]] +\n                   distance_matrix_2[candidate[node1_idx-1], candidate[node1_idx]] +\n                   distance_matrix_2[candidate[node1_idx], candidate[(node1_idx+1)%n]] +\n                   distance_matrix_2[candidate[node2_idx-1], candidate[node2_idx]] +\n                   distance_matrix_2[candidate[node2_idx], candidate[(node2_idx+1)%n]])\n\n        if new_cost < old_cost:\n            new_solution = candidate\n\n    # Guided node insertion\n    for _ in range(min(5, n//3)):\n        i = np.random.randint(0, n)\n        node = new_solution[i]\n\n        # Calculate current costs\n        current_cost1 = (distance_matrix_1[new_solution[i-1], new_solution[i]] +\n                        distance_matrix_1[new_solution[i], new_solution[(i+1)%n]])\n        current_cost2 = (distance_matrix_2[new_solution[i-1], new_solution[i]] +\n                        distance_matrix_2[new_solution[i], new_solution[(i+1)%n]])\n\n        # Remove the node\n        candidate = np.delete(new_solution, i)\n\n        # Find the best position to reinsert the node\n        best_pos = None\n        best_cost = float('inf')\n\n        for j in range(len(candidate)):\n            temp = np.insert(candidate, j, node)\n            temp_cost1 = (distance_matrix_1[temp[j-1], temp[j]] +\n                         distance_matrix_1[temp[j], temp[(j+1)%len(temp)]])\n            temp_cost2 = (distance_matrix_2[temp[j-1], temp[j]] +\n                         distance_matrix_2[temp[j], temp[(j+1)%len(temp)]])\n\n            # Dynamic insertion depth based on improvement potential\n            improvement_ratio = (current_cost1 - temp_cost1) / current_cost1 + (current_cost2 - temp_cost2) / current_cost2\n            depth = max(1, min(3, int(2 * improvement_ratio)))\n\n            # Consider positions within the depth range\n            for k in range(max(0, j-depth), min(len(temp), j+depth+1)):\n                if k != j:\n                    temp2 = np.insert(candidate, k, node)\n                    temp2_cost1 = (distance_matrix_1[temp2[k-1], temp2[k]] +\n                                 distance_matrix_1[temp2[k], temp2[(k+1)%len(temp2)]])\n                    temp2_cost2 = (distance_matrix_2[temp2[k-1], temp2[k]] +\n                                 distance_matrix_2[temp2[k], temp2[(k+1)%len(temp2)]])\n\n                    if temp2_cost1 + temp2_cost2 < best_cost:\n                        best_cost = temp2_cost1 + temp2_cost2\n                        best_pos = k\n\n        if best_pos is not None:\n            new_solution = np.insert(candidate, best_pos, node)\n\n    # Ensure the solution is valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               6.762487469458119,
               5.627394968801918
          ]
     },
     {
          "algorithm": "{The new algorithm employs a hierarchical clustering-based approach to partition the solution into multi-level segments, where each segment is defined by both spatial proximity in the two objective spaces and the relative strength of edges between nodes. It then performs a novel multi-phase local search that combines adaptive segment merging with probabilistic node relocation, where nodes are moved between segments based on their potential to improve both objectives while maintaining tour feasibility, followed by a constrained edge swapping phase that prioritizes moves which simultaneously enhance the solution's quality in both objective spaces, with the segment hierarchy dynamically adapting during the search process to better guide the exploration of the solution space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hierarchical clustering-based segmentation\n    from scipy.cluster.hierarchy import linkage, fcluster\n    from scipy.spatial.distance import pdist, squareform\n\n    # Calculate distance matrices for both objectives\n    coords1 = instance[base_solution, :2]\n    coords2 = instance[base_solution, 2:]\n    dist1 = squareform(pdist(coords1))\n    dist2 = squareform(pdist(coords2))\n    combined_dist = (dist1 + dist2) / 2\n\n    # Perform hierarchical clustering\n    Z = linkage(combined_dist, 'ward')\n    max_d = 0.7 * max(Z[:, 2])\n    clusters = fcluster(Z, max_d, criterion='distance')\n\n    # Create segments from clusters\n    segments = []\n    for cluster_id in np.unique(clusters):\n        segment_indices = np.where(clusters == cluster_id)[0]\n        if len(segment_indices) > 1:\n            segments.append((segment_indices.min(), segment_indices.max() + 1))\n\n    # Sort segments by size (descending)\n    segments.sort(key=lambda x: -(x[1] - x[0]))\n\n    # Adaptive segment merging\n    for _ in range(min(2, len(segments))):\n        if len(segments) < 2:\n            break\n\n        # Select two adjacent segments\n        seg1_start, seg1_end = segments[0]\n        seg2_start, seg2_end = segments[1]\n\n        if seg1_end == seg2_start:\n            # Merge segments\n            new_segment = (seg1_start, seg2_end)\n            segments = [new_segment] + segments[2:]\n            segments.sort(key=lambda x: -(x[1] - x[0]))\n\n    # Multi-phase local search\n    # Phase 1: Probabilistic node relocation\n    for _ in range(min(3, n//2)):\n        # Select a random segment\n        if not segments:\n            break\n\n        seg_start, seg_end = segments[np.random.randint(len(segments))]\n        if seg_end - seg_start < 2:\n            continue\n\n        # Select a node to relocate\n        node_idx = np.random.randint(seg_start, seg_end)\n        node = new_solution[node_idx]\n\n        # Remove the node\n        candidate = np.delete(new_solution, node_idx)\n\n        # Find best insertion position in another segment\n        best_pos = -1\n        best_cost = float('inf')\n\n        for other_seg_start, other_seg_end in segments:\n            if other_seg_start == seg_start and other_seg_end == seg_end:\n                continue\n\n            for pos in range(other_seg_start, other_seg_end):\n                if pos == node_idx or pos == node_idx-1:\n                    continue\n\n                temp = np.insert(candidate, pos, node)\n                cost1 = sum(distance_matrix_1[temp[i], temp[i+1]] for i in range(n-1)) + distance_matrix_1[temp[-1], temp[0]]\n                cost2 = sum(distance_matrix_2[temp[i], temp[i+1]] for i in range(n-1)) + distance_matrix_2[temp[-1], temp[0]]\n\n                if cost1 + cost2 < best_cost:\n                    best_cost = cost1 + cost2\n                    best_pos = pos\n\n        if best_pos != -1:\n            new_solution = np.insert(candidate, best_pos, node)\n\n    # Phase 2: Constrained edge swapping\n    for _ in range(min(5, n//3)):\n        # Select two edges to swap\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        while abs(i - j) < 2:\n            j = np.random.randint(0, n)\n\n        # Calculate potential improvement\n        old_edges = [(new_solution[i-1], new_solution[i]), (new_solution[j-1], new_solution[j])]\n        new_edges = [(new_solution[i-1], new_solution[j]), (new_solution[i], new_solution[j-1])]\n\n        old_cost = (distance_matrix_1[old_edges[0][0], old_edges[0][1]] + distance_matrix_1[old_edges[1][0], old_edges[1][1]] +\n                    distance_matrix_2[old_edges[0][0], old_edges[0][1]] + distance_matrix_2[old_edges[1][0], old_edges[1][1]])\n\n        new_cost = (distance_matrix_1[new_edges[0][0], new_edges[0][1]] + distance_matrix_1[new_edges[1][0], new_edges[1][1]] +\n                    distance_matrix_2[new_edges[0][0], new_edges[0][1]] + distance_matrix_2[new_edges[1][0], new_edges[1][1]])\n\n        # Accept move if it improves both objectives or with probability\n        if new_cost < old_cost or np.random.random() < min(0.4, 0.1 + (old_cost - new_cost) / old_cost):\n            # Swap the edges\n            new_solution[i:j] = new_solution[i:j][::-1]\n\n    # Ensure the solution is valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               6.456601358394835,
               5.726033516699377
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a novel approach that combines hierarchical clustering of nodes based on their multi-objective distances with a guided segment inversion strategy, followed by a probabilistic edge reversal process that dynamically adjusts its intensity based on the current solution's objective trade-off characteristics, and concludes with a constrained node reinsertion phase that prioritizes positions with complementary improvement potential across both objectives, while maintaining feasibility through a permutation-aware validation mechanism.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select base solution based on normalized objective values\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = normalized_obj[:, 0] + normalized_obj[:, 1]\n    base_solution = archive[np.argmin(scores)][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hierarchical clustering of nodes\n    from scipy.cluster.hierarchy import linkage, fcluster\n\n    # Calculate multi-objective distances\n    multi_dist = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            multi_dist[i, j] = (distance_matrix_1[i, j] + distance_matrix_2[i, j]) / 2\n\n    # Perform hierarchical clustering\n    Z = linkage(multi_dist, 'ward')\n    clusters = fcluster(Z, t=2, criterion='maxclust')\n\n    # Guided segment inversion based on clusters\n    for _ in range(2):\n        # Select a random cluster\n        cluster_id = np.random.choice(np.unique(clusters))\n        cluster_indices = np.where(clusters == cluster_id)[0]\n\n        if len(cluster_indices) < 3:\n            continue\n\n        # Select a segment within the cluster\n        start = np.random.choice(cluster_indices[:-1])\n        end = np.random.choice(cluster_indices[cluster_indices > start])\n\n        # Calculate current cost\n        current_cost = 0\n        for i in range(start, end):\n            current_cost += distance_matrix_1[new_solution[i], new_solution[i+1]] + distance_matrix_2[new_solution[i], new_solution[i+1]]\n        current_cost += distance_matrix_1[new_solution[end], new_solution[start]] + distance_matrix_2[new_solution[end], new_solution[start]]\n\n        # Invert the segment\n        candidate = new_solution.copy()\n        candidate[start:end+1] = candidate[start:end+1][::-1]\n\n        # Calculate new cost\n        new_cost = 0\n        for i in range(start, end):\n            new_cost += distance_matrix_1[candidate[i], candidate[i+1]] + distance_matrix_2[candidate[i], candidate[i+1]]\n        new_cost += distance_matrix_1[candidate[end], candidate[start]] + distance_matrix_2[candidate[end], candidate[start]]\n\n        if new_cost < current_cost:\n            new_solution = candidate\n\n    # Probabilistic edge reversal with dynamic intensity\n    for _ in range(3):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        while abs(i - j) < 2:\n            j = np.random.randint(0, n)\n\n        # Calculate objective trade-off\n        obj1_ratio = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j-1], new_solution[j]]) / \\\n                     (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[j-1]])\n        obj2_ratio = (distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j-1], new_solution[j]]) / \\\n                     (distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[j-1]])\n\n        # Dynamic reversal probability\n        reversal_prob = min(0.8, 0.2 + 0.6 * (1 - abs(obj1_ratio - obj2_ratio)))\n\n        if np.random.random() < reversal_prob:\n            new_solution[i:j] = new_solution[i:j][::-1]\n\n    # Constrained node reinsertion with objective-aware position selection\n    for _ in range(2):\n        # Select a random node\n        idx = np.random.randint(1, n-1)\n        node = new_solution[idx]\n\n        # Remove the node\n        candidate = np.concatenate([new_solution[:idx], new_solution[idx+1:]])\n\n        # Find best insertion position\n        best_pos = -1\n        best_score = float('inf')\n\n        for pos in range(n-1):\n            if pos == idx or pos == idx-1:\n                continue\n\n            # Insert node at position pos\n            temp = np.insert(candidate, pos, node)\n\n            # Calculate objective scores\n            cost1 = sum(distance_matrix_1[temp[i], temp[i+1]] for i in range(n-1)) + distance_matrix_1[temp[-1], temp[0]]\n            cost2 = sum(distance_matrix_2[temp[i], temp[i+1]] for i in range(n-1)) + distance_matrix_2[temp[-1], temp[0]]\n\n            # Normalize scores\n            norm_cost1 = (cost1 - distance_matrix_1.min()) / (distance_matrix_1.max() - distance_matrix_1.min() + 1e-8)\n            norm_cost2 = (cost2 - distance_matrix_2.min()) / (distance_matrix_2.max() - distance_matrix_2.min() + 1e-8)\n\n            # Combined score with trade-off consideration\n            score = norm_cost1 + norm_cost2 + 0.3 * abs(norm_cost1 - norm_cost2)\n\n            if score < best_score:\n                best_score = score\n                best_pos = pos\n\n        if best_pos != -1:\n            new_solution = np.insert(candidate, best_pos, node)\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               5.915367991787147,
               5.848319274999013
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a novel approach by combining hierarchical clustering with multi-objective aware edge inversion and selective node reinsertion, which first organizes the solution into hierarchical clusters based on the combined spatial proximity and edge strength in both objective spaces, then selectively inverts entire clusters while considering their potential to improve both objectives, followed by a targeted node reinsertion phase that prioritizes nodes from different clusters with complementary improvement potential in both objectives, while dynamically adjusting the insertion position based on the current solution's hierarchical structure and the relative improvement potential in both objectives. The algorithm ensures feasibility by maintaining the permutation property of TSP tours throughout the process and returns the improved neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hierarchical clustering\n    from scipy.cluster.hierarchy import linkage, fcluster\n    from scipy.spatial.distance import pdist, squareform\n\n    # Calculate combined spatial proximity and edge strength\n    coords1 = instance[base_solution, :2]\n    coords2 = instance[base_solution, 2:]\n    dist1 = squareform(pdist(coords1))\n    dist2 = squareform(pdist(coords2))\n    combined_dist = 0.5 * dist1 + 0.5 * dist2\n\n    # Calculate edge strength in both objectives\n    edge_strength = np.zeros((n, n))\n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                edge_strength[i,j] = (distance_matrix_1[base_solution[i], base_solution[j]] +\n                                    distance_matrix_2[base_solution[i], base_solution[j]])\n\n    # Create distance matrix for clustering\n    cluster_dist = combined_dist + edge_strength\n\n    # Perform hierarchical clustering\n    Z = linkage(cluster_dist, 'ward')\n    max_d = 0.7 * np.max(Z[:, 2])\n    clusters = fcluster(Z, max_d, criterion='distance')\n\n    # Get unique cluster IDs\n    unique_clusters = np.unique(clusters)\n    if len(unique_clusters) < 2:\n        return new_solution\n\n    # Cluster inversion\n    for _ in range(min(3, len(unique_clusters))):\n        # Select two different clusters\n        cluster_ids = np.random.choice(unique_clusters, size=2, replace=False)\n        cluster1 = np.where(clusters == cluster_ids[0])[0]\n        cluster2 = np.where(clusters == cluster_ids[1])[0]\n\n        if len(cluster1) < 1 or len(cluster2) < 1:\n            continue\n\n        # Calculate potential improvement\n        old_cost = 0\n        for i in range(len(base_solution)):\n            j = (i + 1) % n\n            if (i in cluster1 and j in cluster1) or (i in cluster2 and j in cluster2):\n                continue\n            old_cost += distance_matrix_1[base_solution[i], base_solution[j]] + distance_matrix_2[base_solution[i], base_solution[j]]\n\n        # Invert one of the clusters\n        candidate = new_solution.copy()\n        if np.random.random() < 0.5:\n            candidate[cluster1] = candidate[cluster1][::-1]\n        else:\n            candidate[cluster2] = candidate[cluster2][::-1]\n\n        new_cost = 0\n        for i in range(len(candidate)):\n            j = (i + 1) % n\n            new_cost += distance_matrix_1[candidate[i], candidate[j]] + distance_matrix_2[candidate[i], candidate[j]]\n\n        if new_cost < old_cost:\n            new_solution = candidate\n\n    # Selective node reinsertion\n    for _ in range(min(5, n//3)):\n        # Select a node from one cluster\n        cluster_id = np.random.choice(unique_clusters)\n        cluster_nodes = np.where(clusters == cluster_id)[0]\n        if len(cluster_nodes) < 2:\n            continue\n\n        node_idx = np.random.choice(cluster_nodes)\n        node = new_solution[node_idx]\n\n        # Calculate current costs\n        current_cost1 = (distance_matrix_1[new_solution[node_idx-1], new_solution[node_idx]] +\n                        distance_matrix_1[new_solution[node_idx], new_solution[(node_idx+1)%n]])\n        current_cost2 = (distance_matrix_2[new_solution[node_idx-1], new_solution[node_idx]] +\n                        distance_matrix_2[new_solution[node_idx], new_solution[(node_idx+1)%n]])\n\n        # Remove the node\n        candidate = np.delete(new_solution, node_idx)\n\n        # Find best position to reinsert from a different cluster\n        best_pos = None\n        best_cost = float('inf')\n\n        for cluster_id2 in unique_clusters:\n            if cluster_id2 == cluster_id:\n                continue\n\n            cluster_nodes2 = np.where(clusters == cluster_id2)[0]\n            if len(cluster_nodes2) < 1:\n                continue\n\n            # Consider positions near nodes from the other cluster\n            for pos in cluster_nodes2:\n                for offset in [-1, 0, 1]:\n                    actual_pos = (pos + offset) % len(candidate)\n                    temp = np.insert(candidate, actual_pos, node)\n                    temp_cost1 = (distance_matrix_1[temp[actual_pos-1], temp[actual_pos]] +\n                                distance_matrix_1[temp[actual_pos], temp[(actual_pos+1)%len(temp)]])\n                    temp_cost2 = (distance_matrix_2[temp[actual_pos-1], temp[actual_pos]] +\n                                distance_matrix_2[temp[actual_pos], temp[(actual_pos+1)%len(temp)]])\n\n                    if temp_cost1 + temp_cost2 < best_cost:\n                        best_cost = temp_cost1 + temp_cost2\n                        best_pos = actual_pos\n\n        if best_pos is not None:\n            new_solution = np.insert(candidate, best_pos, node)\n\n    # Ensure the solution is valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               5.782559088643776,
               6.4433598625867035
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with probability proportional to its potential for improvement\n    scores = []\n    for sol, _ in archive:\n        # Calculate diversity score (number of unique edges not in other solutions)\n        diversity = 0\n        edges = set(zip(sol, np.roll(sol, -1)))\n        for other_sol, _ in archive:\n            other_edges = set(zip(other_sol, np.roll(other_sol, -1)))\n            diversity += len(edges - other_edges)\n        scores.append(diversity)\n\n    if all(s == 0 for s in scores):\n        # If all solutions are identical, select randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Normalize scores and select with probability\n        total = sum(scores)\n        probs = [s / total for s in scores]\n        idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search strategy\n    if random.random() < 0.7:  # 70% chance for segment relocation\n        # Select segment length based on instance size\n        max_segment = min(5, n // 4)\n        segment_length = random.randint(2, max_segment)\n\n        # Select random segment\n        start = random.randint(0, n - segment_length)\n        segment = new_solution[start:start+segment_length]\n\n        # Find best insertion position that improves both objectives\n        best_cost = float('inf')\n        best_pos = -1\n\n        for pos in range(n - segment_length + 1):\n            if pos >= start and pos < start + segment_length:\n                continue  # Skip current position\n\n            # Create candidate solution\n            candidate = np.concatenate([\n                new_solution[:pos],\n                segment,\n                new_solution[pos:start],\n                new_solution[start+segment_length:]\n            ])\n\n            # Calculate cost\n            cost1 = sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(n-1))\n            cost1 += distance_matrix_1[candidate[-1], candidate[0]]  # Complete the tour\n\n            cost2 = sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(n-1))\n            cost2 += distance_matrix_2[candidate[-1], candidate[0]]\n\n            total_cost = cost1 + cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_pos = pos\n\n        if best_pos != -1 and best_cost < float('inf'):\n            # Apply the best move\n            new_solution = np.concatenate([\n                new_solution[:best_pos],\n                segment,\n                new_solution[best_pos:start],\n                new_solution[start+segment_length:]\n            ])\n    else:  # Edge insertion\n        # Select random edge to remove\n        i = random.randint(0, n-1)\n        j = (i + 1) % n\n\n        # Select random node to insert between\n        k = random.randint(0, n-1)\n        while k == i or k == j or k == (i-1)%n:\n            k = random.randint(0, n-1)\n\n        # Create candidate solution\n        candidate = new_solution.copy()\n        candidate[i], candidate[j] = candidate[j], candidate[i]  # Reverse the edge\n        candidate = np.roll(candidate, -i)  # Make i the first element\n        candidate = np.concatenate([candidate[:1], candidate[2:k+1], candidate[1:2], candidate[k+1:]])\n        candidate = np.roll(candidate, i)  # Restore original order\n\n        # Check if the move is valid (visits all nodes exactly once)\n        if len(set(candidate)) == n:\n            new_solution = candidate\n\n    return new_solution\n\n",
          "score": [
               6.602584769458544,
               5.827298074802924
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a novel approach by combining hierarchical clustering with multi-objective aware edge contraction and expansion. It first partitions the solution into hierarchical clusters based on spatial proximity in both objective spaces, then selectively contracts and expands edges between clusters to balance the trade-off between the two objectives, followed by a guided node reinsertion process that prioritizes nodes with complementary improvement potential in both objectives, while dynamically adjusting the reinsertion depth based on the current solution's structure and the relative improvement potential in both objectives. The algorithm ensures feasibility by maintaining the permutation property of TSP tours throughout the process and returns the improved neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hierarchical clustering based on spatial proximity in both objectives\n    from scipy.cluster.hierarchy import linkage, fcluster\n\n    # Calculate pairwise distances in both objective spaces\n    coords1 = instance[base_solution, :2]\n    coords2 = instance[base_solution, 2:]\n    dist1 = np.sqrt(np.sum((coords1[:, np.newaxis, :] - coords1[np.newaxis, :, :])**2, axis=2))\n    dist2 = np.sqrt(np.sum((coords2[:, np.newaxis, :] - coords2[np.newaxis, :, :])**2, axis=2))\n    combined_dist = 0.5 * dist1 + 0.5 * dist2\n\n    # Perform hierarchical clustering\n    Z = linkage(combined_dist[np.triu_indices(n, k=1)], method='average')\n    clusters = fcluster(Z, t=0.5 * np.max(Z[:, 2]), criterion='distance')\n\n    # Identify cluster boundaries\n    cluster_boundaries = []\n    current_cluster = clusters[0]\n    for i in range(1, n):\n        if clusters[i] != current_cluster:\n            cluster_boundaries.append(i)\n            current_cluster = clusters[i]\n\n    # Edge contraction and expansion\n    for _ in range(min(3, len(cluster_boundaries))):\n        if not cluster_boundaries:\n            break\n\n        # Select a random boundary\n        boundary_idx = np.random.choice(cluster_boundaries)\n        i = boundary_idx - 1\n        j = boundary_idx\n\n        # Calculate current costs\n        current_cost1 = distance_matrix_1[new_solution[i], new_solution[j]]\n        current_cost2 = distance_matrix_2[new_solution[i], new_solution[j]]\n\n        # Try contracting the edge (remove it)\n        candidate = np.delete(new_solution, j)\n        cost1 = sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(len(candidate)-1)) + distance_matrix_1[candidate[-1], candidate[0]]\n        cost2 = sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(len(candidate)-1)) + distance_matrix_2[candidate[-1], candidate[0]]\n\n        # Try expanding the edge (add a new node)\n        if len(candidate) < n:\n            # Find the node that would best improve the solution\n            best_node = None\n            best_cost = float('inf')\n\n            for node in range(n):\n                if node not in candidate:\n                    # Try inserting the node between i and j\n                    temp = np.insert(candidate, i+1, node)\n                    temp_cost1 = sum(distance_matrix_1[temp[i], temp[i+1]] for i in range(len(temp)-1)) + distance_matrix_1[temp[-1], temp[0]]\n                    temp_cost2 = sum(distance_matrix_2[temp[i], temp[i+1]] for i in range(len(temp)-1)) + distance_matrix_2[temp[-1], temp[0]]\n\n                    if temp_cost1 + temp_cost2 < best_cost:\n                        best_cost = temp_cost1 + temp_cost2\n                        best_node = node\n\n            if best_node is not None:\n                candidate = np.insert(candidate, i+1, best_node)\n\n        # Choose the better option\n        if cost1 + cost2 < best_cost:\n            new_solution = candidate\n        else:\n            new_solution = np.insert(candidate, i+1, best_node)\n\n    # Guided node reinsertion\n    for _ in range(min(5, n//2)):\n        i = np.random.randint(0, n)\n        node = new_solution[i]\n\n        # Calculate current costs\n        current_cost1 = (distance_matrix_1[new_solution[i-1], new_solution[i]] +\n                         distance_matrix_1[new_solution[i], new_solution[(i+1)%n]])\n        current_cost2 = (distance_matrix_2[new_solution[i-1], new_solution[i]] +\n                         distance_matrix_2[new_solution[i], new_solution[(i+1)%n]])\n\n        # Remove the node\n        candidate = np.delete(new_solution, i)\n\n        # Find the best position to reinsert the node\n        best_pos = None\n        best_cost = float('inf')\n\n        for j in range(len(candidate)):\n            temp = np.insert(candidate, j, node)\n            temp_cost1 = (distance_matrix_1[temp[j-1], temp[j]] +\n                         distance_matrix_1[temp[j], temp[(j+1)%len(temp)]])\n            temp_cost2 = (distance_matrix_2[temp[j-1], temp[j]] +\n                         distance_matrix_2[temp[j], temp[(j+1)%len(temp)]])\n\n            # Dynamic reinsertion depth based on improvement potential\n            improvement_ratio = (current_cost1 - temp_cost1) / current_cost1 + (current_cost2 - temp_cost2) / current_cost2\n            depth = max(1, min(3, int(2 * improvement_ratio)))\n\n            # Consider positions within the depth range\n            for k in range(max(0, j-depth), min(len(temp), j+depth+1)):\n                if k != j:\n                    temp2 = np.insert(candidate, k, node)\n                    temp2_cost1 = (distance_matrix_1[temp2[k-1], temp2[k]] +\n                                  distance_matrix_1[temp2[k], temp2[(k+1)%len(temp2)]])\n                    temp2_cost2 = (distance_matrix_2[temp2[k-1], temp2[k]] +\n                                  distance_matrix_2[temp2[k], temp2[(k+1)%len(temp2)]])\n\n                    if temp2_cost1 + temp2_cost2 < best_cost:\n                        best_cost = temp2_cost1 + temp2_cost2\n                        best_pos = k\n\n        if best_pos is not None:\n            new_solution = np.insert(candidate, best_pos, node)\n\n    # Ensure the solution is valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               6.064051003022471,
               6.274244567844251
          ]
     },
     {
          "algorithm": "{The new algorithm builds upon the common backbone idea of selecting a promising solution from the archive and applying a hybrid local search strategy, but it introduces a novel approach by combining adaptive path decomposition with multi-objective aware edge flipping. The algorithm first decomposes the solution into adaptive path segments based on their contribution to both objectives, then selectively flips edges between segments to balance the trade-off between the two objectives, followed by a guided node swapping process that prioritizes nodes with complementary improvement potential in both objectives, while dynamically adjusting the swapping range based on the current solution's structure and the relative improvement potential in both objectives. The algorithm ensures feasibility by maintaining the permutation property of TSP tours throughout the process and returns the improved neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Adaptive path decomposition\n    path_segments = []\n    current_segment = [base_solution[0]]\n    for i in range(1, n):\n        # Calculate edge weights in both objectives\n        prev_node = base_solution[i-1]\n        curr_node = base_solution[i]\n        next_node = base_solution[(i+1)%n]\n\n        w1 = distance_matrix_1[prev_node, curr_node] + distance_matrix_1[curr_node, next_node]\n        w2 = distance_matrix_2[prev_node, curr_node] + distance_matrix_2[curr_node, next_node]\n\n        # Determine if current node continues the segment or starts a new one\n        if len(current_segment) < 3 or (w1 + w2) / (distance_matrix_1[prev_node, next_node] + distance_matrix_2[prev_node, next_node]) > 1.2:\n            current_segment.append(curr_node)\n        else:\n            path_segments.append(current_segment)\n            current_segment = [curr_node]\n\n    if current_segment:\n        path_segments.append(current_segment)\n\n    # Edge flipping between segments\n    for _ in range(min(3, len(path_segments))):\n        if len(path_segments) < 2:\n            break\n\n        # Select two random segments\n        i, j = np.random.choice(len(path_segments), size=2, replace=False)\n        seg1, seg2 = path_segments[i], path_segments[j]\n\n        # Calculate current costs\n        cost1 = (distance_matrix_1[seg1[-1], seg2[0]] +\n                distance_matrix_1[seg2[-1], seg1[0]] if i < j else distance_matrix_1[seg2[-1], seg1[0]])\n        cost2 = (distance_matrix_2[seg1[-1], seg2[0]] +\n                distance_matrix_2[seg2[-1], seg1[0]] if i < j else distance_matrix_2[seg2[-1], seg1[0]])\n\n        # Try flipping the connection\n        new_order = []\n        if i < j:\n            new_order = np.concatenate([base_solution[:seg1[0]], seg2, seg1, base_solution[seg2[-1]+1:]])\n        else:\n            new_order = np.concatenate([base_solution[:seg2[0]], seg1, seg2, base_solution[seg1[-1]+1:]])\n\n        # Calculate new costs\n        new_cost1 = sum(distance_matrix_1[new_order[i], new_order[i+1]] for i in range(len(new_order)-1)) + distance_matrix_1[new_order[-1], new_order[0]]\n        new_cost2 = sum(distance_matrix_2[new_order[i], new_order[i+1]] for i in range(len(new_order)-1)) + distance_matrix_2[new_order[-1], new_order[0]]\n\n        # Accept if improvement in at least one objective\n        if new_cost1 + new_cost2 < cost1 + cost2:\n            new_solution = new_order.copy()\n            # Update path segments\n            path_segments[i], path_segments[j] = path_segments[j], path_segments[i]\n\n    # Guided node swapping\n    for _ in range(min(5, n//2)):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n\n        if i == j:\n            continue\n\n        # Calculate current costs\n        current_cost1 = (distance_matrix_1[new_solution[i-1], new_solution[i]] +\n                        distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] +\n                        distance_matrix_1[new_solution[j-1], new_solution[j]] +\n                        distance_matrix_1[new_solution[j], new_solution[(j+1)%n]])\n        current_cost2 = (distance_matrix_2[new_solution[i-1], new_solution[i]] +\n                        distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] +\n                        distance_matrix_2[new_solution[j-1], new_solution[j]] +\n                        distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n\n        # Swap nodes\n        candidate = new_solution.copy()\n        candidate[i], candidate[j] = candidate[j], candidate[i]\n\n        # Calculate new costs\n        new_cost1 = (distance_matrix_1[candidate[i-1], candidate[i]] +\n                    distance_matrix_1[candidate[i], candidate[(i+1)%n]] +\n                    distance_matrix_1[candidate[j-1], candidate[j]] +\n                    distance_matrix_1[candidate[j], candidate[(j+1)%n]])\n        new_cost2 = (distance_matrix_2[candidate[i-1], candidate[i]] +\n                    distance_matrix_2[candidate[i], candidate[(i+1)%n]] +\n                    distance_matrix_2[candidate[j-1], candidate[j]] +\n                    distance_matrix_2[candidate[j], candidate[(j+1)%n]])\n\n        # Dynamic swapping range based on improvement potential\n        improvement_ratio = (current_cost1 - new_cost1) / current_cost1 + (current_cost2 - new_cost2) / current_cost2\n        swap_range = max(1, min(5, int(3 * improvement_ratio)))\n\n        # Consider swapping within the range\n        for k in range(max(0, i-swap_range), min(n, i+swap_range+1)):\n            if k == i:\n                continue\n            for l in range(max(0, j-swap_range), min(n, j+swap_range+1)):\n                if l == j or k == l:\n                    continue\n\n                temp = candidate.copy()\n                temp[k], temp[l] = temp[l], temp[k]\n\n                temp_cost1 = (distance_matrix_1[temp[k-1], temp[k]] +\n                            distance_matrix_1[temp[k], temp[(k+1)%n]] +\n                            distance_matrix_1[temp[l-1], temp[l]] +\n                            distance_matrix_1[temp[l], temp[(l+1)%n]])\n                temp_cost2 = (distance_matrix_2[temp[k-1], temp[k]] +\n                            distance_matrix_2[temp[k], temp[(k+1)%n]] +\n                            distance_matrix_2[temp[l-1], temp[l]] +\n                            distance_matrix_2[temp[l], temp[(l+1)%n]])\n\n                if temp_cost1 + temp_cost2 < new_cost1 + new_cost2:\n                    candidate = temp.copy()\n                    new_cost1, new_cost2 = temp_cost1, temp_cost2\n\n        if new_cost1 + new_cost2 < current_cost1 + current_cost2:\n            new_solution = candidate.copy()\n\n    # Ensure the solution is valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               6.084809078203636,
               5.929778474737819
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a novel approach by combining adaptive path decomposition with multi-objective aware node swapping, which first partitions the solution into hierarchical paths based on both spatial coherence and edge strength in the two objective spaces, then selectively swaps nodes between paths to optimize the trade-off between objectives, followed by a probability-weighted path inversion phase that prioritizes moves with complementary improvement potential in both objectives, while dynamically adjusting the swapping depth based on the current solution's structure and the relative improvement potential in both objectives. The algorithm ensures feasibility by maintaining the permutation property of TSP tours throughout the process and returns the improved neighbor solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 3:\n        return new_solution\n\n    from scipy.spatial.distance import pdist, squareform\n\n    coords1 = instance[base_solution, :2]\n    coords2 = instance[base_solution, 2:]\n    dist1 = squareform(pdist(coords1))\n    dist2 = squareform(pdist(coords2))\n\n    path_length = max(3, min(7, n // 4))\n    paths = []\n    for i in range(0, n, path_length):\n        path = base_solution[i:i+path_length]\n        if len(path) < 2:\n            continue\n\n        strength1 = sum(distance_matrix_1[path[j], path[j+1]] for j in range(len(path)-1))\n        strength2 = sum(distance_matrix_2[path[j], path[j+1]] for j in range(len(path)-1))\n        paths.append((i, i+path_length, strength1 + strength2))\n\n    paths.sort(key=lambda x: -x[2])\n\n    for _ in range(min(3, len(paths))):\n        if len(paths) < 2:\n            break\n\n        path1_idx, path1_end, _ = paths[0]\n        path2_idx, path2_end, _ = paths[1]\n\n        path1_nodes = base_solution[path1_idx:path1_end]\n        path2_nodes = base_solution[path2_idx:path2_end]\n\n        if len(path1_nodes) < 2 or len(path2_nodes) < 2:\n            continue\n\n        node1_idx = np.random.randint(path1_idx, path1_end)\n        node2_idx = np.random.randint(path2_idx, path2_end)\n        node1 = new_solution[node1_idx]\n        node2 = new_solution[node2_idx]\n\n        old_cost1 = (distance_matrix_1[new_solution[node1_idx-1], node1] +\n                     distance_matrix_1[node1, new_solution[(node1_idx+1)%n]] +\n                     distance_matrix_1[new_solution[node2_idx-1], node2] +\n                     distance_matrix_1[node2, new_solution[(node2_idx+1)%n]])\n\n        old_cost2 = (distance_matrix_2[new_solution[node1_idx-1], node1] +\n                     distance_matrix_2[node1, new_solution[(node1_idx+1)%n]] +\n                     distance_matrix_2[new_solution[node2_idx-1], node2] +\n                     distance_matrix_2[node2, new_solution[(node2_idx+1)%n]])\n\n        new_cost1 = (distance_matrix_1[new_solution[node1_idx-1], node2] +\n                     distance_matrix_1[node2, new_solution[(node1_idx+1)%n]] +\n                     distance_matrix_1[new_solution[node2_idx-1], node1] +\n                     distance_matrix_1[node1, new_solution[(node2_idx+1)%n]])\n\n        new_cost2 = (distance_matrix_2[new_solution[node1_idx-1], node2] +\n                     distance_matrix_2[node2, new_solution[(node1_idx+1)%n]] +\n                     distance_matrix_2[new_solution[node2_idx-1], node1] +\n                     distance_matrix_2[node1, new_solution[(node2_idx+1)%n]])\n\n        if new_cost1 + new_cost2 < old_cost1 + old_cost2:\n            new_solution[node1_idx], new_solution[node2_idx] = new_solution[node2_idx], new_solution[node1_idx]\n\n    for _ in range(min(5, n//3)):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        while abs(i - j) < 2:\n            j = np.random.randint(0, n)\n\n        old_cost1 = (distance_matrix_1[new_solution[i-1], new_solution[i]] +\n                    distance_matrix_1[new_solution[j-1], new_solution[j]])\n\n        old_cost2 = (distance_matrix_2[new_solution[i-1], new_solution[i]] +\n                    distance_matrix_2[new_solution[j-1], new_solution[j]])\n\n        new_cost1 = (distance_matrix_1[new_solution[i-1], new_solution[j]] +\n                    distance_matrix_1[new_solution[i], new_solution[j-1]])\n\n        new_cost2 = (distance_matrix_2[new_solution[i-1], new_solution[j]] +\n                    distance_matrix_2[new_solution[i], new_solution[j-1]])\n\n        improvement = (old_cost1 + old_cost2) - (new_cost1 + new_cost2)\n\n        if improvement > 0 or np.random.random() < min(0.5, 0.1 + improvement / (old_cost1 + old_cost2)):\n            new_solution[i:j] = new_solution[i:j][::-1]\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               5.927690221836014,
               6.344430830785339
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' employs a novel adaptive path decomposition and recombination strategy that dynamically partitions the tour into segments based on both objective spaces' characteristics, then reconstructs the tour by interleaving these segments in a way that maximizes the trade-off between the two objectives. The selection process prioritizes solutions that exhibit non-dominated segments in the Pareto front, while the local search operator uses a probabilistic segment recombination mechanism guided by a multi-objective utility function that considers the segment's contribution to both objectives. The function ensures feasibility by maintaining the permutation property through a series of carefully designed segment swaps and rotations, with the segment length and recombination pattern determined by an adaptive probability model that learns from the current solution's structure and the distance matrices.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement using adaptive segment analysis\n    selected_idx = np.argmin([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive path decomposition based on both objectives\n    segment_length = np.random.randint(3, min(7, n // 2))\n    start_pos = np.random.randint(0, n - segment_length)\n\n    # Extract segment and analyze its contribution to both objectives\n    segment = new_solution[start_pos:start_pos + segment_length]\n    segment_cost1 = sum(distance_matrix_1[segment[i-1], segment[i]] for i in range(segment_length))\n    segment_cost2 = sum(distance_matrix_2[segment[i-1], segment[i]] for i in range(segment_length))\n\n    # Determine segment's Pareto dominance relative to the rest of the tour\n    total_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n    total_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n    # Probabilistic recombination based on segment's characteristics\n    if segment_cost1 / total_cost1 < 0.3 or segment_cost2 / total_cost2 < 0.3:\n        # If segment is significantly worse in one objective, consider removing it\n        new_solution = np.concatenate([new_solution[:start_pos], new_solution[start_pos + segment_length:]])\n        # Insert the segment in a different position\n        insert_pos = np.random.randint(0, len(new_solution) - segment_length + 1)\n        new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n    else:\n        # If segment is balanced, consider rotating it\n        rotation = np.random.randint(1, segment_length)\n        segment = np.roll(segment, rotation)\n        new_solution[start_pos:start_pos + segment_length] = segment\n\n    # Ensure feasibility by checking for duplicates\n    if len(np.unique(new_solution)) != n:\n        # If invalid, perform a simple swap to restore feasibility\n        a, b = np.random.choice(range(1, n-1), 2, replace=False)\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    return new_solution\n\n",
          "score": [
               6.4586950415254565,
               5.903120343468656
          ]
     }
]