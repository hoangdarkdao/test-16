[
    {
        "algorithm": "The algorithm selects a random solution from the archive and applies a hybrid local search combining edge exchange (reversing a segment) and node insertion (relocating a node), ensuring feasibility by validating solution length and uniqueness. It prioritizes improving solutions by leveraging randomness in segment selection and node relocation, with no explicit dominance/diversity checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (dominated or diverse)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine edge exchange and node insertion\n    n = len(base_solution)\n    if n < 4:\n        return new_solution  # Too small to apply meaningful local search\n\n    # Step 1: Edge exchange (swap two edges)\n    i, j = np.random.choice(n, size=2, replace=False)\n    if i > j:\n        i, j = j, i\n\n    # Ensure the exchange creates a valid tour\n    if j - i > 1:\n        # Reverse the segment between i and j\n        new_solution[i:j] = new_solution[i:j][::-1]\n\n    # Step 2: Node insertion (move a node to a different position)\n    k = np.random.randint(0, n)\n    l = np.random.randint(0, n)\n    if k != l:\n        node = new_solution[k]\n        new_solution = np.delete(new_solution, k)\n        new_solution = np.insert(new_solution, l, node)\n\n    # Ensure the solution remains feasible\n    assert len(new_solution) == n, \"Solution length changed\"\n    assert len(np.unique(new_solution)) == n, \"Duplicate nodes in solution\"\n\n    return new_solution\n\n",
        "score": [
            -0.8999263182725653,
            1.5403056144714355
        ]
    },
    {
        "algorithm": "The algorithm selects the best solution from the archive (lowest total cost) and applies a hybrid local search: 70% chance for an edge swap (reversing a segment) or 30% for a segment reversal (swapping two edges), ensuring feasibility by validating uniqueness. If invalid, it defaults to a simple edge swap. The selection prioritizes solutions with high potential for improvement, while the local search diversifies exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (lowest total cost)\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: choose between edge swap or segment reversal based on current diversity\n    if random.random() < 0.7:  # 70% chance for edge swap\n        # Edge swap: select two random edges and swap their connections\n        n = len(selected_solution)\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i:j+1] = selected_solution[j:i-1:-1]\n    else:\n        # Segment reversal: reverse a random segment of the tour\n        n = len(selected_solution)\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i:j+1] = selected_solution[j:i-1:-1]\n\n    # Ensure the new solution is valid (no duplicates)\n    if len(np.unique(new_solution)) != len(selected_solution):\n        # If invalid, revert to a simple edge swap\n        i, j = sorted(random.sample(range(1, len(selected_solution)-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.695281572845684,
            1.1709911227226257
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects the best solution from the archive (prioritizing lowest total cost) and applies a hybrid local search combining multi-segment reversal (with probabilistic segment selection) and node relocation (with limited randomness). It ensures feasibility through validation checks, reverting to the original solution if duplicates or length changes are detected. The approach balances exploration (via random segment selection and relocation) while maintaining feasibility, making it more creative than standard 2-opt methods.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (lowest total cost)\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n    new_solution = selected_solution.copy()\n\n    n = len(selected_solution)\n    if n < 4:\n        return new_solution  # Too small to apply meaningful local search\n\n    # Hybrid local search: multi-segment reversal with probabilistic node relocation\n    # Multi-segment reversal (generalization of segment reversal)\n    num_segments = min(3, n // 3)  # Limit number of segments to avoid excessive changes\n    segment_indices = sorted(random.sample(range(1, n-1), num_segments * 2))\n    for i in range(0, len(segment_indices), 2):\n        start, end = segment_indices[i], segment_indices[i+1]\n        if start < end:\n            new_solution[start:end+1] = new_solution[end:start-1:-1]\n\n    # Probabilistic node relocation (inspired by Algorithm 2)\n    for _ in range(min(2, n // 2)):  # Limit number of relocations\n        if random.random() < 0.6:  # 60% chance to relocate\n            k = random.randint(0, n-1)\n            l = random.randint(0, n-1)\n            if k != l:\n                node = new_solution[k]\n                new_solution = np.delete(new_solution, k)\n                new_solution = np.insert(new_solution, l, node)\n\n    # Two-phase validation to ensure feasibility\n    # Phase 1: Check for duplicates\n    if len(np.unique(new_solution)) != n:\n        # If duplicates found, revert to original solution\n        new_solution = selected_solution.copy()\n\n    # Phase 2: Check solution length\n    if len(new_solution) != n:\n        # If length changed, revert to original solution\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.719801261221124,
            1.2372207641601562
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume-based selection with a hybrid local search that prioritizes Pareto-frontier guided segment reversal, adaptive edge reinsertion based on combined distance improvements in both objective spaces, and probabilistic node insertion/deletion with simulated annealing-like acceptance criteria, all while maintaining feasibility through validation checks. The selection focuses on solutions with high hypervolume product, while the local search dynamically adjusts segment sizes and insertion points based on the combined cost improvements in both objectives, using probabilistic acceptance to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume product\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Hybrid local search with novel operators\n    # 1. Pareto-frontier guided segment reversal\n    seg_size = min(4, max(2, np.random.randint(1, n//3)))\n    i = np.random.randint(0, n - seg_size)\n    segment = new_solution[i:i+seg_size]\n\n    # Evaluate segment in both objectives\n    original_cost1 = sum(distance_matrix_1[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n    original_cost2 = sum(distance_matrix_2[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n\n    reversed_segment = segment[::-1]\n    reversed_cost1 = (distance_matrix_1[new_solution[(i-1)%n], reversed_segment[0]] +\n                      distance_matrix_1[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                      sum(distance_matrix_1[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n    reversed_cost2 = (distance_matrix_2[new_solution[(i-1)%n], reversed_segment[0]] +\n                      distance_matrix_2[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                      sum(distance_matrix_2[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n\n    if (reversed_cost1 < original_cost1 and reversed_cost2 < original_cost2) or \\\n       (np.random.random() < np.exp((reversed_cost1 + reversed_cost2 - original_cost1 - original_cost2) / 1.0)):\n        new_solution[i:i+seg_size] = reversed_segment\n\n    # 2. Adaptive edge reinsertion based on combined distance\n    if n > 4:\n        a, b = np.random.choice(n, size=2, replace=False)\n        if a > b:\n            a, b = b, a\n        if b - a > 1:\n            # Calculate combined distance improvement\n            original_dist = (distance_matrix_1[new_solution[a-1], new_solution[a]] +\n                            distance_matrix_1[new_solution[b-1], new_solution[b]] +\n                            distance_matrix_2[new_solution[a-1], new_solution[a]] +\n                            distance_matrix_2[new_solution[b-1], new_solution[b]])\n\n            new_dist = (distance_matrix_1[new_solution[a-1], new_solution[b]] +\n                        distance_matrix_1[new_solution[b-1], new_solution[a]] +\n                        distance_matrix_2[new_solution[a-1], new_solution[b]] +\n                        distance_matrix_2[new_solution[b-1], new_solution[a]])\n\n            if new_dist < original_dist or np.random.random() < 0.3:\n                new_solution = np.concatenate([new_solution[:a], new_solution[b:], new_solution[a:b]])\n\n    # 3. Probabilistic node insertion/deletion\n    if n > 4 and np.random.random() < 0.5:\n        pos = np.random.randint(0, n)\n        node = np.random.choice(n)\n        if node not in new_solution[:pos]:\n            temp_solution = np.insert(new_solution, pos, node)\n            if len(np.unique(temp_solution)) == n + 1:\n                # Evaluate insertion\n                cost1 = (distance_matrix_1[new_solution[pos-1], node] +\n                         distance_matrix_1[node, new_solution[pos]] -\n                         distance_matrix_1[new_solution[pos-1], new_solution[pos]])\n                cost2 = (distance_matrix_2[new_solution[pos-1], node] +\n                         distance_matrix_2[node, new_solution[pos]] -\n                         distance_matrix_2[new_solution[pos-1], new_solution[pos]])\n\n                if cost1 < 0 and cost2 < 0 or np.random.random() < 0.2:\n                    new_solution = temp_solution\n\n    # Ensure feasibility\n    assert len(new_solution) == n, \"Solution length changed\"\n    assert len(np.unique(new_solution)) == n, \"Duplicate nodes in solution\"\n\n    return new_solution\n\n",
        "score": [
            -0.9238378590173768,
            1.6598199605941772
        ]
    },
    {
        "algorithm": "The algorithm selects the highest-hypervolume solution from the archive, applies a dynamic 4-opt move to restructure the tour, and refines it using a variable-neighborhood descent approach with probabilistic segment insertions and temperature-based acceptance criteria, balancing exploration and exploitation through adaptive neighborhood sizes and cooling schedules. The hypervolume metric prioritizes solutions with better trade-offs between objectives, while the dynamic 4-opt and variable-neighborhood search ensure diverse and high-quality local improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    # Dynamic 4-opt move\n    i, j, k, l = sorted(random.sample(range(1, n), 4))\n    segment1 = new_solution[i:j]\n    segment2 = new_solution[j:k]\n    segment3 = new_solution[k:l]\n    new_segment = np.concatenate([segment2, segment3, segment1])\n    new_solution[i:l] = new_segment\n\n    # Variable-neighborhood descent with probabilistic insertions\n    temp = 1.0\n    cooling_rate = 0.95\n    neighborhood_sizes = [2, 3, 4, 5]\n\n    for size in neighborhood_sizes:\n        a, b = sorted(random.sample(range(1, n), 2))\n        current_obj = (sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n                       sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)))\n\n        # Try inserting a segment of variable size\n        if size > 2:\n            segment = new_solution[a:a+size]\n            temp_solution = np.concatenate([new_solution[:a], new_solution[a+size:]])\n            insert_pos = random.randint(1, len(temp_solution)-1)\n            temp_solution = np.insert(temp_solution, insert_pos, segment)\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[a], temp_solution[b] = temp_solution[b], temp_solution[a]\n\n        new_obj = (sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n)),\n                   sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n)))\n\n        if (hypervolume(new_obj) > hypervolume(current_obj) or\n            random.random() < np.exp((hypervolume(new_obj) - hypervolume(current_obj)) / temp)):\n            new_solution = temp_solution\n\n        temp *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -0.9424316571645178,
            2.2048558592796326
        ]
    },
    {
        "algorithm": "The algorithm selects the highest-hypervolume solution from the archive, applies adaptive multi-segment reversals and probabilistic edge swaps to explore the neighborhood, and ensures feasibility by validating the tour structure. It prioritizes solutions with better objective trade-offs (higher hypervolume) and balances exploration (random segment reversals and swaps) with exploitation (local improvements). The method dynamically adjusts segment counts and swap probabilities based on problem size, ensuring valid TSP tours while avoiding revisits or omissions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive multi-segment reversal\n    num_segments = min(3, n // 3)\n    segment_indices = sorted(random.sample(range(1, n-1), num_segments * 2))\n    for i in range(0, len(segment_indices), 2):\n        start, end = segment_indices[i], segment_indices[i+1]\n        if start < end:\n            new_solution[start:end+1] = new_solution[end:start-1:-1]\n\n    # Probabilistic edge swaps\n    for _ in range(min(3, n // 2)):\n        if random.random() < 0.5:\n            a, b = sorted(random.sample(range(1, n-1), 2))\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Feasibility validation\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7954199191497837,
            1.3437512516975403
        ]
    },
    {
        "algorithm": "This algorithm selects the best solution from the archive using an adaptive weighted sum of objectives, then applies a hybrid local search combining edge insertion with segment reversal, where the operation choice depends on solution diversity. It prioritizes segment reversals for diverse solutions and validates/repairs solutions to ensure feasibility, falling back to simple swaps if needed. The weighting and operation probabilities are dynamically adjusted based on solution quality metrics.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with best weighted sum of objectives (adaptive weighting)\n    weights = (0.6, 0.4) if random.random() < 0.5 else (0.4, 0.6)\n    archive_sorted = sorted(archive, key=lambda x: weights[0]*x[1][0] + weights[1]*x[1][1])\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Calculate current solution quality metrics\n    n = len(selected_solution)\n    current_cost1 = sum(distance_matrix_1[selected_solution[i], selected_solution[i+1]] for i in range(-1, n-1))\n    current_cost2 = sum(distance_matrix_2[selected_solution[i], selected_solution[i+1]] for i in range(-1, n-1))\n    diversity = len(set(selected_solution)) / n\n\n    # Adaptive local search probability\n    if diversity > 0.8:\n        prob = 0.8  # Higher diversity -> more segment reversals\n    else:\n        prob = 0.3\n\n    if random.random() < prob:\n        # Edge insertion with path optimization\n        i = random.randint(1, n-2)\n        j = random.randint(1, n-2)\n        while j == i or j == i+1 or j == i-1:\n            j = random.randint(1, n-2)\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        # Optimize inserted segment\n        segment = new_solution[i:j+1]\n        segment = sorted(segment, key=lambda x: distance_matrix_1[new_solution[i-1], x] + distance_matrix_1[x, new_solution[j+1]])\n        new_solution[i:j+1] = segment\n    else:\n        # Segment reversal with adaptive length\n        segment_length = max(2, min(5, int(np.ceil(n * 0.1))))  # 10% of tour length\n        i = random.randint(1, n-segment_length-1)\n        new_solution = selected_solution.copy()\n        new_solution[i:i+segment_length] = selected_solution[i+segment_length-1:i-1:-1]\n\n    # Validate and repair if needed\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple edge swap\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8559321636679985,
            1.3462276458740234
        ]
    },
    {
        "algorithm": "The algorithm selects the most diverse solution from the archive (based on the sum of edge lengths in both objectives) and applies a hybrid local search: 60% probability for a segment shift (moving a random segment to a new position) or 40% for a node swap with another node, ensuring feasibility by validating uniqueness and reverting to a simple edge swap if invalid. The selection prioritizes solutions with higher diversity, while the local search balances exploration (segment shifts) and exploitation (node swaps).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity (sum of edge lengths in both objectives)\n    def diversity_score(solution):\n        cost1 = sum(distance_matrix_1[solution[i-1], solution[i]] for i in range(len(solution)))\n        cost2 = sum(distance_matrix_2[solution[i-1], solution[i]] for i in range(len(solution)))\n        return cost1 + cost2\n\n    archive_sorted = sorted(archive, key=lambda x: diversity_score(x[0]))\n    selected_solution = archive_sorted[-1][0].copy()  # Select the most diverse solution\n\n    # Hybrid local search\n    if random.random() < 0.6:  # 60% chance for segment shift\n        n = len(selected_solution)\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        k = random.randint(1, n-1)\n        new_solution = selected_solution.copy()\n        segment = new_solution[i:j+1]\n        new_solution = np.concatenate([new_solution[:i], new_solution[j+1:k], segment, new_solution[k:]])\n    else:  # 40% chance for node swap with another segment\n        n = len(selected_solution)\n        i = random.randint(1, n-1)\n        j = random.randint(1, n-1)\n        while j == i or j == (i-1) % n or j == (i+1) % n:\n            j = random.randint(1, n-1)\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure the new solution is valid (no duplicates)\n    if len(np.unique(new_solution)) != len(selected_solution):\n        # If invalid, revert to a simple edge swap\n        i, j = sorted(random.sample(range(1, len(selected_solution)-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -1.0117954119007642,
            7.185237467288971
        ]
    },
    {
        "algorithm": "The algorithm selects the highest-hypervolume solution from the archive, applies adaptive multi-segment reversal and probabilistic edge swaps guided by combined distance improvements in both objectives, while ensuring feasibility through validation checks. It prioritizes solutions with better combined objective values and employs a hybrid local search strategy that balances exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive multi-segment reversal guided by combined distance\n    num_segments = min(3, n // 3)\n    segment_indices = sorted(random.sample(range(1, n-1), num_segments * 2))\n    for i in range(0, len(segment_indices), 2):\n        start, end = segment_indices[i], segment_indices[i+1]\n        if start < end:\n            original_cost = (distance_matrix_1[new_solution[start-1], new_solution[start]] +\n                            distance_matrix_1[new_solution[end-1], new_solution[end]] +\n                            distance_matrix_2[new_solution[start-1], new_solution[start]] +\n                            distance_matrix_2[new_solution[end-1], new_solution[end]])\n            reversed_cost = (distance_matrix_1[new_solution[start-1], new_solution[end]] +\n                            distance_matrix_1[new_solution[start], new_solution[end-1]] +\n                            distance_matrix_2[new_solution[start-1], new_solution[end]] +\n                            distance_matrix_2[new_solution[start], new_solution[end-1]])\n            if reversed_cost < original_cost or random.random() < 0.3:\n                new_solution[start:end+1] = new_solution[end:start-1:-1]\n\n    # Probabilistic edge swaps with combined distance improvement\n    for _ in range(min(3, n // 2)):\n        if random.random() < 0.5:\n            a, b = sorted(random.sample(range(1, n-1), 2))\n            original_cost = (distance_matrix_1[new_solution[a-1], new_solution[a]] +\n                            distance_matrix_1[new_solution[b-1], new_solution[b]] +\n                            distance_matrix_2[new_solution[a-1], new_solution[a]] +\n                            distance_matrix_2[new_solution[b-1], new_solution[b]])\n            swapped_cost = (distance_matrix_1[new_solution[a-1], new_solution[b]] +\n                           distance_matrix_1[new_solution[b-1], new_solution[a]] +\n                           distance_matrix_2[new_solution[a-1], new_solution[b]] +\n                           distance_matrix_2[new_solution[b-1], new_solution[a]])\n            if swapped_cost < original_cost or random.random() < 0.2:\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Feasibility validation\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.6782491521277348,
            1.2605713605880737
        ]
    },
    {
        "algorithm": "The heuristic selects the highest-hypervolume solution from the archive, applies a 3-opt move to diversify the tour, and then uses simulated annealing to refine it by probabilistically accepting edge swaps that improve or slightly degrade the solution, cooling the temperature over iterations to balance exploration and exploitation. The algorithm prioritizes solutions with better hypervolume (product of objectives) and balances local search with randomness to escape local optima while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with highest hypervolume improvement potential\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: 3-opt with simulated annealing edge swaps\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Perform 3-opt\n    i, j, k = sorted(random.sample(range(1, n), 3))\n    segment1 = new_solution[i:j]\n    segment2 = new_solution[j:k]\n    new_segment = np.concatenate([segment2, segment1])\n    new_solution[i:k] = new_segment\n\n    # Simulated annealing-inspired edge swaps\n    temp = 1.0\n    cooling_rate = 0.99\n    for _ in range(10):\n        a, b = sorted(random.sample(range(1, n), 2))\n        current_obj = (sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n                       sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)))\n\n        # Try swapping edges\n        temp_solution = new_solution.copy()\n        temp_solution[a], temp_solution[b] = temp_solution[b], temp_solution[a]\n        new_obj = (sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n)),\n                   sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n)))\n\n        # Accept if better or with probability based on temperature\n        if (hypervolume(new_obj) > hypervolume(current_obj) or\n            random.random() < np.exp((hypervolume(new_obj) - hypervolume(current_obj)) / temp)):\n            new_solution = temp_solution\n\n        temp *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -0.9159466759073818,
            2.6878561973571777
        ]
    }
]