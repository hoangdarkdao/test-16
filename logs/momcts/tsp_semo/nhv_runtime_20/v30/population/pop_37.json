[
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized objective product) and applies a multi-stage local search: first an adaptive segment inversion that reverses a random segment if it improves both objectives, followed by probabilistic node relocation that moves a node to the best position with a 70% chance. The method ensures feasibility by maintaining unique node visits and uses simulated annealing for occasional uphill moves.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized objective product\n    max_obj = max(max(obj) for _, obj in archive)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0]/max_obj) * (x[1][1]/max_obj), reverse=True)\n    base_solution = archive_sorted[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Multi-stage local search\n    # Stage 1: Adaptive segment inversion\n    max_seg_size = min(5, n//2)\n    seg_size = np.random.randint(2, max_seg_size+1)\n    i = np.random.randint(0, n - seg_size)\n    segment = new_solution[i:i+seg_size]\n\n    # Evaluate segment in both objectives\n    original_cost1 = sum(distance_matrix_1[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n    original_cost2 = sum(distance_matrix_2[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n\n    reversed_segment = segment[::-1]\n    reversed_cost1 = (distance_matrix_1[new_solution[(i-1)%n], reversed_segment[0]] +\n                     distance_matrix_1[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                     sum(distance_matrix_1[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n    reversed_cost2 = (distance_matrix_2[new_solution[(i-1)%n], reversed_segment[0]] +\n                     distance_matrix_2[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                     sum(distance_matrix_2[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n\n    delta_cost = (reversed_cost1 + reversed_cost2) - (original_cost1 + original_cost2)\n    if delta_cost < 0 or (delta_cost > 0 and np.random.random() < np.exp(-delta_cost/1.0)):\n        new_solution[i:i+seg_size] = reversed_segment\n\n    # Stage 2: Probabilistic node relocation\n    if n > 4 and np.random.random() < 0.7:\n        node_idx = np.random.randint(1, n-1)\n        node = new_solution[node_idx]\n        new_solution = np.delete(new_solution, node_idx)\n\n        best_pos = -1\n        best_cost = float('inf')\n\n        for pos in range(1, n):\n            temp_solution = np.insert(new_solution, pos, node)\n            cost1 = (distance_matrix_1[temp_solution[pos-1], node] +\n                    distance_matrix_1[node, temp_solution[pos]] -\n                    distance_matrix_1[temp_solution[pos-1], temp_solution[pos]])\n            cost2 = (distance_matrix_2[temp_solution[pos-1], node] +\n                    distance_matrix_2[node, temp_solution[pos]] -\n                    distance_matrix_2[temp_solution[pos-1], temp_solution[pos]])\n            total_cost = cost1 + cost2\n\n            if total_cost < best_cost or (total_cost == best_cost and np.random.random() < 0.5):\n                best_cost = total_cost\n                best_pos = pos\n\n        if best_pos != -1:\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    # Ensure feasibility\n    assert len(new_solution) == n, \"Solution length changed\"\n    assert len(np.unique(new_solution)) == n, \"Duplicate nodes in solution\"\n\n    return new_solution\n\n",
        "score": [
            -0.9784972097067457,
            2.5674105882644653
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume-based selection with an adaptive segment-swapping mechanism, prioritizing solutions with high hypervolume and crowding distance while dynamically adjusting segment sizes and swap probabilities based on temperature. It ensures feasibility by validating and repairing tours after segment swaps, with the temperature parameter gradually decreasing to focus on high-quality local improvements. The key variables are the base solution (selected via hypervolume/crowding), segment size (adaptive to temperature), and repair mechanism (handling missing/duplicate nodes). The structure alternates between selection, segment swaps, and validation, with temperature controlling exploration/exploitation trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj1, obj2):\n        return max(0, obj1[0] - obj2[0]) * max(0, obj1[1] - obj2[1])\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    # Select solution with highest hypervolume and crowding distance\n    archive.sort(key=lambda x: (-hypervolume(x[1], (0, 0)), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Temperature parameter for adaptive control\n    temperature = max(1.0, n / 10)\n\n    # Adaptive segment swapping\n    segment_size = max(2, min(n // 3, int(temperature)))\n    num_swaps = min(3, max(1, n // (segment_size * 2)))\n\n    for _ in range(num_swaps):\n        if random.random() < (0.8 * temperature / max(1.0, n / 5)):\n            # Select two non-overlapping segments\n            seg1_start = random.randint(1, n - 2 * segment_size - 1)\n            seg2_start = random.randint(seg1_start + segment_size, n - segment_size - 1)\n\n            seg1 = new_solution[seg1_start:seg1_start+segment_size]\n            seg2 = new_solution[seg2_start:seg2_start+segment_size]\n\n            # Swap segments\n            new_solution[seg1_start:seg1_start+segment_size] = seg2\n            new_solution[seg2_start:seg2_start+segment_size] = seg1\n\n            # Decrease temperature\n            temperature *= 0.95\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            new_solution[np.where(np.isin(new_solution, list(extra)))[0][0]] = next(iter(missing))\n\n    return new_solution\n\n",
        "score": [
            -0.971151372604398,
            0.7450237274169922
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using hypervolume and crowding distance metrics, then applies adaptive 3-opt with temperature-based probabilistic acceptance to generate a neighbor solution while ensuring tour feasibility through validation and repair. It prioritizes solutions with higher hypervolume and lower crowding distance, then explores 3-opt moves probabilistically based on a temperature parameter that decreases with solution quality, and finally repairs any infeasibilities in the tour.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    # Select solution with highest hypervolume and least crowded neighbors\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive 3-opt with temperature-based acceptance\n    temperature = max(0.1, 1.0 - (selected[2] / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6)))\n\n    for _ in range(min(3, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        # Evaluate all possible 3-opt moves\n        moves = [\n            # Original order\n            (new_solution, 0),\n            # a-b-c reversed\n            (np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]]), 1),\n            # a-c-b reversed\n            (np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]]), 2),\n            # b-a-c reversed\n            (np.concatenate([new_solution[:b], new_solution[a:b-1:-1], new_solution[c:a-1:-1], new_solution[c+1:]]), 3),\n            # b-c-a reversed\n            (np.concatenate([new_solution[:b], new_solution[c:b-1:-1], new_solution[a:c-1:-1], new_solution[a+1:]]), 4),\n            # c-a-b reversed\n            (np.concatenate([new_solution[:c], new_solution[a:c-1:-1], new_solution[b:a-1:-1], new_solution[b+1:]]), 5),\n            # c-b-a reversed\n            (np.concatenate([new_solution[:c], new_solution[b:c-1:-1], new_solution[a:b-1:-1], new_solution[a+1:]]), 6)\n        ]\n\n        # Calculate costs for each move\n        move_costs = []\n        for move, idx in moves:\n            if idx == 0:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, n-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, n-1))\n            else:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, len(move)-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, len(move)-1))\n            move_costs.append((move, cost1, cost2))\n\n        # Select best move with temperature-based probability\n        best_move = min(move_costs, key=lambda x: (x[1] + x[2]))\n        if (move_costs[0][1] + move_costs[0][2]) > (best_move[1] + best_move[2]) or \\\n           (random.random() < temperature and len(np.unique(best_move[0])) == n):\n            new_solution = best_move[0].copy()\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Simple repair mechanism\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -0.9931873366440623,
            3.3111976385116577
        ]
    },
    {
        "algorithm": "The algorithm selects solutions from the archive using hypervolume and crowding distance metrics, then applies an adaptive 3-opt local search with temperature-based probabilistic acceptance to generate neighbors, balancing Pareto diversity and local refinement while ensuring tour feasibility. It prioritizes solutions with higher hypervolume and lower crowding distance, then evaluates multiple 3-opt moves to find the most promising neighbor, occasionally accepting worse solutions probabilistically based on temperature, and includes a repair mechanism to maintain feasibility. The temperature is dynamically adjusted based on the solution's hypervolume relative to the archive.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    # Select solution with highest hypervolume and least crowded neighbors\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive 3-opt with temperature-based acceptance\n    temperature = max(0.1, 1.0 - (selected[2] / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6)))\n\n    for _ in range(min(3, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        # Evaluate all possible 3-opt moves\n        moves = [\n            # Original order\n            (new_solution, 0),\n            # a-b-c reversed\n            (np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]]), 1),\n            # a-c-b reversed\n            (np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]]), 2),\n            # b-a-c reversed\n            (np.concatenate([new_solution[:b], new_solution[a:b-1:-1], new_solution[c:a-1:-1], new_solution[c+1:]]), 3),\n            # b-c-a reversed\n            (np.concatenate([new_solution[:b], new_solution[c:b-1:-1], new_solution[a:c-1:-1], new_solution[a+1:]]), 4),\n            # c-a-b reversed\n            (np.concatenate([new_solution[:c], new_solution[a:c-1:-1], new_solution[b:a-1:-1], new_solution[b+1:]]), 5),\n            # c-b-a reversed\n            (np.concatenate([new_solution[:c], new_solution[b:c-1:-1], new_solution[a:b-1:-1], new_solution[a+1:]]), 6)\n        ]\n\n        # Calculate costs for each move\n        move_costs = []\n        for move, idx in moves:\n            if idx == 0:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, n-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, n-1))\n            else:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, len(move)-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, len(move)-1))\n            move_costs.append((move, cost1, cost2))\n\n        # Select best move with temperature-based probability\n        best_move = min(move_costs, key=lambda x: (x[1] + x[2]))\n        if (move_costs[0][1] + move_costs[0][2]) > (best_move[1] + best_move[2]) or \\\n           (random.random() < temperature and len(np.unique(best_move[0])) == n):\n            new_solution = best_move[0].copy()\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Simple repair mechanism\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -1.0251145125491288,
            3.4849088191986084
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive by prioritizing non-dominated ones with balanced objectives, then applies an adaptive segment-swap local search to generate neighbors while ensuring feasibility through dynamic validation and repair. It balances exploration and exploitation through mutation intensity proportional to solution quality, and uses segment swaps to diversify the search space while maintaining tour validity. The critical design ideas are dominance-based selection, adaptive mutation intensity, and a novel segment-swap operator with feasibility repair.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    # Select non-dominated solutions\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with best balance between objectives\n    selected = min(non_dominated, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive mutation intensity\n    mutation_intensity = min(0.5, 0.1 + (selected[1][0] + selected[1][1]) / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    # Novel segment-swap local search\n    for _ in range(int(mutation_intensity * n)):\n        # Random segment selection\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n\n        # Random insertion point\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Perform segment swap\n        segment = new_solution[start:end]\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Reconstruct tour from scratch if too many errors\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if len(missing) > n//2 or len(extra) > n//2:\n            new_solution = np.random.permutation(n)\n        else:\n            # Local repair\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -0.7524281480617852,
            0.43341946601867676
        ]
    },
    {
        "algorithm": "The algorithm selects high-potential solutions from the archive using hypervolume and crowding distance, then applies an adaptive k-opt local search with temperature-based probabilistic operations (reverse, shift, rotate, and segment swap) to generate feasible neighbors, ensuring validity through validation and repair. It prioritizes solutions with better hypervolume while diversifying selection with crowding distance, and adaptively balances exploration (high temperature) and exploitation (low temperature) based on solution quality. The k-opt operations are applied to segments of varying sizes, with segment swaps and rotations enabling more diverse neighborhood exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    k = min(5, max(3, n // 5))\n    temperature = 1.0 - (selected[2] / (max(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'rotate', 'swap'], weights=[0.3, 0.3, 0.2, 0.2])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            else:  # rotate\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.8615481553915842,
            0.5991706848144531
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume and crowding distance to prioritize high-quality solutions from the archive, then applies a dynamic multi-segment local search that alternates between insertion and reversal operations, with segment sizes and positions determined by objective-space costs and probabilistic acceptance. It ensures feasibility through objective-driven repairs when necessary, balancing exploration and exploitation with temperature-based selection.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    def objective_difference(obj1, obj2):\n        return (obj1[0] - obj2[0]) ** 2 + (obj1[1] - obj2[1]) ** 2\n\n    archive.sort(key=lambda x: (-hypervolume(x[1]), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    temp = 1.0 / (1 + np.log(1 + len(archive)))\n    num_segments = np.random.randint(2, min(5, n//3))\n\n    for _ in range(num_segments):\n        seg_length = np.random.randint(2, min(5, n//num_segments))\n        i = np.random.randint(0, n - seg_length)\n        segment = new_solution[i:i+seg_length]\n\n        if np.random.random() < 0.5:\n            # Multi-segment insertion with objective-aware positioning\n            insertion_scores = []\n            for pos in range(1, n-seg_length):\n                if pos >= i and pos < i+seg_length:\n                    continue\n                cost1 = (distance_matrix_1[new_solution[pos-1], segment[0]] +\n                        distance_matrix_1[segment[-1], new_solution[pos]] -\n                        distance_matrix_1[new_solution[pos-1], new_solution[pos]])\n                cost2 = (distance_matrix_2[new_solution[pos-1], segment[0]] +\n                        distance_matrix_2[segment[-1], new_solution[pos]] -\n                        distance_matrix_2[new_solution[pos-1], new_solution[pos]])\n                insertion_scores.append((cost1 + cost2, pos))\n\n            if insertion_scores:\n                best_pos = min(insertion_scores, key=lambda x: x[0])[1]\n                new_solution = np.concatenate([new_solution[:best_pos], segment, new_solution[best_pos:]])\n        else:\n            # Dynamic segment reversal with objective balancing\n            reversed_segment = segment[::-1]\n            original_cost1 = sum(distance_matrix_1[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_length+1))\n            original_cost2 = sum(distance_matrix_2[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_length+1))\n            reversed_cost1 = (distance_matrix_1[new_solution[(i-1)%n], reversed_segment[0]] +\n                             distance_matrix_1[reversed_segment[-1], new_solution[(i+seg_length)%n]] +\n                             sum(distance_matrix_1[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_length)))\n            reversed_cost2 = (distance_matrix_2[new_solution[(i-1)%n], reversed_segment[0]] +\n                             distance_matrix_2[reversed_segment[-1], new_solution[(i+seg_length)%n]] +\n                             sum(distance_matrix_2[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_length)))\n\n            delta_cost = (reversed_cost1 + reversed_cost2) - (original_cost1 + original_cost2)\n            if delta_cost < 0 or (delta_cost > 0 and np.random.random() < np.exp(-delta_cost / temp)):\n                new_solution[i:i+seg_length] = reversed_segment\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n:\n        visited = set()\n        repaired = []\n        for node in new_solution:\n            if node not in visited:\n                visited.add(node)\n                repaired.append(node)\n\n        missing_nodes = set(range(n)) - visited\n        for node in missing_nodes:\n            insertion_scores = []\n            for i in range(1, len(repaired)):\n                cost1 = (distance_matrix_1[repaired[i-1], node] +\n                        distance_matrix_1[node, repaired[i]] -\n                        distance_matrix_1[repaired[i-1], repaired[i]])\n                cost2 = (distance_matrix_2[repaired[i-1], node] +\n                        distance_matrix_2[node, repaired[i]] -\n                        distance_matrix_2[repaired[i-1], repaired[i]])\n                insertion_scores.append((cost1 + cost2, i))\n\n            best_pos = min(insertion_scores, key=lambda x: x[0])[1]\n            repaired.insert(best_pos, node)\n\n        new_solution = np.array(repaired)\n\n    return new_solution\n\n",
        "score": [
            -0.8647747298796808,
            0.8773264288902283
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using hypervolume and crowding distance metrics, then applies adaptive segment reversal and probabilistic edge swaps to generate neighbors while ensuring feasibility through dynamic validation and repair. It prioritizes solutions with higher hypervolume and lower crowding distance, adaptively reverses segments of the tour, and probabilistically swaps edges based on the solution's quality, with repair mechanisms to maintain tour validity. The selection and modification process is guided by the solution's objective values and the archive's diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    # Select solution with highest hypervolume and least crowded neighbors\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment reversal\n    max_segments = min(5, n // 3)\n    num_segments = random.randint(1, max_segments)\n    segment_length = max(2, n // (num_segments * 2))\n\n    for _ in range(num_segments):\n        start = random.randint(0, n - segment_length)\n        end = start + segment_length\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Probabilistic edge swaps\n    swap_prob = min(0.5, 0.1 + selected[2] / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n    for i in range(1, n-1):\n        if random.random() < swap_prob:\n            j = random.randint(1, n-1)\n            if i != j:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -0.9707275659407705,
            1.1732860803604126
        ]
    },
    {
        "algorithm": "This algorithm selects the best solution from the archive (based on the sum of objectives) and applies a novel segment-based crossover with adaptive mutation, followed by a Pareto-aware local search using dynamic neighborhood exploration and a hybrid of simulated annealing with multi-objective adaptive walk to refine the solution while ensuring feasibility. The algorithm prioritizes exploration through random segment reversals and swaps, while exploitation is guided by Pareto dominance and simulated annealing's temperature-based acceptance. The objective sum is used to initially select the base solution, but the local search and refinement steps explicitly consider both objectives separately.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def objective_sum(obj):\n        return obj[0] + obj[1]\n\n    archive.sort(key=lambda x: objective_sum(x[1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Novel segment-based crossover with adaptive mutation\n    i, j, k = sorted(random.sample(range(1, n), 3))\n    segment1 = new_solution[i:j]\n    segment2 = new_solution[j:k]\n\n    if random.random() < 0.5:\n        segment1 = segment1[::-1]\n        segment2 = segment2[::-1]\n\n    if random.random() < 0.3:\n        segment1, segment2 = segment2, segment1\n\n    new_segment = np.concatenate([segment1, segment2])\n    new_solution[i:k] = new_segment\n\n    # Pareto-aware local search with dynamic neighborhood\n    for _ in range(5):\n        a, b = sorted(random.sample(range(1, n), 2))\n        temp_solution = new_solution.copy()\n\n        if random.random() < 0.7:\n            temp_solution[a:b] = temp_solution[a:b][::-1]\n        else:\n            temp_solution[a], temp_solution[b] = temp_solution[b], temp_solution[a]\n\n        current_obj = (sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n                       sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)))\n        new_obj = (sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n)),\n                   sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n)))\n\n        if (new_obj[0] <= current_obj[0] and new_obj[1] < current_obj[1]) or \\\n           (new_obj[0] < current_obj[0] and new_obj[1] <= current_obj[1]):\n            new_solution = temp_solution\n\n    # Hybrid simulated annealing with multi-objective adaptive walk\n    initial_temp = 1.5\n    temp = initial_temp\n    cooling_rate = 0.95\n    iterations = 15\n\n    for _ in range(iterations):\n        current_obj = (sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n                       sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)))\n\n        temp_solution = new_solution.copy()\n        a, b = sorted(random.sample(range(1, n), 2))\n\n        if random.random() < 0.6:\n            temp_solution[a:b] = temp_solution[a:b][::-1]\n        else:\n            temp_solution[a], temp_solution[b] = temp_solution[b], temp_solution[a]\n\n        new_obj = (sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n)),\n                   sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n)))\n\n        delta = (new_obj[0] + new_obj[1]) - (current_obj[0] + current_obj[1])\n        if delta < 0 or random.random() < np.exp(-delta / temp):\n            new_solution = temp_solution\n\n        temp *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -1.0121964283362856,
            3.8954556584358215
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on Pareto diversity (hypervolume and crowding distance) and applies an adaptive k-opt strategy (k=3-5) with temperature-based probabilistic operations (reverse, shift, swap, rotate) to generate neighbors, while ensuring feasibility through validation and repair. The temperature dynamically adjusts based on solution quality, favoring exploration for diverse solutions and exploitation for high-quality ones.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    k = min(5, max(3, n // 5))\n    temperature = 1.0 - (selected[2] / (max(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'swap', 'rotate'], weights=[0.4, 0.3, 0.2, 0.1])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            else:  # rotate\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.8000770662690869,
            0.6698082089424133
        ]
    }
]