[
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects non-dominated solutions from the archive using hypervolume and dominance ranking, then applies an adaptive 4-opt+ local search with simulated annealing to generate neighbors, balancing exploration and exploitation through temperature-controlled acceptance. It prioritizes solutions with higher hypervolume while ensuring feasibility through dynamic repair of missing/duplicate nodes. The local search explores diverse 4-segment reversals and accepts improvements or random moves based on temperature, gradually cooling the search process.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    selected = max(non_dominated, key=lambda x: hypervolume(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 6:\n        return new_solution\n\n    temperature = max(0.1, 1.0 - (hypervolume(selected[1]) / (max(hypervolume(obj) for _, obj in archive) + 1e-6)))\n    k = min(6, max(4, n // 4))\n\n    for _ in range(min(4, n // 3)):\n        a, b, c, d = sorted(random.sample(range(1, n-1), 4))\n\n        current_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)))\n\n        candidates = [\n            np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[d:c-1:-1], new_solution[d+1:]]),\n            np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[d:b-1:-1], new_solution[d+1:]]),\n            np.concatenate([new_solution[:a], new_solution[d:a-1:-1], new_solution[c:d-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]])\n        ]\n\n        for candidate in candidates:\n            new_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(-1, n-1)))\n\n            if new_cost < current_cost or random.random() < temperature:\n                new_solution = candidate.copy()\n                current_cost = new_cost\n                temperature *= 0.95\n                break\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution[:n]\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 301,
        "algorithm": "This algorithm selects promising solutions from an archive using crowding distance and dominance ranking, then applies a hybrid 3-opt+ local search with adaptive mutation to generate neighbors, balancing exploration and exploitation through dynamic temperature adjustment and segment-based perturbation. The selection prioritizes solutions with high crowding distance or low total cost, while the local search explores three candidate moves (reverse, insert, and swap segments) with a temperature-based acceptance criterion. The algorithm ensures feasibility by repairing invalid tours when nodes are missing or duplicated.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def crowding_distance(solutions, objectives):\n        n = len(solutions)\n        if n <= 2:\n            return [float('inf')] * n\n\n        sorted_indices = [sorted(range(n), key=lambda i: objectives[i][0]), sorted(range(n), key=lambda i: objectives[i][1])]\n        distances = [0.0] * n\n\n        for obj_idx in range(2):\n            sorted_idx = sorted_indices[obj_idx]\n            distances[sorted_idx[0]] = float('inf')\n            distances[sorted_idx[-1]] = float('inf')\n            if objectives[sorted_idx[-1]][obj_idx] == objectives[sorted_idx[0]][obj_idx]:\n                continue\n            norm = objectives[sorted_idx[-1]][obj_idx] - objectives[sorted_idx[0]][obj_idx]\n            for i in range(1, n-1):\n                distances[sorted_idx[i]] += (objectives[sorted_idx[i+1]][obj_idx] - objectives[sorted_idx[i-1]][obj_idx]) / norm\n\n        return distances\n\n    objectives = [obj for _, obj in archive]\n    distances = crowding_distance(archive, objectives)\n    selected_idx = max(range(len(archive)), key=lambda i: (distances[i], -sum(objectives[i])))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = max(0.1, 1.0 - (sum(archive[selected_idx][1]) / (max(sum(obj) for _, obj in archive) + 1e-6)))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(5, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        current_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)))\n\n        candidates = [\n            np.concatenate([new_solution[:a], new_solution[a:b+1][::-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c+1], new_solution[a:b], new_solution[c+1:]]),\n            np.concatenate([new_solution[:a], new_solution[c:b-1:-1], new_solution[a:b], new_solution[c+1:]])\n        ]\n\n        for candidate in candidates:\n            new_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(-1, n-1)))\n\n            if new_cost < current_cost or random.random() < temperature:\n                new_solution = candidate.copy()\n                current_cost = new_cost\n                temperature *= 0.98\n                break\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution[:n]\n\n",
        "score": [
            -0.8738897529394049,
            3.0178638100624084
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def crowding_distance(solutions, objectives):\n        n = len(solutions)\n        if n <= 2:\n            return [float('inf')] * n\n\n        sorted_indices = [sorted(range(n), key=lambda i: objectives[i][0]), sorted(range(n), key=lambda i: objectives[i][1])]\n        distances = [0.0] * n\n\n        for obj_idx in range(2):\n            sorted_idx = sorted_indices[obj_idx]\n            distances[sorted_idx[0]] = float('inf')\n            distances[sorted_idx[-1]] = float('inf')\n            if objectives[sorted_idx[-1]][obj_idx] == objectives[sorted_idx[0]][obj_idx]:\n                continue\n            norm = objectives[sorted_idx[-1]][obj_idx] - objectives[sorted_idx[0]][obj_idx]\n            for i in range(1, n-1):\n                distances[sorted_idx[i]] += (objectives[sorted_idx[i+1]][obj_idx] - objectives[sorted_idx[i-1]][obj_idx]) / norm\n\n        return distances\n\n    objectives = [obj for _, obj in archive]\n    distances = crowding_distance(archive, objectives)\n    selected_idx = max(range(len(archive)), key=lambda i: (distances[i], -sum(objectives[i])))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = max(0.1, 1.0 - (sum(archive[selected_idx][1]) / (max(sum(obj) for _, obj in archive) + 1e-6)))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(5, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        current_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)))\n\n        candidates = [\n            np.concatenate([new_solution[:a], new_solution[a:b+1][::-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c+1], new_solution[a:b], new_solution[c+1:]]),\n            np.concatenate([new_solution[:a], new_solution[c:b-1:-1], new_solution[a:b], new_solution[c+1:]])\n        ]\n\n        for candidate in candidates:\n            new_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(-1, n-1)))\n\n            if new_cost < current_cost or random.random() < temperature:\n                new_solution = candidate.copy()\n                current_cost = new_cost\n                temperature *= 0.98\n                break\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution[:n]\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects non-dominated solutions from the archive using hypervolume and dominance ranking, then applies an adaptive 4-opt+ local search with simulated annealing to generate neighbors, balancing exploration and exploitation through temperature-controlled acceptance. It prioritizes solutions with higher hypervolume while ensuring feasibility through dynamic repair of missing/duplicate nodes. The local search explores diverse 4-segment reversals and accepts improvements or random moves based on temperature, gradually cooling the search process.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    selected = max(non_dominated, key=lambda x: hypervolume(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 6:\n        return new_solution\n\n    temperature = max(0.1, 1.0 - (hypervolume(selected[1]) / (max(hypervolume(obj) for _, obj in archive) + 1e-6)))\n    k = min(6, max(4, n // 4))\n\n    for _ in range(min(4, n // 3)):\n        a, b, c, d = sorted(random.sample(range(1, n-1), 4))\n\n        current_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)))\n\n        candidates = [\n            np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[d:c-1:-1], new_solution[d+1:]]),\n            np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[d:b-1:-1], new_solution[d+1:]]),\n            np.concatenate([new_solution[:a], new_solution[d:a-1:-1], new_solution[c:d-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]])\n        ]\n\n        for candidate in candidates:\n            new_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(-1, n-1)))\n\n            if new_cost < current_cost or random.random() < temperature:\n                new_solution = candidate.copy()\n                current_cost = new_cost\n                temperature *= 0.95\n                break\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution[:n]\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 302,
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted sum of objectives (prioritizing balanced improvement), then applies a dynamic 3-opt+ local search with adaptive perturbation to explore diverse neighborhoods while ensuring feasibility through node repair. It uses a probabilistic acceptance criterion based on cost improvement and solution diversity, balancing exploitation (cost reduction) and exploration (perturbation). The method dynamically adjusts perturbation rates and includes occasional 2-opt-like swaps for further refinement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def weighted_sum(obj, weights=(0.5, 0.5)):\n        return obj[0] * weights[0] + obj[1] * weights[1]\n\n    selected = min(archive, key=lambda x: weighted_sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    diversity = sum(abs(obj[0] - obj[1]) for _, obj in archive) / len(archive)\n    perturbation_rate = min(0.5, max(0.1, diversity / 100))\n\n    for _ in range(min(5, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        current_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)))\n\n        candidates = [\n            np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]])\n        ]\n\n        for candidate in candidates:\n            new_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(-1, n-1)))\n\n            if new_cost < current_cost or random.random() < perturbation_rate:\n                new_solution = candidate.copy()\n                current_cost = new_cost\n                perturbation_rate *= 0.9\n                break\n\n    if random.random() < 0.3:\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        new_solution[i:j] = new_solution[j-1:i-1:-1]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution[:n]\n\n",
        "score": [
            -0.8177558163840855,
            1.4071353077888489
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def weighted_sum(obj, weights=(0.5, 0.5)):\n        return obj[0] * weights[0] + obj[1] * weights[1]\n\n    selected = min(archive, key=lambda x: weighted_sum(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    diversity = sum(abs(obj[0] - obj[1]) for _, obj in archive) / len(archive)\n    perturbation_rate = min(0.5, max(0.1, diversity / 100))\n\n    for _ in range(min(5, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        current_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(-1, n-1)))\n\n        candidates = [\n            np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]])\n        ]\n\n        for candidate in candidates:\n            new_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(-1, n-1)) +\n                        sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(-1, n-1)))\n\n            if new_cost < current_cost or random.random() < perturbation_rate:\n                new_solution = candidate.copy()\n                current_cost = new_cost\n                perturbation_rate *= 0.9\n                break\n\n    if random.random() < 0.3:\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        new_solution[i:j] = new_solution[j-1:i-1:-1]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution[:n]\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines hypervolume-based selection with an adaptive segment-swapping mechanism, prioritizing solutions with high hypervolume and crowding distance while dynamically adjusting segment sizes and swap probabilities based on temperature. It ensures feasibility by validating and repairing tours after segment swaps, with the temperature parameter gradually decreasing to focus on high-quality local improvements. The key variables are the base solution (selected via hypervolume/crowding), segment size (adaptive to temperature), and repair mechanism (handling missing/duplicate nodes). The structure alternates between selection, segment swaps, and validation, with temperature controlling exploration/exploitation trade-offs.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj1, obj2):\n        return max(0, obj1[0] - obj2[0]) * max(0, obj1[1] - obj2[1])\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    # Select solution with highest hypervolume and crowding distance\n    archive.sort(key=lambda x: (-hypervolume(x[1], (0, 0)), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Temperature parameter for adaptive control\n    temperature = max(1.0, n / 10)\n\n    # Adaptive segment swapping\n    segment_size = max(2, min(n // 3, int(temperature)))\n    num_swaps = min(3, max(1, n // (segment_size * 2)))\n\n    for _ in range(num_swaps):\n        if random.random() < (0.8 * temperature / max(1.0, n / 5)):\n            # Select two non-overlapping segments\n            seg1_start = random.randint(1, n - 2 * segment_size - 1)\n            seg2_start = random.randint(seg1_start + segment_size, n - segment_size - 1)\n\n            seg1 = new_solution[seg1_start:seg1_start+segment_size]\n            seg2 = new_solution[seg2_start:seg2_start+segment_size]\n\n            # Swap segments\n            new_solution[seg1_start:seg1_start+segment_size] = seg2\n            new_solution[seg2_start:seg2_start+segment_size] = seg1\n\n            # Decrease temperature\n            temperature *= 0.95\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            new_solution[np.where(np.isin(new_solution, list(extra)))[0][0]] = next(iter(missing))\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the archive by prioritizing non-dominated ones with balanced objectives, then applies an adaptive segment-swap local search to generate neighbors while ensuring feasibility through dynamic validation and repair. It balances exploration and exploitation through mutation intensity proportional to solution quality, and uses segment swaps to diversify the search space while maintaining tour validity. The critical design ideas are dominance-based selection, adaptive mutation intensity, and a novel segment-swap operator with feasibility repair.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    # Select non-dominated solutions\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with best balance between objectives\n    selected = min(non_dominated, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive mutation intensity\n    mutation_intensity = min(0.5, 0.1 + (selected[1][0] + selected[1][1]) / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    # Novel segment-swap local search\n    for _ in range(int(mutation_intensity * n)):\n        # Random segment selection\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n\n        # Random insertion point\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Perform segment swap\n        segment = new_solution[start:end]\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Reconstruct tour from scratch if too many errors\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if len(missing) > n//2 or len(extra) > n//2:\n            new_solution = np.random.permutation(n)\n        else:\n            # Local repair\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the archive using hypervolume and dominance ranking, then applies an adaptive 3-opt+ local search with temperature-based probabilistic edge swaps to generate neighbors, ensuring tour feasibility through dynamic validation and repair. It prioritizes non-dominated solutions with high hypervolume, uses a mix of segment-based operations (reverse, shift, swap, rotate, edge_swap), and dynamically adjusts the intensity of exploration based on temperature derived from solution quality. The method ensures feasibility by repairing missing or duplicate nodes in the generated tour.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    # Select non-dominated solutions\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with highest hypervolume\n    selected = max(non_dominated, key=lambda x: hypervolume(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = 1.0 - (hypervolume(selected[1]) / (max(hypervolume(obj) for _, obj in archive) + 1e-6))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'rotate', 'swap', 'edge_swap'], weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            elif op == 'rotate':\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n            else:  # edge_swap\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n                if random.random() < 0.3:\n                    new_solution = np.concatenate([\n                        new_solution[:a],\n                        new_solution[b:b+1],\n                        new_solution[a+1:b],\n                        new_solution[a:a+1],\n                        new_solution[b+1:]\n                    ])\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines hypervolume-based selection with a novel adaptive segment-swapping mechanism, prioritizing high-potential solutions and dynamically adjusting segment sizes and swap probabilities based on temperature, while incorporating probabilistic edge-swaps to balance exploration and exploitation. It ensures feasibility through dynamic validation and repair, gradually focusing on local improvements as temperature decreases.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj1, obj2):\n        return max(0, obj1[0] - obj2[0]) * max(0, obj1[1] - obj2[1])\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    archive.sort(key=lambda x: (-hypervolume(x[1], (0, 0)), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    temperature = max(1.0, n / 10)\n    segment_size = max(2, min(n // 3, int(temperature)))\n    num_swaps = min(3, max(1, n // (segment_size * 2)))\n\n    for _ in range(num_swaps):\n        if random.random() < (0.8 * temperature / max(1.0, n / 5)):\n            seg1_start = random.randint(1, n - 2 * segment_size - 1)\n            seg2_start = random.randint(seg1_start + segment_size, n - segment_size - 1)\n\n            seg1 = new_solution[seg1_start:seg1_start+segment_size]\n            seg2 = new_solution[seg2_start:seg2_start+segment_size]\n\n            new_solution[seg1_start:seg1_start+segment_size] = seg2\n            new_solution[seg2_start:seg2_start+segment_size] = seg1\n\n            temperature *= 0.95\n\n    for _ in range(min(3, n // 2)):\n        i, j = random.sample(range(1, n-1), 2)\n        if random.random() < temperature:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            if random.random() < 0.3:\n                new_solution = np.concatenate([\n                    new_solution[:i],\n                    new_solution[j:j+1],\n                    new_solution[i+1:j],\n                    new_solution[i:i+1],\n                    new_solution[j+1:]\n                ])\n\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects non-dominated solutions from the archive using hypervolume-based ranking, then applies a temperature-controlled hybrid local search with probabilistic segment operations (reverse, shift, swap, rotate, edge_swap) to generate neighbors, ensuring feasibility through dynamic repair of duplicate nodes. The temperature parameter adapts the search intensity based on solution quality, while segment size and operation selection are dynamically adjusted to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    selected = max(non_dominated, key=lambda x: hypervolume(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = 1.0 - (hypervolume(selected[1]) / (max(hypervolume(obj) for _, obj in archive) + 1e-6))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'rotate', 'swap', 'edge_swap'], weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            elif op == 'rotate':\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n            else:\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n                if random.random() < 0.3:\n                    new_solution = np.concatenate([\n                        new_solution[:a],\n                        new_solution[b:b+1],\n                        new_solution[a+1:b],\n                        new_solution[a:a+1],\n                        new_solution[b+1:]\n                    ])\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm combines hypervolume-based selection with a temperature-dependent segment-based local search, using probabilistic segment inversions and adaptive crossover to generate neighbors while maintaining feasibility through a multi-phase repair mechanism. It prioritizes solutions with higher hypervolume and dynamically adjusts segment sizes and mutation probabilities based on solution quality, using a Pareto-aware simulated annealing criterion to balance exploration and exploitation. The most critical design ideas are the segment-based evolutionary strategy with dynamic adjustments and the hybrid local search that preserves tour feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def dominates(a, b):\n        return a[0] <= b[0] and a[1] <= b[1] and (a[0] < b[0] or a[1] < b[1])\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: (-hypervolume(x[1]), -sum(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    temperature = max(0.1, 1.0 - (hypervolume(archive[0][1]) / (sum(hypervolume(obj) for _, obj in archive) + 1e-6)))\n    segment_size = max(2, min(n // 3, int(temperature * n / 3)))\n\n    for _ in range(int(1 / temperature)):\n        if random.random() < (0.7 * temperature):\n            seg_start = random.randint(1, n - segment_size - 1)\n            seg = new_solution[seg_start:seg_start+segment_size]\n\n            if random.random() < 0.6:\n                seg = seg[::-1]\n\n            best_pos = -1\n            best_cost = float('inf')\n\n            for pos in range(1, n - segment_size + 1):\n                if pos >= seg_start and pos < seg_start + segment_size:\n                    continue\n\n                temp_solution = new_solution.copy()\n                temp_solution[seg_start:seg_start+segment_size] = temp_solution[pos:pos+segment_size]\n                temp_solution[pos:pos+segment_size] = seg\n\n                cost1 = sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(1, n)) + distance_matrix_1[temp_solution[-1], temp_solution[0]]\n                cost2 = sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(1, n)) + distance_matrix_2[temp_solution[-1], temp_solution[0]]\n\n                total_cost = (cost1 + cost2) * (1 + 0.1 * random.random() / temperature)\n\n                if total_cost < best_cost or (total_cost > 0 and random.random() < np.exp(-total_cost / temperature)):\n                    best_cost = total_cost\n                    best_pos = pos\n\n            if best_pos != -1:\n                new_solution[seg_start:seg_start+segment_size] = new_solution[best_pos:best_pos+segment_size]\n                new_solution[best_pos:best_pos+segment_size] = seg\n\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Hypervolume, adaptive 3-opt+, dominance ranking, probabilistic edge swaps.\n- **Advice**: Select solutions via hypervolume and dominance ranking, then apply adaptive 3-opt+ (hybrid of 3-opt and edge swaps) with temperature-based probabilistic acceptance.\n- **Avoid**: Random selection, single-objective metrics, or operators that risk infeasibility.\n- **Explanation**: Hypervolume/dominance ensures Pareto diversity, while adaptive 3-opt+ balances local refinement and edge exploration without invalid tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 303,
        "algorithm": "The algorithm selects non-dominated solutions using hypervolume ranking, then applies an adaptive 3-opt+ local search with temperature-based probabilistic edge swaps, ensuring feasibility by dynamically repairing duplicate nodes while balancing exploration and exploitation through dynamic segment sizes and operation probabilities. It prioritizes high-hypervolume solutions and uses temperature to adaptively switch between segment-based operations and edge swaps, with a focus on maintaining tour validity through node uniqueness checks. The approach combines multi-objective selection with a hybrid local search strategy that dynamically adjusts operation types based on solution quality and problem size.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    selected = max(non_dominated, key=lambda x: hypervolume(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = 1.0 - (hypervolume(selected[1]) / (max(hypervolume(obj) for _, obj in archive) + 1e-6))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'rotate', 'swap', 'edge_swap'], weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            elif op == 'rotate':\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n            else:\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n                if random.random() < 0.3:\n                    new_solution = np.concatenate([\n                        new_solution[:a],\n                        new_solution[b:b+1],\n                        new_solution[a+1:b],\n                        new_solution[a:a+1],\n                        new_solution[b+1:]\n                    ])\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.7787335364168699,
            0.5860230922698975
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    selected = max(non_dominated, key=lambda x: hypervolume(x[1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    temperature = 1.0 - (hypervolume(selected[1]) / (max(hypervolume(obj) for _, obj in archive) + 1e-6))\n    k = min(5, max(3, n // 5))\n\n    for _ in range(min(3, n // 2)):\n        segment = sorted(random.sample(range(1, n-1), k))\n\n        if random.random() < temperature:\n            op = random.choices(['reverse', 'shift', 'rotate', 'swap', 'edge_swap'], weights=[0.2, 0.2, 0.2, 0.2, 0.2])[0]\n            if op == 'reverse':\n                new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n            elif op == 'shift':\n                shift_amount = random.randint(1, len(segment)-1)\n                new_solution[segment] = np.roll(new_solution[segment], shift_amount)\n            elif op == 'swap':\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            elif op == 'rotate':\n                new_solution[segment] = np.roll(new_solution[segment], random.choice([-1, 1]))\n            else:\n                a, b = random.sample(segment, 2)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n                if random.random() < 0.3:\n                    new_solution = np.concatenate([\n                        new_solution[:a],\n                        new_solution[b:b+1],\n                        new_solution[a+1:b],\n                        new_solution[a:a+1],\n                        new_solution[b+1:]\n                    ])\n        else:\n            other_segment = sorted(random.sample(range(1, n-1), k))\n            if random.random() < 0.5:\n                new_solution[segment], new_solution[other_segment] = new_solution[other_segment], new_solution[segment]\n            else:\n                new_solution[segment] = new_solution[other_segment]\n\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing = set(range(n)) - set(unique_nodes)\n        extra = set(unique_nodes) - set(range(n))\n        if missing and extra:\n            for i in range(n):\n                if new_solution[i] in extra:\n                    new_solution[i] = next(iter(missing))\n                    missing.remove(new_solution[i])\n                    if not missing:\n                        break\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the archive by prioritizing non-dominated ones with balanced objectives, then applies an adaptive segment-swap local search to generate neighbors while ensuring feasibility through dynamic validation and repair. It balances exploration and exploitation through mutation intensity proportional to solution quality, and uses segment swaps to diversify the search space while maintaining tour validity. The critical design ideas are dominance-based selection, adaptive mutation intensity, and a novel segment-swap operator with feasibility repair.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    # Select non-dominated solutions\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with best balance between objectives\n    selected = min(non_dominated, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive mutation intensity\n    mutation_intensity = min(0.5, 0.1 + (selected[1][0] + selected[1][1]) / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    # Novel segment-swap local search\n    for _ in range(int(mutation_intensity * n)):\n        # Random segment selection\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n\n        # Random insertion point\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Perform segment swap\n        segment = new_solution[start:end]\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Reconstruct tour from scratch if too many errors\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if len(missing) > n//2 or len(extra) > n//2:\n            new_solution = np.random.permutation(n)\n        else:\n            # Local repair\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 304,
        "algorithm": "The algorithm selects a promising TSP solution from an archive using non-dominated sorting, prioritizing balanced solutions, and applies an efficient segment-swap mutation with dynamic intensity. It ensures feasibility through vectorized repairs using numpy operations, focusing on balancing exploration (via segment swaps) and exploitation (via mutation intensity adjustment). The critical design ideas are precomputed ranks for dominance checks, streamlined segment operations, and numpy-based feasibility repairs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute solution ranks and find non-dominated solutions in O(n)\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.zeros(len(archive), dtype=int)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1] and\n                          (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1])):\n                ranks[i] += 1\n\n    non_dominated_indices = np.where(ranks == 0)[0]\n    if len(non_dominated_indices) == 0:\n        non_dominated_indices = np.arange(len(archive))\n\n    # Select best balanced solution\n    selected_idx = non_dominated_indices[np.argmin(np.abs(objectives[non_dominated_indices, 0] - objectives[non_dominated_indices, 1]))]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Simplified mutation intensity calculation\n    mutation_intensity = min(0.5, 0.1 + (objectives[selected_idx][0] + objectives[selected_idx][1]) / (np.sum(objectives) + 1e-6))\n\n    # Efficient segment-swap using index operations\n    for _ in range(int(mutation_intensity * n)):\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Create new solution by swapping segments\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            new_solution[start:end],\n            new_solution[insert_pos:]\n        ])\n\n    # Fast feasibility repair using numpy\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n or len(new_solution) != n:\n        missing = np.setdiff1d(np.arange(n), unique_nodes)\n        extra = np.setdiff1d(new_solution, np.arange(n))\n        if len(missing) > n//2 or len(extra) > n//2:\n            new_solution = np.random.permutation(n)\n        else:\n            # Vectorized repair\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = missing[0]\n                missing = missing[1:]\n\n    return new_solution\n\n",
        "score": [
            -0.7055176716947547,
            1.2116066813468933
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute solution ranks and find non-dominated solutions in O(n)\n    objectives = np.array([obj for _, obj in archive])\n    ranks = np.zeros(len(archive), dtype=int)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1] and\n                          (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1])):\n                ranks[i] += 1\n\n    non_dominated_indices = np.where(ranks == 0)[0]\n    if len(non_dominated_indices) == 0:\n        non_dominated_indices = np.arange(len(archive))\n\n    # Select best balanced solution\n    selected_idx = non_dominated_indices[np.argmin(np.abs(objectives[non_dominated_indices, 0] - objectives[non_dominated_indices, 1]))]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Simplified mutation intensity calculation\n    mutation_intensity = min(0.5, 0.1 + (objectives[selected_idx][0] + objectives[selected_idx][1]) / (np.sum(objectives) + 1e-6))\n\n    # Efficient segment-swap using index operations\n    for _ in range(int(mutation_intensity * n)):\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Create new solution by swapping segments\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            new_solution[start:end],\n            new_solution[insert_pos:]\n        ])\n\n    # Fast feasibility repair using numpy\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n or len(new_solution) != n:\n        missing = np.setdiff1d(np.arange(n), unique_nodes)\n        extra = np.setdiff1d(new_solution, np.arange(n))\n        if len(missing) > n//2 or len(extra) > n//2:\n            new_solution = np.random.permutation(n)\n        else:\n            # Vectorized repair\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = missing[0]\n                missing = missing[1:]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the archive by prioritizing non-dominated ones with balanced objectives, then applies an adaptive segment-swap local search to generate neighbors while ensuring feasibility through dynamic validation and repair. It balances exploration and exploitation through mutation intensity proportional to solution quality, and uses segment swaps to diversify the search space while maintaining tour validity. The critical design ideas are dominance-based selection, adaptive mutation intensity, and a novel segment-swap operator with feasibility repair.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def dominates(obj1, obj2):\n        return obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])\n\n    # Select non-dominated solutions\n    non_dominated = []\n    for s, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if dominates(other_obj, obj):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with best balance between objectives\n    selected = min(non_dominated, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive mutation intensity\n    mutation_intensity = min(0.5, 0.1 + (selected[1][0] + selected[1][1]) / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    # Novel segment-swap local search\n    for _ in range(int(mutation_intensity * n)):\n        # Random segment selection\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n\n        # Random insertion point\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Perform segment swap\n        segment = new_solution[start:end]\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Reconstruct tour from scratch if too many errors\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if len(missing) > n//2 or len(extra) > n//2:\n            new_solution = np.random.permutation(n)\n        else:\n            # Local repair\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 305,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute non-dominated solutions using a more efficient approach\n    non_dominated = []\n    for i, (s, obj) in enumerate(archive):\n        is_dominated = False\n        for j, (_, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with best balance between objectives\n    selected = min(non_dominated, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Simplified adaptive mutation intensity\n    mutation_intensity = min(0.5, 0.1 + (selected[1][0] + selected[1][1]) / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    # Optimized segment-swap local search with reduced operations\n    for _ in range(int(mutation_intensity * n)):\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Directly swap segments without concatenation\n        segment = new_solution[start:end]\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Simplified feasibility check and repair\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n or len(new_solution) != n:\n        if len(unique_nodes) < n:\n            missing = set(range(n)) - set(unique_nodes)\n            for node in missing:\n                pos = np.where(new_solution == unique_nodes[-1])[0][0]\n                new_solution[pos] = node\n\n    return new_solution\n\n",
        "score": [
            -0.9362126796813541,
            0.3351072072982788
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute non-dominated solutions using a more efficient approach\n    non_dominated = []\n    for i, (s, obj) in enumerate(archive):\n        is_dominated = False\n        for j, (_, other_obj) in enumerate(archive):\n            if i != j and other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((s, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    # Select solution with best balance between objectives\n    selected = min(non_dominated, key=lambda x: abs(x[1][0] - x[1][1]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Simplified adaptive mutation intensity\n    mutation_intensity = min(0.5, 0.1 + (selected[1][0] + selected[1][1]) / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6))\n\n    # Optimized segment-swap local search with reduced operations\n    for _ in range(int(mutation_intensity * n)):\n        seg_length = random.randint(2, min(5, n//2))\n        start = random.randint(0, n - seg_length)\n        end = start + seg_length\n        insert_pos = random.randint(0, n - seg_length)\n        if insert_pos >= start:\n            insert_pos += seg_length\n\n        # Directly swap segments without concatenation\n        segment = new_solution[start:end]\n        new_solution = np.concatenate([\n            new_solution[:start],\n            new_solution[end:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Simplified feasibility check and repair\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n or len(new_solution) != n:\n        if len(unique_nodes) < n:\n            missing = set(range(n)) - set(unique_nodes)\n            for node in missing:\n                pos = np.where(new_solution == unique_nodes[-1])[0][0]\n                new_solution[pos] = node\n\n    return new_solution\n\n",
        "operation": "r1"
    }
]