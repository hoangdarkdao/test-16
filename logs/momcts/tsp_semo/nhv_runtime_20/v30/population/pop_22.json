[
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized objective product) and applies a multi-stage local search: first an adaptive segment inversion that reverses a random segment if it improves both objectives, followed by probabilistic node relocation that moves a node to the best position with a 70% chance. The method ensures feasibility by maintaining unique node visits and uses simulated annealing for occasional uphill moves.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest normalized objective product\n    max_obj = max(max(obj) for _, obj in archive)\n    archive_sorted = sorted(archive, key=lambda x: (x[1][0]/max_obj) * (x[1][1]/max_obj), reverse=True)\n    base_solution = archive_sorted[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Multi-stage local search\n    # Stage 1: Adaptive segment inversion\n    max_seg_size = min(5, n//2)\n    seg_size = np.random.randint(2, max_seg_size+1)\n    i = np.random.randint(0, n - seg_size)\n    segment = new_solution[i:i+seg_size]\n\n    # Evaluate segment in both objectives\n    original_cost1 = sum(distance_matrix_1[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n    original_cost2 = sum(distance_matrix_2[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n\n    reversed_segment = segment[::-1]\n    reversed_cost1 = (distance_matrix_1[new_solution[(i-1)%n], reversed_segment[0]] +\n                     distance_matrix_1[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                     sum(distance_matrix_1[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n    reversed_cost2 = (distance_matrix_2[new_solution[(i-1)%n], reversed_segment[0]] +\n                     distance_matrix_2[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                     sum(distance_matrix_2[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n\n    delta_cost = (reversed_cost1 + reversed_cost2) - (original_cost1 + original_cost2)\n    if delta_cost < 0 or (delta_cost > 0 and np.random.random() < np.exp(-delta_cost/1.0)):\n        new_solution[i:i+seg_size] = reversed_segment\n\n    # Stage 2: Probabilistic node relocation\n    if n > 4 and np.random.random() < 0.7:\n        node_idx = np.random.randint(1, n-1)\n        node = new_solution[node_idx]\n        new_solution = np.delete(new_solution, node_idx)\n\n        best_pos = -1\n        best_cost = float('inf')\n\n        for pos in range(1, n):\n            temp_solution = np.insert(new_solution, pos, node)\n            cost1 = (distance_matrix_1[temp_solution[pos-1], node] +\n                    distance_matrix_1[node, temp_solution[pos]] -\n                    distance_matrix_1[temp_solution[pos-1], temp_solution[pos]])\n            cost2 = (distance_matrix_2[temp_solution[pos-1], node] +\n                    distance_matrix_2[node, temp_solution[pos]] -\n                    distance_matrix_2[temp_solution[pos-1], temp_solution[pos]])\n            total_cost = cost1 + cost2\n\n            if total_cost < best_cost or (total_cost == best_cost and np.random.random() < 0.5):\n                best_cost = total_cost\n                best_pos = pos\n\n        if best_pos != -1:\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    # Ensure feasibility\n    assert len(new_solution) == n, \"Solution length changed\"\n    assert len(np.unique(new_solution)) == n, \"Duplicate nodes in solution\"\n\n    return new_solution\n\n",
        "score": [
            -0.9784972097067457,
            2.5674105882644653
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume-based selection with an adaptive segment-swapping mechanism, prioritizing solutions with high hypervolume and crowding distance while dynamically adjusting segment sizes and swap probabilities based on temperature. It ensures feasibility by validating and repairing tours after segment swaps, with the temperature parameter gradually decreasing to focus on high-quality local improvements. The key variables are the base solution (selected via hypervolume/crowding), segment size (adaptive to temperature), and repair mechanism (handling missing/duplicate nodes). The structure alternates between selection, segment swaps, and validation, with temperature controlling exploration/exploitation trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj1, obj2):\n        return max(0, obj1[0] - obj2[0]) * max(0, obj1[1] - obj2[1])\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    # Select solution with highest hypervolume and crowding distance\n    archive.sort(key=lambda x: (-hypervolume(x[1], (0, 0)), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Temperature parameter for adaptive control\n    temperature = max(1.0, n / 10)\n\n    # Adaptive segment swapping\n    segment_size = max(2, min(n // 3, int(temperature)))\n    num_swaps = min(3, max(1, n // (segment_size * 2)))\n\n    for _ in range(num_swaps):\n        if random.random() < (0.8 * temperature / max(1.0, n / 5)):\n            # Select two non-overlapping segments\n            seg1_start = random.randint(1, n - 2 * segment_size - 1)\n            seg2_start = random.randint(seg1_start + segment_size, n - segment_size - 1)\n\n            seg1 = new_solution[seg1_start:seg1_start+segment_size]\n            seg2 = new_solution[seg2_start:seg2_start+segment_size]\n\n            # Swap segments\n            new_solution[seg1_start:seg1_start+segment_size] = seg2\n            new_solution[seg2_start:seg2_start+segment_size] = seg1\n\n            # Decrease temperature\n            temperature *= 0.95\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            new_solution[np.where(np.isin(new_solution, list(extra)))[0][0]] = next(iter(missing))\n\n    return new_solution\n\n",
        "score": [
            -0.971151372604398,
            0.7450237274169922
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using hypervolume and crowding distance metrics, then applies adaptive 3-opt with temperature-based probabilistic acceptance to generate a neighbor solution while ensuring tour feasibility through validation and repair. It prioritizes solutions with higher hypervolume and lower crowding distance, then explores 3-opt moves probabilistically based on a temperature parameter that decreases with solution quality, and finally repairs any infeasibilities in the tour.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    # Select solution with highest hypervolume and least crowded neighbors\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive 3-opt with temperature-based acceptance\n    temperature = max(0.1, 1.0 - (selected[2] / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6)))\n\n    for _ in range(min(3, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        # Evaluate all possible 3-opt moves\n        moves = [\n            # Original order\n            (new_solution, 0),\n            # a-b-c reversed\n            (np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]]), 1),\n            # a-c-b reversed\n            (np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]]), 2),\n            # b-a-c reversed\n            (np.concatenate([new_solution[:b], new_solution[a:b-1:-1], new_solution[c:a-1:-1], new_solution[c+1:]]), 3),\n            # b-c-a reversed\n            (np.concatenate([new_solution[:b], new_solution[c:b-1:-1], new_solution[a:c-1:-1], new_solution[a+1:]]), 4),\n            # c-a-b reversed\n            (np.concatenate([new_solution[:c], new_solution[a:c-1:-1], new_solution[b:a-1:-1], new_solution[b+1:]]), 5),\n            # c-b-a reversed\n            (np.concatenate([new_solution[:c], new_solution[b:c-1:-1], new_solution[a:b-1:-1], new_solution[a+1:]]), 6)\n        ]\n\n        # Calculate costs for each move\n        move_costs = []\n        for move, idx in moves:\n            if idx == 0:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, n-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, n-1))\n            else:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, len(move)-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, len(move)-1))\n            move_costs.append((move, cost1, cost2))\n\n        # Select best move with temperature-based probability\n        best_move = min(move_costs, key=lambda x: (x[1] + x[2]))\n        if (move_costs[0][1] + move_costs[0][2]) > (best_move[1] + best_move[2]) or \\\n           (random.random() < temperature and len(np.unique(best_move[0])) == n):\n            new_solution = best_move[0].copy()\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Simple repair mechanism\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -0.9931873366440623,
            3.3111976385116577
        ]
    },
    {
        "algorithm": "The algorithm selects solutions from the archive using hypervolume and crowding distance metrics, then applies an adaptive 3-opt local search with temperature-based probabilistic acceptance to generate neighbors, balancing Pareto diversity and local refinement while ensuring tour feasibility. It prioritizes solutions with higher hypervolume and lower crowding distance, then evaluates multiple 3-opt moves to find the most promising neighbor, occasionally accepting worse solutions probabilistically based on temperature, and includes a repair mechanism to maintain feasibility. The temperature is dynamically adjusted based on the solution's hypervolume relative to the archive.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj1, obj2):\n        return abs(obj1[0] - obj2[0]) + abs(obj1[1] - obj2[1])\n\n    # Select solution with highest hypervolume and least crowded neighbors\n    archive_with_scores = [(s, obj, hypervolume(obj), crowding_distance(obj, archive[i+1][1]) if i < len(archive)-1 else 0)\n                          for i, (s, obj) in enumerate(archive)]\n    selected = max(archive_with_scores, key=lambda x: (x[2], -x[3]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive 3-opt with temperature-based acceptance\n    temperature = max(0.1, 1.0 - (selected[2] / (sum(obj[0] + obj[1] for _, obj in archive) + 1e-6)))\n\n    for _ in range(min(3, n // 2)):\n        a, b, c = sorted(random.sample(range(1, n-1), 3))\n\n        # Evaluate all possible 3-opt moves\n        moves = [\n            # Original order\n            (new_solution, 0),\n            # a-b-c reversed\n            (np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[c:b-1:-1], new_solution[c+1:]]), 1),\n            # a-c-b reversed\n            (np.concatenate([new_solution[:a], new_solution[c:a-1:-1], new_solution[b:c-1:-1], new_solution[b+1:]]), 2),\n            # b-a-c reversed\n            (np.concatenate([new_solution[:b], new_solution[a:b-1:-1], new_solution[c:a-1:-1], new_solution[c+1:]]), 3),\n            # b-c-a reversed\n            (np.concatenate([new_solution[:b], new_solution[c:b-1:-1], new_solution[a:c-1:-1], new_solution[a+1:]]), 4),\n            # c-a-b reversed\n            (np.concatenate([new_solution[:c], new_solution[a:c-1:-1], new_solution[b:a-1:-1], new_solution[b+1:]]), 5),\n            # c-b-a reversed\n            (np.concatenate([new_solution[:c], new_solution[b:c-1:-1], new_solution[a:b-1:-1], new_solution[a+1:]]), 6)\n        ]\n\n        # Calculate costs for each move\n        move_costs = []\n        for move, idx in moves:\n            if idx == 0:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, n-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, n-1))\n            else:\n                cost1 = sum(distance_matrix_1[move[i], move[i+1]] for i in range(-1, len(move)-1))\n                cost2 = sum(distance_matrix_2[move[i], move[i+1]] for i in range(-1, len(move)-1))\n            move_costs.append((move, cost1, cost2))\n\n        # Select best move with temperature-based probability\n        best_move = min(move_costs, key=lambda x: (x[1] + x[2]))\n        if (move_costs[0][1] + move_costs[0][2]) > (best_move[1] + best_move[2]) or \\\n           (random.random() < temperature and len(np.unique(best_move[0])) == n):\n            new_solution = best_move[0].copy()\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # Simple repair mechanism\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -1.0251145125491288,
            3.4849088191986084
        ]
    },
    {
        "algorithm": "The algorithm selects the most Pareto-optimal solution from the archive using dominance ranking, then applies a hybrid local search combining adaptive k-opt moves (with segment reversals and insertions) and probabilistic edge flips to generate a neighbor, while ensuring feasibility through validation and repair. The move size (k) adapts to problem size, and segment operations are biased toward reversals (70% probability). The solution prioritizes diversity and local improvement while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance_rank(solutions):\n        ranks = [0] * len(solutions)\n        for i, (s1, obj1) in enumerate(solutions):\n            for j, (s2, obj2) in enumerate(solutions):\n                if i != j and (obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])):\n                    ranks[j] += 1\n        return ranks\n\n    ranks = pareto_dominance_rank(archive)\n    best_idx = np.argmin(ranks)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Hybrid k-opt with adaptive size\n    k = min(3, max(2, n // 5))\n    for _ in range(min(2, n // 3)):\n        segment = sorted(random.sample(range(1, n-1), k))\n        if random.random() < 0.7:\n            # Segment reversal with probability\n            new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n        else:\n            # Segment insertion\n            insert_pos = random.randint(0, n-1)\n            segment_nodes = new_solution[segment]\n            new_solution = np.concatenate([new_solution[:insert_pos], segment_nodes, new_solution[insert_pos:]])\n            new_solution = np.delete(new_solution, np.where(np.isin(new_solution, segment_nodes))[0][k:])\n\n    # Probabilistic edge flips\n    for _ in range(min(3, n // 2)):\n        if random.random() < 0.6:\n            a, b = sorted(random.sample(range(1, n-1), 2))\n            new_solution[a:b+1] = new_solution[b:a-1:-1]\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            new_solution[np.where(np.isin(new_solution, list(extra)))[0][0]] = next(iter(missing))\n\n    return new_solution\n\n",
        "score": [
            -0.9197952618686553,
            1.2500128746032715
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume and crowding distance selection with an adaptive k-opt (3-5) local search, using temperature-based probabilistic acceptance to balance exploration and exploitation while ensuring feasibility. It prioritizes high-hypervolume solutions and dynamically adjusts segment sizes for segment inversions, with simulated annealing-like temperature decay to control move acceptance probabilities. The method maintains TSP feasibility by validating uniqueness and length of solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    archive.sort(key=lambda x: (-hypervolume(x[1]), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive k-opt (k=3-5) with temperature-based acceptance\n    k = np.random.randint(3, 6)\n    segment_size = max(2, n // k)\n    temp = 1.0 / (1 + np.log(1 + len(archive)))\n\n    for _ in range(2):\n        i = np.random.randint(0, n - segment_size)\n        segment = new_solution[i:i+segment_size]\n\n        # Evaluate original and inverted segment\n        original_cost1 = sum(distance_matrix_1[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(segment_size+1))\n        original_cost2 = sum(distance_matrix_2[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(segment_size+1))\n\n        reversed_segment = segment[::-1]\n        reversed_cost1 = (distance_matrix_1[new_solution[(i-1)%n], reversed_segment[0]] +\n                         distance_matrix_1[reversed_segment[-1], new_solution[(i+segment_size)%n]] +\n                         sum(distance_matrix_1[reversed_segment[j-1], reversed_segment[j]] for j in range(1, segment_size)))\n        reversed_cost2 = (distance_matrix_2[new_solution[(i-1)%n], reversed_segment[0]] +\n                         distance_matrix_2[reversed_segment[-1], new_solution[(i+segment_size)%n]] +\n                         sum(distance_matrix_2[reversed_segment[j-1], reversed_segment[j]] for j in range(1, segment_size)))\n\n        delta_cost = (reversed_cost1 + reversed_cost2) - (original_cost1 + original_cost2)\n        if delta_cost < 0 or (delta_cost > 0 and np.random.random() < np.exp(-delta_cost / temp)):\n            new_solution[i:i+segment_size] = reversed_segment\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.962732381814172,
            1.5362690687179565
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume and crowding distance to prioritize high-quality solutions from the archive, then applies a dynamic multi-segment local search that alternates between insertion and reversal operations, with segment sizes and positions determined by objective-space costs and probabilistic acceptance. It ensures feasibility through objective-driven repairs when necessary, balancing exploration and exploitation with temperature-based selection.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    def objective_difference(obj1, obj2):\n        return (obj1[0] - obj2[0]) ** 2 + (obj1[1] - obj2[1]) ** 2\n\n    archive.sort(key=lambda x: (-hypervolume(x[1]), -crowding_distance(x[1])))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    temp = 1.0 / (1 + np.log(1 + len(archive)))\n    num_segments = np.random.randint(2, min(5, n//3))\n\n    for _ in range(num_segments):\n        seg_length = np.random.randint(2, min(5, n//num_segments))\n        i = np.random.randint(0, n - seg_length)\n        segment = new_solution[i:i+seg_length]\n\n        if np.random.random() < 0.5:\n            # Multi-segment insertion with objective-aware positioning\n            insertion_scores = []\n            for pos in range(1, n-seg_length):\n                if pos >= i and pos < i+seg_length:\n                    continue\n                cost1 = (distance_matrix_1[new_solution[pos-1], segment[0]] +\n                        distance_matrix_1[segment[-1], new_solution[pos]] -\n                        distance_matrix_1[new_solution[pos-1], new_solution[pos]])\n                cost2 = (distance_matrix_2[new_solution[pos-1], segment[0]] +\n                        distance_matrix_2[segment[-1], new_solution[pos]] -\n                        distance_matrix_2[new_solution[pos-1], new_solution[pos]])\n                insertion_scores.append((cost1 + cost2, pos))\n\n            if insertion_scores:\n                best_pos = min(insertion_scores, key=lambda x: x[0])[1]\n                new_solution = np.concatenate([new_solution[:best_pos], segment, new_solution[best_pos:]])\n        else:\n            # Dynamic segment reversal with objective balancing\n            reversed_segment = segment[::-1]\n            original_cost1 = sum(distance_matrix_1[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_length+1))\n            original_cost2 = sum(distance_matrix_2[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_length+1))\n            reversed_cost1 = (distance_matrix_1[new_solution[(i-1)%n], reversed_segment[0]] +\n                             distance_matrix_1[reversed_segment[-1], new_solution[(i+seg_length)%n]] +\n                             sum(distance_matrix_1[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_length)))\n            reversed_cost2 = (distance_matrix_2[new_solution[(i-1)%n], reversed_segment[0]] +\n                             distance_matrix_2[reversed_segment[-1], new_solution[(i+seg_length)%n]] +\n                             sum(distance_matrix_2[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_length)))\n\n            delta_cost = (reversed_cost1 + reversed_cost2) - (original_cost1 + original_cost2)\n            if delta_cost < 0 or (delta_cost > 0 and np.random.random() < np.exp(-delta_cost / temp)):\n                new_solution[i:i+seg_length] = reversed_segment\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n:\n        visited = set()\n        repaired = []\n        for node in new_solution:\n            if node not in visited:\n                visited.add(node)\n                repaired.append(node)\n\n        missing_nodes = set(range(n)) - visited\n        for node in missing_nodes:\n            insertion_scores = []\n            for i in range(1, len(repaired)):\n                cost1 = (distance_matrix_1[repaired[i-1], node] +\n                        distance_matrix_1[node, repaired[i]] -\n                        distance_matrix_1[repaired[i-1], repaired[i]])\n                cost2 = (distance_matrix_2[repaired[i-1], node] +\n                        distance_matrix_2[node, repaired[i]] -\n                        distance_matrix_2[repaired[i-1], repaired[i]])\n                insertion_scores.append((cost1 + cost2, i))\n\n            best_pos = min(insertion_scores, key=lambda x: x[0])[1]\n            repaired.insert(best_pos, node)\n\n        new_solution = np.array(repaired)\n\n    return new_solution\n\n",
        "score": [
            -0.8647747298796808,
            0.8773264288902283
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using hypervolume and Pareto dominance, then applies adaptive segment inversion with dynamic temperature scaling to generate neighbors, ensuring feasibility through validation and repair. It prioritizes solutions with high hypervolume and non-dominated status, dynamically adjusting segment sizes and inversion probabilities based on solution quality, while maintaining feasibility through repair mechanisms. The temperature parameter and segment size are adjusted based on the solution's quality and diversity, with higher-quality solutions receiving more aggressive modifications.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj1, obj2):\n        return max(0, obj1[0] - obj2[0]) * max(0, obj1[1] - obj2[1])\n\n    def dominates(obj1, obj2):\n        return (obj1[0] <= obj2[0] and obj1[1] < obj2[1]) or (obj1[0] < obj2[0] and obj1[1] <= obj2[1])\n\n    # Select solution with highest hypervolume and non-dominated status\n    archive.sort(key=lambda x: (-hypervolume(x[1], (0, 0)), -sum(1 for y in archive if dominates(y[1], x[1]))))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Dynamic temperature parameter\n    temperature = max(1.0, n / 8)\n\n    # Adaptive segment inversion\n    segment_size = max(2, min(n // 4, int(temperature * 1.5)))\n    num_inversions = min(4, max(2, n // (segment_size * 3)))\n\n    for _ in range(num_inversions):\n        if random.random() < (0.7 * temperature / max(1.0, n / 4)):\n            seg_start = random.randint(1, n - segment_size - 1)\n            segment = new_solution[seg_start:seg_start+segment_size]\n            new_solution[seg_start:seg_start+segment_size] = segment[::-1]\n\n            # Adjust temperature based on solution quality\n            temperature *= 0.9 if hypervolume(archive[0][1], (0, 0)) > sum(x[1][0]+x[1][1] for x in archive)/len(archive) else 0.95\n\n    # Feasibility repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            new_solution[np.where(np.isin(new_solution, list(extra)))[0][0]] = next(iter(missing))\n\n    return new_solution\n\n",
        "score": [
            -0.9380237135048078,
            1.4545336961746216
        ]
    },
    {
        "algorithm": "The algorithm selects the most diverse solution from the archive (based on the sum of edge lengths in both objectives) and applies a hybrid local search: 60% probability for a segment shift (moving a random segment to a new position) or 40% for a node swap with another node, ensuring feasibility by validating uniqueness and reverting to a simple edge swap if invalid. The selection prioritizes solutions with higher diversity, while the local search balances exploration (segment shifts) and exploitation (node swaps).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity (sum of edge lengths in both objectives)\n    def diversity_score(solution):\n        cost1 = sum(distance_matrix_1[solution[i-1], solution[i]] for i in range(len(solution)))\n        cost2 = sum(distance_matrix_2[solution[i-1], solution[i]] for i in range(len(solution)))\n        return cost1 + cost2\n\n    archive_sorted = sorted(archive, key=lambda x: diversity_score(x[0]))\n    selected_solution = archive_sorted[-1][0].copy()  # Select the most diverse solution\n\n    # Hybrid local search\n    if random.random() < 0.6:  # 60% chance for segment shift\n        n = len(selected_solution)\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        k = random.randint(1, n-1)\n        new_solution = selected_solution.copy()\n        segment = new_solution[i:j+1]\n        new_solution = np.concatenate([new_solution[:i], new_solution[j+1:k], segment, new_solution[k:]])\n    else:  # 40% chance for node swap with another segment\n        n = len(selected_solution)\n        i = random.randint(1, n-1)\n        j = random.randint(1, n-1)\n        while j == i or j == (i-1) % n or j == (i+1) % n:\n            j = random.randint(1, n-1)\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure the new solution is valid (no duplicates)\n    if len(np.unique(new_solution)) != len(selected_solution):\n        # If invalid, revert to a simple edge swap\n        i, j = sorted(random.sample(range(1, len(selected_solution)-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -1.0117954119007642,
            7.185237467288971
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume-based selection with a multi-segment perturbation strategy, dynamically adjusting segment sizes and applying reversals/shifts to explore the solution space while ensuring feasibility through a repair mechanism. It prioritizes solutions with higher hypervolume and adaptively selects segments for perturbation, with cross-segment edge swaps enhancing diversity, while the repair step guarantees valid TSP tours.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive_sorted = sorted(archive, key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive_sorted[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Multi-segment perturbation\n    num_segments = min(3, max(2, n // 4))\n    segment_lengths = sorted(random.sample(range(2, n // 2), num_segments))\n    segments = []\n    current_pos = 1\n\n    for length in segment_lengths:\n        if current_pos + length >= n - 1:\n            break\n        segments.append((current_pos, current_pos + length))\n        current_pos += length + 1\n\n    for start, end in segments:\n        if random.random() < 0.6:\n            # Segment reversal\n            new_solution[start:end] = new_solution[end-1:start-1:-1]\n        else:\n            # Segment shift\n            shift_pos = random.randint(1, n - (end - start + 1))\n            segment = new_solution[start:end]\n            new_solution = np.concatenate([new_solution[:start], new_solution[end:shift_pos], segment, new_solution[shift_pos:]])\n\n    # Cross-segment edge swaps\n    for _ in range(min(2, n // 3)):\n        if random.random() < 0.5:\n            seg1_start, seg1_end = random.choice(segments)\n            seg2_start, seg2_end = random.choice(segments)\n            if seg1_start != seg2_start:\n                a = random.randint(seg1_start, seg1_end - 1)\n                b = random.randint(seg2_start, seg2_end - 1)\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            for node in extra:\n                if len(missing) == 0:\n                    break\n                pos = np.where(new_solution == node)[0][0]\n                new_solution[pos] = next(iter(missing))\n                missing.remove(next(iter(missing)))\n\n    return new_solution\n\n",
        "score": [
            -0.7377970275453563,
            0.9160555601119995
        ]
    }
]