[
    {
        "algorithm": "The algorithm selects the best solution from the archive (lowest total cost) and applies a hybrid local search: 70% chance for an edge swap (reversing a segment) or 30% for a segment reversal (swapping two edges), ensuring feasibility by validating uniqueness. If invalid, it defaults to a simple edge swap. The selection prioritizes solutions with high potential for improvement, while the local search diversifies exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (lowest total cost)\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: choose between edge swap or segment reversal based on current diversity\n    if random.random() < 0.7:  # 70% chance for edge swap\n        # Edge swap: select two random edges and swap their connections\n        n = len(selected_solution)\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i:j+1] = selected_solution[j:i-1:-1]\n    else:\n        # Segment reversal: reverse a random segment of the tour\n        n = len(selected_solution)\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i:j+1] = selected_solution[j:i-1:-1]\n\n    # Ensure the new solution is valid (no duplicates)\n    if len(np.unique(new_solution)) != len(selected_solution):\n        # If invalid, revert to a simple edge swap\n        i, j = sorted(random.sample(range(1, len(selected_solution)-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.695281572845684,
            1.1709911227226257
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects the best solution from the archive (prioritizing lowest total cost) and applies a hybrid local search combining multi-segment reversal (with probabilistic segment selection) and node relocation (with limited randomness). It ensures feasibility through validation checks, reverting to the original solution if duplicates or length changes are detected. The approach balances exploration (via random segment selection and relocation) while maintaining feasibility, making it more creative than standard 2-opt methods.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (lowest total cost)\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n    new_solution = selected_solution.copy()\n\n    n = len(selected_solution)\n    if n < 4:\n        return new_solution  # Too small to apply meaningful local search\n\n    # Hybrid local search: multi-segment reversal with probabilistic node relocation\n    # Multi-segment reversal (generalization of segment reversal)\n    num_segments = min(3, n // 3)  # Limit number of segments to avoid excessive changes\n    segment_indices = sorted(random.sample(range(1, n-1), num_segments * 2))\n    for i in range(0, len(segment_indices), 2):\n        start, end = segment_indices[i], segment_indices[i+1]\n        if start < end:\n            new_solution[start:end+1] = new_solution[end:start-1:-1]\n\n    # Probabilistic node relocation (inspired by Algorithm 2)\n    for _ in range(min(2, n // 2)):  # Limit number of relocations\n        if random.random() < 0.6:  # 60% chance to relocate\n            k = random.randint(0, n-1)\n            l = random.randint(0, n-1)\n            if k != l:\n                node = new_solution[k]\n                new_solution = np.delete(new_solution, k)\n                new_solution = np.insert(new_solution, l, node)\n\n    # Two-phase validation to ensure feasibility\n    # Phase 1: Check for duplicates\n    if len(np.unique(new_solution)) != n:\n        # If duplicates found, revert to original solution\n        new_solution = selected_solution.copy()\n\n    # Phase 2: Check solution length\n    if len(new_solution) != n:\n        # If length changed, revert to original solution\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.719801261221124,
            1.2372207641601562
        ]
    },
    {
        "algorithm": "The algorithm selects the most diverse solution from the archive (based on the sum of edge lengths in both objectives) and applies a hybrid local search: 60% probability for a segment shift (moving a random segment to a new position) or 40% for a node swap with another node, ensuring feasibility by validating uniqueness and reverting to a simple edge swap if invalid. The selection prioritizes solutions with higher diversity, while the local search balances exploration (segment shifts) and exploitation (node swaps).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity (sum of edge lengths in both objectives)\n    def diversity_score(solution):\n        cost1 = sum(distance_matrix_1[solution[i-1], solution[i]] for i in range(len(solution)))\n        cost2 = sum(distance_matrix_2[solution[i-1], solution[i]] for i in range(len(solution)))\n        return cost1 + cost2\n\n    archive_sorted = sorted(archive, key=lambda x: diversity_score(x[0]))\n    selected_solution = archive_sorted[-1][0].copy()  # Select the most diverse solution\n\n    # Hybrid local search\n    if random.random() < 0.6:  # 60% chance for segment shift\n        n = len(selected_solution)\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        k = random.randint(1, n-1)\n        new_solution = selected_solution.copy()\n        segment = new_solution[i:j+1]\n        new_solution = np.concatenate([new_solution[:i], new_solution[j+1:k], segment, new_solution[k:]])\n    else:  # 40% chance for node swap with another segment\n        n = len(selected_solution)\n        i = random.randint(1, n-1)\n        j = random.randint(1, n-1)\n        while j == i or j == (i-1) % n or j == (i+1) % n:\n            j = random.randint(1, n-1)\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure the new solution is valid (no duplicates)\n    if len(np.unique(new_solution)) != len(selected_solution):\n        # If invalid, revert to a simple edge swap\n        i, j = sorted(random.sample(range(1, len(selected_solution)-1), 2))\n        new_solution = selected_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -1.0117954119007642,
            7.185237467288971
        ]
    },
    {
        "algorithm": "This heuristic algorithm combines adaptive solution selection with a hybrid local search operator that dynamically alternates between multi-segment reversal and probabilistic edge insertion, prioritizing solutions with high hypervolume and diversity. It employs a temperature-based acceptance criterion to balance exploration and exploitation, with a fallback mechanism to ensure feasibility through Pareto-optimality-preserving edge swaps. The algorithm emphasizes both local refinement and global diversification by modulating search behavior based on solution quality and diversity metrics.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    # Select top 20% solutions by hypervolume and choose the most diverse one\n    archive_sorted = sorted(archive, key=lambda x: hypervolume(x[1]), reverse=True)\n    top_solutions = archive_sorted[:max(1, len(archive_sorted) // 5)]\n    selected_solution = max(top_solutions, key=lambda x: len(set(x[0])) / len(x[0]))[0].copy()\n\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Calculate solution quality metrics\n    diversity = len(set(selected_solution)) / n\n    current_cost1 = sum(distance_matrix_1[selected_solution[i], selected_solution[i+1]] for i in range(-1, n-1))\n    current_cost2 = sum(distance_matrix_2[selected_solution[i], selected_solution[i+1]] for i in range(-1, n-1))\n    current_hv = hypervolume((current_cost1, current_cost2))\n\n    # Adaptive operator selection\n    if diversity > 0.7 or random.random() < 0.6:\n        # Multi-segment reversal with Pareto-aware length selection\n        segment_lengths = [2, 3, 4]\n        selected_length = random.choice(segment_lengths)\n        i = random.randint(1, n - selected_length - 1)\n        j = i + selected_length\n\n        # Evaluate potential segments\n        segments = [\n            (i, j, selected_solution[i:j]),\n            (i, j, selected_solution[i:j][::-1]),\n            (i, j, sorted(selected_solution[i:j], key=lambda x: distance_matrix_1[selected_solution[i-1], x] + distance_matrix_1[x, selected_solution[j]]))\n        ]\n\n        best_segment = min(segments, key=lambda s: hypervolume((\n            current_cost1 - distance_matrix_1[selected_solution[i-1], selected_solution[i]] - distance_matrix_1[selected_solution[j-1], selected_solution[j]] +\n            distance_matrix_1[selected_solution[i-1], s[2][0]] + sum(distance_matrix_1[s[2][k], s[2][k+1]] for k in range(len(s[2])-1)) + distance_matrix_1[s[2][-1], selected_solution[j]],\n            current_cost2 - distance_matrix_2[selected_solution[i-1], selected_solution[i]] - distance_matrix_2[selected_solution[j-1], selected_solution[j]] +\n            distance_matrix_2[selected_solution[i-1], s[2][0]] + sum(distance_matrix_2[s[2][k], s[2][k+1]] for k in range(len(s[2])-1)) + distance_matrix_2[s[2][-1], selected_solution[j]]\n        )))\n\n        new_solution[i:j] = best_segment[2]\n    else:\n        # Probabilistic edge insertion with temperature-based acceptance\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        temp = max(0.1, 1.0 - (current_hv / (current_cost1 + current_cost2 + 1e-6)))\n\n        if random.random() < temp:\n            segment = new_solution[i:j+1]\n            new_solution = np.concatenate([new_solution[:i], new_solution[j+1:]])\n            insert_pos = random.randint(1, len(new_solution)-1)\n            new_solution = np.insert(new_solution, insert_pos, segment)\n\n    # Feasibility validation and repair\n    if len(np.unique(new_solution)) != n:\n        # Pareto-optimality preserving edge swap\n        i, j = sorted(random.sample(range(1, n-1), 2))\n        old_cost1 = distance_matrix_1[selected_solution[i-1], selected_solution[i]] + distance_matrix_1[selected_solution[i], selected_solution[i+1]] + \\\n                    distance_matrix_1[selected_solution[j-1], selected_solution[j]] + distance_matrix_1[selected_solution[j], selected_solution[j+1]]\n        new_cost1 = distance_matrix_1[selected_solution[i-1], selected_solution[j]] + distance_matrix_1[selected_solution[j], selected_solution[i+1]] + \\\n                    distance_matrix_1[selected_solution[j-1], selected_solution[i]] + distance_matrix_1[selected_solution[i], selected_solution[j+1]]\n        old_cost2 = distance_matrix_2[selected_solution[i-1], selected_solution[i]] + distance_matrix_2[selected_solution[i], selected_solution[i+1]] + \\\n                    distance_matrix_2[selected_solution[j-1], selected_solution[j]] + distance_matrix_2[selected_solution[j], selected_solution[j+1]]\n        new_cost2 = distance_matrix_2[selected_solution[i-1], selected_solution[j]] + distance_matrix_2[selected_solution[j], selected_solution[i+1]] + \\\n                    distance_matrix_2[selected_solution[j-1], selected_solution[i]] + distance_matrix_2[selected_solution[i], selected_solution[j+1]]\n\n        if (old_cost1 > new_cost1 and old_cost2 > new_cost2) or \\\n           (old_cost1 > new_cost1 and random.random() < temp) or \\\n           (old_cost2 > new_cost2 and random.random() < temp):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Fallback to simple repair\n            new_solution = np.concatenate([selected_solution[:1], np.unique(selected_solution[1:])])\n\n    return new_solution\n\n",
        "score": [
            -0.9596301951410044,
            1.5502821207046509
        ]
    },
    {
        "algorithm": "The algorithm selects the most Pareto-optimal solution from the archive using dominance ranking, then applies a hybrid local search combining adaptive k-opt moves (with segment reversals and insertions) and probabilistic edge flips to generate a neighbor, while ensuring feasibility through validation and repair. The move size (k) adapts to problem size, and segment operations are biased toward reversals (70% probability). The solution prioritizes diversity and local improvement while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance_rank(solutions):\n        ranks = [0] * len(solutions)\n        for i, (s1, obj1) in enumerate(solutions):\n            for j, (s2, obj2) in enumerate(solutions):\n                if i != j and (obj1[0] <= obj2[0] and obj1[1] <= obj2[1] and (obj1[0] < obj2[0] or obj1[1] < obj2[1])):\n                    ranks[j] += 1\n        return ranks\n\n    ranks = pareto_dominance_rank(archive)\n    best_idx = np.argmin(ranks)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Hybrid k-opt with adaptive size\n    k = min(3, max(2, n // 5))\n    for _ in range(min(2, n // 3)):\n        segment = sorted(random.sample(range(1, n-1), k))\n        if random.random() < 0.7:\n            # Segment reversal with probability\n            new_solution[segment[0]:segment[-1]+1] = new_solution[segment[-1]:segment[0]-1:-1]\n        else:\n            # Segment insertion\n            insert_pos = random.randint(0, n-1)\n            segment_nodes = new_solution[segment]\n            new_solution = np.concatenate([new_solution[:insert_pos], segment_nodes, new_solution[insert_pos:]])\n            new_solution = np.delete(new_solution, np.where(np.isin(new_solution, segment_nodes))[0][k:])\n\n    # Probabilistic edge flips\n    for _ in range(min(3, n // 2)):\n        if random.random() < 0.6:\n            a, b = sorted(random.sample(range(1, n-1), 2))\n            new_solution[a:b+1] = new_solution[b:a-1:-1]\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        missing = set(range(n)) - set(new_solution)\n        extra = set(new_solution) - set(range(n))\n        if missing and extra:\n            new_solution[np.where(np.isin(new_solution, list(extra)))[0][0]] = next(iter(missing))\n\n    return new_solution\n\n",
        "score": [
            -0.9197952618686553,
            1.2500128746032715
        ]
    },
    {
        "algorithm": "The algorithm selects the least-crowded solution from the archive (based on objective diversity) and applies a hybrid approach of adaptive segment insertions and probabilistic node relocations to generate a neighbor solution. It dynamically adjusts segment sizes and relocation probabilities based on problem size and ensures feasibility by validating the tour structure. The base solution is prioritized if the generated neighbor is invalid, maintaining solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def crowding_distance(obj):\n        return (obj[0] - obj[1]) ** 2\n\n    archive.sort(key=lambda x: crowding_distance(x[1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment insertion\n    segment_size = max(2, n // 4)\n    num_insertions = min(2, n // segment_size)\n    for _ in range(num_insertions):\n        start = random.randint(1, n - segment_size - 1)\n        segment = new_solution[start:start+segment_size]\n        new_solution = np.concatenate([new_solution[:start], new_solution[start+segment_size:], segment])\n\n    # Probabilistic node relocation\n    for _ in range(min(4, n // 3)):\n        if random.random() < 0.7:\n            pos = random.randint(1, n - 2)\n            node = new_solution[pos]\n            new_solution = np.delete(new_solution, pos)\n            new_pos = random.randint(1, len(new_solution) - 1)\n            new_solution = np.insert(new_solution, new_pos, node)\n\n    # Feasibility validation\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9218659483533176,
            1.4765825867652893
        ]
    },
    {
        "algorithm": "The algorithm selects the highest-hypervolume solution from the archive, applies a dynamic 4-opt move to restructure the tour, and refines it using a variable-neighborhood descent approach with probabilistic segment insertions and temperature-based acceptance criteria, balancing exploration and exploitation through adaptive neighborhood sizes and cooling schedules. The hypervolume metric prioritizes solutions with better trade-offs between objectives, while the dynamic 4-opt and variable-neighborhood search ensure diverse and high-quality local improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    # Dynamic 4-opt move\n    i, j, k, l = sorted(random.sample(range(1, n), 4))\n    segment1 = new_solution[i:j]\n    segment2 = new_solution[j:k]\n    segment3 = new_solution[k:l]\n    new_segment = np.concatenate([segment2, segment3, segment1])\n    new_solution[i:l] = new_segment\n\n    # Variable-neighborhood descent with probabilistic insertions\n    temp = 1.0\n    cooling_rate = 0.95\n    neighborhood_sizes = [2, 3, 4, 5]\n\n    for size in neighborhood_sizes:\n        a, b = sorted(random.sample(range(1, n), 2))\n        current_obj = (sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n                       sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)))\n\n        # Try inserting a segment of variable size\n        if size > 2:\n            segment = new_solution[a:a+size]\n            temp_solution = np.concatenate([new_solution[:a], new_solution[a+size:]])\n            insert_pos = random.randint(1, len(temp_solution)-1)\n            temp_solution = np.insert(temp_solution, insert_pos, segment)\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[a], temp_solution[b] = temp_solution[b], temp_solution[a]\n\n        new_obj = (sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n)),\n                   sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n)))\n\n        if (hypervolume(new_obj) > hypervolume(current_obj) or\n            random.random() < np.exp((hypervolume(new_obj) - hypervolume(current_obj)) / temp)):\n            new_solution = temp_solution\n\n        temp *= cooling_rate\n\n    return new_solution\n\n",
        "score": [
            -0.9424316571645178,
            2.2048558592796326
        ]
    },
    {
        "algorithm": "The algorithm selects the highest-hypervolume solution from the archive, applies adaptive multi-segment reversal and probabilistic edge swaps guided by combined distance improvements in both objectives, while ensuring feasibility through validation checks. It prioritizes solutions with better combined objective values and employs a hybrid local search strategy that balances exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive multi-segment reversal guided by combined distance\n    num_segments = min(3, n // 3)\n    segment_indices = sorted(random.sample(range(1, n-1), num_segments * 2))\n    for i in range(0, len(segment_indices), 2):\n        start, end = segment_indices[i], segment_indices[i+1]\n        if start < end:\n            original_cost = (distance_matrix_1[new_solution[start-1], new_solution[start]] +\n                            distance_matrix_1[new_solution[end-1], new_solution[end]] +\n                            distance_matrix_2[new_solution[start-1], new_solution[start]] +\n                            distance_matrix_2[new_solution[end-1], new_solution[end]])\n            reversed_cost = (distance_matrix_1[new_solution[start-1], new_solution[end]] +\n                            distance_matrix_1[new_solution[start], new_solution[end-1]] +\n                            distance_matrix_2[new_solution[start-1], new_solution[end]] +\n                            distance_matrix_2[new_solution[start], new_solution[end-1]])\n            if reversed_cost < original_cost or random.random() < 0.3:\n                new_solution[start:end+1] = new_solution[end:start-1:-1]\n\n    # Probabilistic edge swaps with combined distance improvement\n    for _ in range(min(3, n // 2)):\n        if random.random() < 0.5:\n            a, b = sorted(random.sample(range(1, n-1), 2))\n            original_cost = (distance_matrix_1[new_solution[a-1], new_solution[a]] +\n                            distance_matrix_1[new_solution[b-1], new_solution[b]] +\n                            distance_matrix_2[new_solution[a-1], new_solution[a]] +\n                            distance_matrix_2[new_solution[b-1], new_solution[b]])\n            swapped_cost = (distance_matrix_1[new_solution[a-1], new_solution[b]] +\n                           distance_matrix_1[new_solution[b-1], new_solution[a]] +\n                           distance_matrix_2[new_solution[a-1], new_solution[b]] +\n                           distance_matrix_2[new_solution[b-1], new_solution[a]])\n            if swapped_cost < original_cost or random.random() < 0.2:\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Feasibility validation\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.6782491521277348,
            1.2605713605880737
        ]
    },
    {
        "algorithm": "The algorithm combines hypervolume-based selection with a hybrid local search that prioritizes Pareto-frontier guided segment reversal, adaptive edge reinsertion based on combined distance improvements in both objective spaces, and probabilistic node insertion/deletion with simulated annealing-like acceptance criteria, all while maintaining feasibility through validation checks. The selection focuses on solutions with high hypervolume product, while the local search dynamically adjusts segment sizes and insertion points based on the combined cost improvements in both objectives, using probabilistic acceptance to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest hypervolume product\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Hybrid local search with novel operators\n    # 1. Pareto-frontier guided segment reversal\n    seg_size = min(4, max(2, np.random.randint(1, n//3)))\n    i = np.random.randint(0, n - seg_size)\n    segment = new_solution[i:i+seg_size]\n\n    # Evaluate segment in both objectives\n    original_cost1 = sum(distance_matrix_1[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n    original_cost2 = sum(distance_matrix_2[new_solution[(i+j-1)%n], new_solution[(i+j)%n]] for j in range(seg_size+1))\n\n    reversed_segment = segment[::-1]\n    reversed_cost1 = (distance_matrix_1[new_solution[(i-1)%n], reversed_segment[0]] +\n                      distance_matrix_1[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                      sum(distance_matrix_1[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n    reversed_cost2 = (distance_matrix_2[new_solution[(i-1)%n], reversed_segment[0]] +\n                      distance_matrix_2[reversed_segment[-1], new_solution[(i+seg_size)%n]] +\n                      sum(distance_matrix_2[reversed_segment[j-1], reversed_segment[j]] for j in range(1, seg_size)))\n\n    if (reversed_cost1 < original_cost1 and reversed_cost2 < original_cost2) or \\\n       (np.random.random() < np.exp((reversed_cost1 + reversed_cost2 - original_cost1 - original_cost2) / 1.0)):\n        new_solution[i:i+seg_size] = reversed_segment\n\n    # 2. Adaptive edge reinsertion based on combined distance\n    if n > 4:\n        a, b = np.random.choice(n, size=2, replace=False)\n        if a > b:\n            a, b = b, a\n        if b - a > 1:\n            # Calculate combined distance improvement\n            original_dist = (distance_matrix_1[new_solution[a-1], new_solution[a]] +\n                            distance_matrix_1[new_solution[b-1], new_solution[b]] +\n                            distance_matrix_2[new_solution[a-1], new_solution[a]] +\n                            distance_matrix_2[new_solution[b-1], new_solution[b]])\n\n            new_dist = (distance_matrix_1[new_solution[a-1], new_solution[b]] +\n                        distance_matrix_1[new_solution[b-1], new_solution[a]] +\n                        distance_matrix_2[new_solution[a-1], new_solution[b]] +\n                        distance_matrix_2[new_solution[b-1], new_solution[a]])\n\n            if new_dist < original_dist or np.random.random() < 0.3:\n                new_solution = np.concatenate([new_solution[:a], new_solution[b:], new_solution[a:b]])\n\n    # 3. Probabilistic node insertion/deletion\n    if n > 4 and np.random.random() < 0.5:\n        pos = np.random.randint(0, n)\n        node = np.random.choice(n)\n        if node not in new_solution[:pos]:\n            temp_solution = np.insert(new_solution, pos, node)\n            if len(np.unique(temp_solution)) == n + 1:\n                # Evaluate insertion\n                cost1 = (distance_matrix_1[new_solution[pos-1], node] +\n                         distance_matrix_1[node, new_solution[pos]] -\n                         distance_matrix_1[new_solution[pos-1], new_solution[pos]])\n                cost2 = (distance_matrix_2[new_solution[pos-1], node] +\n                         distance_matrix_2[node, new_solution[pos]] -\n                         distance_matrix_2[new_solution[pos-1], new_solution[pos]])\n\n                if cost1 < 0 and cost2 < 0 or np.random.random() < 0.2:\n                    new_solution = temp_solution\n\n    # Ensure feasibility\n    assert len(new_solution) == n, \"Solution length changed\"\n    assert len(np.unique(new_solution)) == n, \"Duplicate nodes in solution\"\n\n    return new_solution\n\n",
        "score": [
            -0.9238378590173768,
            1.6598199605941772
        ]
    },
    {
        "algorithm": "The algorithm selects the highest-hypervolume solution from the archive, applies adaptive multi-segment reversals and probabilistic edge swaps to explore the neighborhood, and ensures feasibility by validating the tour structure. It prioritizes solutions with better objective trade-offs (higher hypervolume) and balances exploration (random segment reversals and swaps) with exploitation (local improvements). The method dynamically adjusts segment counts and swap probabilities based on problem size, ensuring valid TSP tours while avoiding revisits or omissions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def hypervolume(obj):\n        return obj[0] * obj[1]\n\n    archive.sort(key=lambda x: hypervolume(x[1]), reverse=True)\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive multi-segment reversal\n    num_segments = min(3, n // 3)\n    segment_indices = sorted(random.sample(range(1, n-1), num_segments * 2))\n    for i in range(0, len(segment_indices), 2):\n        start, end = segment_indices[i], segment_indices[i+1]\n        if start < end:\n            new_solution[start:end+1] = new_solution[end:start-1:-1]\n\n    # Probabilistic edge swaps\n    for _ in range(min(3, n // 2)):\n        if random.random() < 0.5:\n            a, b = sorted(random.sample(range(1, n-1), 2))\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Feasibility validation\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7954199191497837,
            1.3437512516975403
        ]
    }
]